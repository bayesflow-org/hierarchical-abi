{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Ar(1) on a Grid Test with compositional score matching\n",
    "\n",
    "In this notebook, we will test the compositional score matching on a hierarchical problem defined on a grid.\n",
    "- The observations are on grid with `n_grid` x `n_grid` points.\n",
    "- The global parameters are the same for all grid points with hyper-priors:\n",
    "$$ \\alpha \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\mu_\\beta \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\log\\text{std}_\\beta \\sim \\mathcal{N}(-1, 1);$$\n",
    "\n",
    "- The local parameters are different for each grid point\n",
    "$$ \\beta_{i,j}^\\text{raw} \\sim \\mathcal{N}(\\mu_\\beta, \\text{std}_\\beta^2), \\qquad \\beta_{i,j} = 2\\operatorname{sigmoid}(\\beta_{i,j}^\\text{raw})-1$$\n",
    "\n",
    "-  In each grid point, we have a time series of `T` observations. For the time beeing, we fix $\\sigma=1$.\n",
    "$$ y_{i,j} \\sim \\mathcal{N}(\\alpha + \\beta_{i,j}y_{i,j-1}, \\sigma^2), y_{i,0} \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
    "- We observe $T=5$ time points for each grid point. We can also amortize over the time dimension."
   ],
   "id": "5c47077e28d8827f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:58:25.670710Z",
     "start_time": "2025-04-18T14:58:19.321404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "from bayesflow import diagnostics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import HierarchicalScoreModel, SDE, euler_maruyama_sampling, adaptive_sampling, train_score_model\n",
    "from diffusion_model.helper_networks import GaussianFourierProjection, ShallowSet\n",
    "from problems.ar1_grid import AR1GridProblem, Prior\n",
    "from problems import plot_shrinkage, visualize_simulation_output"
   ],
   "id": "54483797f862ea66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas.arruda/miniconda/envs/hierarchical-score-matching/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:bayesflow:\n",
      "When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use\n",
      "\n",
      "with torch.enable_grad():\n",
      "    ...\n",
      "\n",
      "in contexts where you need gradients (e.g. custom training loops).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:58:25.678213Z",
     "start_time": "2025-04-18T14:58:25.676376Z"
    }
   },
   "cell_type": "code",
   "source": "torch_device = torch.device(\"cpu\")",
   "id": "1f23673a8dba58c3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:58:26.403349Z",
     "start_time": "2025-04-18T14:58:26.144989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior = Prior()\n",
    "\n",
    "# test the simulator\n",
    "sim_test = prior.sample(1, n_local_samples=16, get_grid=True)['data'][0]\n",
    "visualize_simulation_output(sim_test)"
   ],
   "id": "69a8dc61f8e7e0c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:58:26.763333Z",
     "start_time": "2025-04-18T14:58:26.407239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "number_of_obs = [1, 4, 8, 16, 64, 128]  # or a list\n",
    "current_sde = SDE(\n",
    "    kernel_type=['variance_preserving', 'sub_variance_preserving'][0],\n",
    "    noise_schedule=['linear', 'cosine', 'flow_matching'][1]\n",
    ")\n",
    "\n",
    "dataset = AR1GridProblem(\n",
    "    n_data=10000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    online_learning=True,\n",
    "    number_of_obs=number_of_obs,\n",
    "    amortize_time=False,\n",
    "    as_set=True\n",
    ")\n",
    "\n",
    "dataset_valid = AR1GridProblem(\n",
    "    n_data=1000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    number_of_obs=number_of_obs,\n",
    "    as_set=True,\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for test in dataloader:\n",
    "    print(test[4].shape)\n",
    "    break"
   ],
   "id": "3125aa477854d777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel type: variance_preserving, noise schedule: cosine\n",
      "t_min: 0.00035210439818911254, t_max: 0.999647855758667\n",
      "alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))\n",
      "Moving prior to device: cpu\n",
      "torch.Size([128, 128, 5])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "global_summary_dim = 5\n",
    "obs_n_time_steps = 0\n",
    "#summary_net = LSTM(input_size=1, hidden_dim=global_summary_dim, max_batch_size=1024)\n",
    "global_summary_net = ShallowSet(dim_input=5, dim_output=global_summary_dim, dim_hidden=16)\n",
    "\n",
    "time_dim = 8\n",
    "time_embedding_local = nn.Sequential(\n",
    "    GaussianFourierProjection(time_dim),\n",
    "    nn.Linear(time_dim, time_dim),\n",
    "    nn.Mish()\n",
    ")\n",
    "time_embedding_global = nn.Sequential(\n",
    "    GaussianFourierProjection(time_dim),\n",
    "    nn.Linear(time_dim, time_dim),\n",
    "    nn.Mish()\n",
    ")\n",
    "\n",
    "score_model = HierarchicalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_theta_local=prior.n_params_local,\n",
    "    input_dim_x_global=global_summary_dim,\n",
    "    input_dim_x_local=global_summary_dim,\n",
    "    #summary_net=summary_net,\n",
    "    global_summary_net=global_summary_net if isinstance(number_of_obs, list) else None,\n",
    "    time_embedding_local=time_embedding_local,\n",
    "    time_embedding_global=time_embedding_global,\n",
    "    hidden_dim=256,\n",
    "    n_blocks=5,\n",
    "    max_number_of_obs=number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs),\n",
    "    prediction_type=['score', 'e', 'x', 'v'][3],\n",
    "    sde=current_sde,\n",
    "    weighting_type=[None, 'likelihood_weighting', 'flow_matching', 'sigmoid'][1],\n",
    "    prior=prior,\n",
    "    name_prefix=f'ar1_3_{number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs)}',\n",
    ")\n",
    "\n",
    "# make dir for plots\n",
    "if not os.path.exists(f\"plots/{score_model.name}\"):\n",
    "    os.makedirs(f\"plots/{score_model.name}\")"
   ],
   "id": "96000faed8041fdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train model\n",
    "loss_history = train_score_model(score_model, dataloader, dataloader_valid=dataloader_valid, hierarchical=True,\n",
    "                                              epochs=2000, device=torch_device)\n",
    "score_model.eval()\n",
    "torch.save(score_model.state_dict(), f\"models/{score_model.name}.pt\")\n",
    "\n",
    "# plot loss history\n",
    "plt.figure(figsize=(16, 4), tight_layout=True)\n",
    "plt.plot(loss_history[:, 0], label='Training', color=\"#132a70\", lw=2.0, alpha=0.9)\n",
    "plt.plot(loss_history[:, 1], label='Validation', linestyle=\"--\", marker=\"o\", color='black')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('Training epoch #')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/{score_model.name}/loss_training.png')"
   ],
   "id": "7a547137b6c88170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.load_state_dict(torch.load(f\"models/{score_model.name}.pt\",\n",
    "                                       map_location=torch_device, weights_only=True))\n",
    "score_model.eval();"
   ],
   "id": "74fbd0646ed4b2bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "57c74f266a1b73a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_grid = 16\n",
    "#np.random.seed(0)\n",
    "prior_dict = prior.sample(batch_size=100, n_local_samples=n_grid*n_grid)\n",
    "\n",
    "valid_prior_global, valid_prior_local, valid_data = prior_dict['global_params'], prior_dict['local_params'], prior_dict['data']\n",
    "n_post_samples = 100\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_grid*n_grid)\n",
    "#score_model.current_number_of_obs = 1 # we can choose here, how many observations are passed together through the score\n",
    "\n",
    "#score_model.current_number_of_obs = 64\n",
    "print(valid_data.shape, score_model.current_number_of_obs)"
   ],
   "id": "38502b19cf973a3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(prior.normalize_data(valid_data[0]).reshape(5, n_grid, n_grid))",
   "id": "6f34c52c97365219",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(valid_data[0].reshape(5, n_grid, n_grid))",
   "id": "98f6856b4bc78fcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = euler_maruyama_sampling(score_model, valid_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                         n_post_samples=n_post_samples, #mini_batch_arg=mini_batch_arg,\n",
    "                                                         diffusion_steps=300, device=torch_device, verbose=True)"
   ],
   "id": "827c505971c104a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names)\n",
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_euler_sampler.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=global_param_names)\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_euler_sampler.png')"
   ],
   "id": "b70165384ef04878",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mini_batch_size = 8\n",
    "t1_value = 0.5# /( (n_grid*n_grid) //score_model.current_number_of_obs)\n",
    "t0_value = 1\n",
    "mini_batch_arg = {\n",
    "    'size': mini_batch_size,\n",
    "    #'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'noisy_condition': {\n",
    "    #    'apply': False,\n",
    "    #    'noise_scale': 1.,\n",
    "    #    'tau_1': 0.6,\n",
    "    #    'tau_2': 0.8,\n",
    "    #    'mixing_factor': 1.\n",
    "    #}\n",
    "}\n",
    "#plt.plot(torch.linspace(0, 1, 100), mini_batch_arg['damping_factor'](torch.linspace(0, 1, 100)))\n",
    "#plt.show()\n",
    "score_model.sde.s_shift_cosine = 0\n",
    "\n",
    "t0_value, t1_value"
   ],
   "id": "9229b9adbf619eab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid, step_list = adaptive_sampling(score_model, valid_data,\n",
    "                                                              obs_n_time_steps=obs_n_time_steps,\n",
    "                                                         n_post_samples=100, #max_evals=2000,\n",
    "                                                         mini_batch_arg=mini_batch_arg, run_sampling_in_parallel=False,\n",
    "                                                         device=torch_device, verbose=True, return_steps=True)"
   ],
   "id": "996c64cb32e5aa66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(step_list[0])\n",
    "plt.show()"
   ],
   "id": "be1b5828042df35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names)\n",
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_euler_sub_sampler.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=global_param_names)\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_global_euler_sub_sampler.png')"
   ],
   "id": "e897ccde2e6f9be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = adaptive_sampling(score_model, valid_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   #mini_batch_arg=mini_batch_arg,\n",
    "                                                   run_sampling_in_parallel=False,\n",
    "                                                   device=torch_device, verbose=True)"
   ],
   "id": "2e0e68a78a1593ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_adaptive_sampler.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_adaptive_sampler.png')"
   ],
   "id": "28b3c9c67f92be6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conditions_global = (np.median(posterior_global_samples_valid, axis=0), posterior_global_samples_valid)[1]\n",
    "posterior_local_samples_valid = euler_maruyama_sampling(score_model, valid_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                        n_post_samples=n_post_samples, conditions=conditions_global,\n",
    "                                                        diffusion_steps=100, device=torch_device, verbose=True)\n",
    "\n",
    "posterior_local_samples_valid = score_model.prior.transform_local_params(posterior_local_samples_valid)"
   ],
   "id": "54255d4bbbc8bd1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_local_samples_valid.reshape(valid_data.shape[0], n_post_samples, -1),\n",
    "                          np.array(valid_prior_local).reshape(valid_data.shape[0], -1),\n",
    "                          variable_names=local_param_names);"
   ],
   "id": "947470d71cedfe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "valid_id = 7\n",
    "print('Data')\n",
    "visualize_simulation_output(valid_data[valid_id])\n",
    "print('Global Estimates')\n",
    "print('mu:', np.median(posterior_global_samples_valid[valid_id, :, 1]), np.std(posterior_global_samples_valid[valid_id, :, 1]))\n",
    "print('log sigma:', np.median(posterior_global_samples_valid[valid_id, :, 2]), np.std(posterior_global_samples_valid[valid_id, :, 2]))\n",
    "print('True')\n",
    "print('mu:', valid_prior_global[valid_id][1].item())\n",
    "print('log sigma:', valid_prior_global[valid_id][2].item())"
   ],
   "id": "f63e9e6f4dba8b14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "local_p_posterior = posterior_local_samples_valid[valid_id]\n",
    "local_p_true = valid_prior_local[valid_id]\n",
    "\n",
    "med = np.median(local_p_posterior, axis=0).flatten()\n",
    "std = np.std(local_p_posterior, axis=0).flatten()\n",
    "error = (med-local_p_true.numpy())**2\n",
    "print(error.sum())\n",
    "visualize_simulation_output(np.stack((med, local_p_true)).T,\n",
    "                            title_prefix=['Posterior Median', 'True'])\n",
    "\n",
    "visualize_simulation_output(np.stack((std, error)).T, title_prefix=['Uncertainty', 'Error'], same_scale=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4), tight_layout=True)\n",
    "plt.errorbar(x=local_p_true.flatten(), y=med.flatten(), yerr=1.96*std.flatten(), fmt='o')\n",
    "plt.plot([np.min(med), np.max(med)], [np.min(med), np.max(med)], 'k--')\n",
    "#plt.axhline(np.median(posterior_global_samples_valid[valid_id], axis=0)[1], color='red', linestyle='--',\n",
    "#            label='Global posterior mean', alpha=0.75)\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('True')\n",
    "#plt.legend()\n",
    "plt.show()"
   ],
   "id": "dad2b7c0c92b5679",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare to STAN",
   "id": "454c871b333f246d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = 32*32\n",
    "global_posterior_stan = np.load(f'problems/ar1/global_posterior_{N}.npy')#[:, -100:]\n",
    "local_posterior_stan = np.load(f'problems/ar1/local_posterior_{N}.npy')#[:, -100:]\n",
    "true_global = np.load(f'problems/ar1/true_global_{N}.npy')\n",
    "true_local = np.load(f'problems/ar1/true_local_{N}.npy')\n",
    "\n",
    "n_grid_stan = int(np.sqrt(true_local.shape[1]))\n",
    "\n",
    "test_data = []\n",
    "for g, l in zip(true_global, true_local):\n",
    "    sim_dict = {'alpha': g[0],\n",
    "                'beta': l}\n",
    "    td = prior.simulator(sim_dict)['observable']\n",
    "    test_data.append(td.reshape(1, n_grid_stan*n_grid_stan, 5))\n",
    "test_data = np.concatenate(test_data)\n",
    "\n",
    "n_obs = n_grid_stan*n_grid_stan\n",
    "batch_size = test_data.shape[0]\n",
    "n_post_samples = 100\n",
    "\n",
    "print(n_grid_stan*n_grid_stan, test_data.shape)"
   ],
   "id": "581f128580f57fd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    t1_value = trial.suggest_float('t1_value', 1e-7, 1)\n",
    "    s_shift_cosine = trial.suggest_float('s_shift_cosine', 0, 10)\n",
    "    tau1 = trial.suggest_float('tau_1', 0.4, 0.9)\n",
    "    tau2 = min(tau1 + trial.suggest_float('delta_tau_2', 0, 0.4), 1)\n",
    "\n",
    "    t0_value = 1\n",
    "    mini_batch_arg = {\n",
    "        'size': 16,\n",
    "        'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2 * t),\n",
    "        'noisy_condition': {\n",
    "            'apply': True,\n",
    "            'noise_scale': 1.,\n",
    "            'tau_1': tau1,\n",
    "            'tau_2': tau2,\n",
    "            'mixing_factor': 1.\n",
    "        }\n",
    "    }\n",
    "    score_model.sde.s_shift_cosine = s_shift_cosine\n",
    "\n",
    "    test_global_samples = adaptive_sampling(score_model, test_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   mini_batch_arg=mini_batch_arg,\n",
    "                                                   run_sampling_in_parallel=False,\n",
    "                                                   device=torch_device, verbose=False)\n",
    "\n",
    "    c_error = diagnostics.calibration_error(test_global_samples, true_global)['values'].mean()\n",
    "    rmse = diagnostics.root_mean_squared_error(test_global_samples, true_global)['values'].mean()\n",
    "    return rmse + c_error\n",
    "\n",
    "study = optuna.create_study()\n",
    "#study.optimize(objective, n_trials=20)\n",
    "#print(study.best_params)\n",
    "\n",
    "study_best_params = {'t1_value': 0.3994890029993266, 's_shift_cosine': 4.190800555472762,\n",
    "                     'tau_1': 0.7639228586194012, 'delta_tau_2': 0.3010046756155764}"
   ],
   "id": "69e77c6be4c572b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t0_value, t1_value = 1, study_best_params['t1_value']\n",
    "mini_batch_arg = {\n",
    "    'size': 4,\n",
    "    'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    'noisy_condition': {\n",
    "        'apply': False,\n",
    "        'noise_scale': 1.,\n",
    "        'tau_1': study_best_params['tau_1'],\n",
    "        'tau_2': min(study_best_params['tau_1'] + study_best_params['delta_tau_2'], 1),\n",
    "        'mixing_factor': 1.\n",
    "    }\n",
    "}\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_grid_stan*n_grid_stan)\n",
    "param_names_stan = ['STAN '+ p for p in global_param_names]\n",
    "score_model.sde.s_shift_cosine = study_best_params['s_shift_cosine']\n",
    "\n",
    "print(mini_batch_arg)"
   ],
   "id": "331b32a82f23f60b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.current_number_of_obs = 64\n",
    "# posterior_global_samples_test = adaptive_sampling(score_model, test_data, obs_n_time_steps=obs_n_time_steps,\n",
    "#                                                     n_post_samples=n_post_samples,\n",
    "#                                                     mini_batch_arg=mini_batch_arg,\n",
    "#                                                     run_sampling_in_parallel=False,\n",
    "#                                                     device=torch_device, verbose=True)\n",
    "\n",
    "posterior_global_samples_test = euler_maruyama_sampling(score_model, test_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   mini_batch_arg=mini_batch_arg,\n",
    "                                                   diffusion_steps=300,\n",
    "                                                   device=torch_device, verbose=True)"
   ],
   "id": "8bd578faee7c394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_test, true_global, variable_names=global_param_names)\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_ours.png')\n",
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_test, true_global)['values'].mean())\n",
    "#fig = diagnostics.recovery(posterior_global_samples_test, np.median(global_posterior_stan, axis=1),\n",
    "#                     variable_names=global_param_names, xlabel='STAN Median Estimate')\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_ours_vs_STAN.png')\n",
    "fig = diagnostics.recovery(global_posterior_stan, true_global, variable_names=param_names_stan)\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_STAN.png')\n",
    "print('RMSE STAN:', diagnostics.root_mean_squared_error(global_posterior_stan, true_global)['values'].mean())"
   ],
   "id": "e8f8151c350c38a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_test, true_global, difference=True,\n",
    "                             variable_names=global_param_names)\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_global_ours.png')\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_test, true_global)['values'].mean())\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(global_posterior_stan, true_global, difference=True, variable_names=param_names_stan)\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_global_STAN.png')\n",
    "print('ECDF STAN:', diagnostics.calibration_error(global_posterior_stan, true_global)['values'].mean())"
   ],
   "id": "277ce7c4c4edb333",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "score_model.current_number_of_obs = 1\n",
    "posterior_local_samples_test = euler_maruyama_sampling(score_model, test_data[:, :12], obs_n_time_steps=obs_n_time_steps,\n",
    "                                                       n_post_samples=n_post_samples,\n",
    "                                                       conditions=posterior_global_samples_test,\n",
    "                                                       #conditions=global_posterior_stan[:, :n_post_samples],\n",
    "                                                       #run_sampling_in_parallel=False,\n",
    "                                                       mini_batch_arg={'local_chunk_size': 1000},\n",
    "                                                       diffusion_steps=200,\n",
    "                                                       device=torch_device, verbose=True)\n",
    "\n",
    "posterior_local_samples_test = score_model.prior.transform_local_params(posterior_local_samples_test)"
   ],
   "id": "bf57087b90c578f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "global_var = np.exp(np.median(posterior_global_samples_test, axis=1)[:, 1])[:, np.newaxis] ** 2\n",
    "shrinkage = 1-np.var(np.median(posterior_local_samples_test, axis=1), axis=1)/global_var\n",
    "\n",
    "global_var_stan = np.exp(np.median(global_posterior_stan, axis=1)[:, 1])**2\n",
    "shrinkage_stan = 1-np.var(np.median(local_posterior_stan, axis=1), axis=1)/global_var_stan\n",
    "\n",
    "true_var = np.exp(true_global)[:, 1]**2\n",
    "shrinkage_true = 1-np.var(true_local, axis=1)/true_var\n",
    "\n",
    "s_order = np.argsort(shrinkage_true)\n",
    "shrinkage = shrinkage.flatten()[s_order]\n",
    "shrinkage_stan = shrinkage_stan.flatten()[s_order]\n",
    "shrinkage_true = shrinkage_true[s_order]\n",
    "\n",
    "min_s = -10\n",
    "shrinkage[shrinkage < min_s] = min_s\n",
    "shrinkage_stan[shrinkage_stan < min_s] = min_s\n",
    "shrinkage_true[shrinkage_true < min_s] = min_s\n",
    "\n",
    "plt.title('Shrinkage')\n",
    "plt.plot(shrinkage, label='score', alpha=0.75)\n",
    "plt.plot(shrinkage_stan, label='STAN', alpha=0.75)\n",
    "plt.plot(shrinkage_true, label='true', alpha=0.75)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Correlation shrinkage score and STAN:', np.corrcoef(shrinkage, shrinkage_stan)[0, 1])\n",
    "print('Correlation shrinkage true and score:', np.corrcoef(shrinkage_true, shrinkage)[0, 1])\n",
    "print('Correlation shrinkage true and STAN:', np.corrcoef(shrinkage_true, shrinkage_stan)[0, 1])\n",
    "\n",
    "print(f\"Score shrinkage < STAN shrinkage: {(shrinkage < shrinkage_stan).sum() / shrinkage.shape[0]*100}%\")"
   ],
   "id": "34fa0480f91f9f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_local_samples_test.reshape(test_data.shape[0], n_post_samples, -1)[:, :, :12],\n",
    "                     true_local[:, :12],\n",
    "                     variable_names=local_param_names[:12])\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_local_ours.png')\n",
    "diagnostics.recovery(local_posterior_stan[:, :, :12], true_local[:, :12], variable_names=local_param_names[:12]);"
   ],
   "id": "9ee1210cd7e43a79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_local_samples_test.reshape(test_data.shape[0], n_post_samples, -1)[:, :, :12],\n",
    "                     np.median(local_posterior_stan[:, :, :12], axis=1),\n",
    "                           ylabel='Score Based Estimates', xlabel='STAN Median Estimate', variable_names=local_param_names[:12])\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_local_ours_vs_STAN.png')"
   ],
   "id": "66ddb1260bd2b0df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_local_samples_test.reshape(test_data.shape[0], n_post_samples, -1)\n",
    "\n",
    "plot_shrinkage(posterior_global_samples_test[:12, :, 1:], posterior_local_samples_test[..., np.newaxis][:12],\n",
    "               min_max=(-10,10))"
   ],
   "id": "7bfc6285e8c7963b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_shrinkage(global_posterior_stan[:12, :, 1:], local_posterior_stan[..., np.newaxis][:12], min_max=(-10,10))",
   "id": "85ac95e3f5f922f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check different sampling schemes",
   "id": "7262a8aec635e1ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure we generate enough synthetic data samples.\n",
    "n_samples_data = 100\n",
    "n_post_samples = 100\n",
    "score_model.current_number_of_obs = 1\n",
    "max_steps = 10000\n",
    "variables_of_interest = ['mini_batch', 'cosine_shift', 'damping_factor_t']\n",
    "\n",
    "variables_of_interest.append('n_conditions')\n",
    "variable_of_interest = variables_of_interest[1]\n",
    "print(variable_of_interest)\n",
    "\n",
    "mini_batch = ['10%']\n",
    "n_conditions = [1]\n",
    "cosine_shifts = [0]\n",
    "d_factors = [1]  # using the d factor depending on the mini batch size\n",
    "data_sizes = np.array([4*4, 16*16, 64*64, 512*512])\n",
    "\n",
    "if variable_of_interest == 'mini_batch':\n",
    "    # Set up your data sizes and mini-batch parameters.\n",
    "    mini_batch = [1, 10, 100, 1000, 10000, None]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest == 'n_conditions':\n",
    "    n_conditions = [1, 4, 8, 16, 64, 128]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest == 'cosine_shift':\n",
    "    cosine_shifts = [0, -1, 1, 2, 5, 10][::-1]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest == 'damping_factor_t':\n",
    "    d_factors = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 0.75, 1]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "else:\n",
    "    raise ValueError('Unknown variable_of_interest')\n",
    "\n",
    "df_path = f'_plots/{score_model.name}/df_results_{variable_of_interest}.csv'\n",
    "if os.path.exists(df_path):\n",
    "    # Load CSV\n",
    "    df_results = pd.read_csv(df_path, index_col=0)\n",
    "else:\n",
    "    df_results = None"
   ],
   "id": "13c7b199d1cb89c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List to store results.\n",
    "results = []\n",
    "reached_max_evals = []\n",
    "\n",
    "# Iterate over data sizes.\n",
    "for n in data_sizes:\n",
    "    # Generate synthetic data with enough samples\n",
    "    prior_dict = prior.sample(batch_size=n_samples_data, n_local_samples=n)\n",
    "    true_params_global, true_params_local, test_data = prior_dict['global_params'], prior_dict['local_params'], prior_dict['data']\n",
    "    print(test_data.shape)\n",
    "\n",
    "    true_params_global = true_params_global.numpy()\n",
    "    true_params_local = true_params_local.numpy()\n",
    "    # Iterate over experimental setting\n",
    "    for mb, nc, cs, d_factor in itertools.product(mini_batch, n_conditions, cosine_shifts, d_factors):\n",
    "        # Skip mini-batch settings that are larger than or equal to the data size.\n",
    "        if mb == '10%':\n",
    "            mb = max(int(n * 0.1), 1)\n",
    "        if mb is not None and mb >= n:\n",
    "            continue\n",
    "        if nc > n:\n",
    "            continue\n",
    "\n",
    "        skip = False\n",
    "        for max_reached in reached_max_evals:\n",
    "            if max_reached[0] <= n:  # check if for a smaller data size we already failed\n",
    "                if max_reached[2] == nc and max_reached[3] == cs and max_reached[4] == d_factor:\n",
    "                    # all conditions are the same, only mini batch size is different\n",
    "                    if max_reached[1] is None:\n",
    "                        pass\n",
    "                    elif mb is None or max_reached[1] < mb:\n",
    "                        print(f'smaller mini batch size already failed, skipping {nc}, {cs}')\n",
    "                        skip = True\n",
    "                        break\n",
    "                #elif max_reached[2] == nc and max_reached[3] == cs and max_reached[4] < d_factor:\n",
    "                #    # all conditions are the same (assuming mini-batching does not change)\n",
    "                #    # check if smaller damping factor already failed\n",
    "                #    print(f'smaller damping factor already failed, skipping {nc}, {cs}')\n",
    "                #    skip = True\n",
    "                #    break\n",
    "        if skip:\n",
    "            results.append({\n",
    "                \"data_size\": n,\n",
    "                \"data_id\": -1,\n",
    "                \"mini_batch\": mb if mb is not None else n,\n",
    "                \"damping_factor\": d_factor,\n",
    "                'n_conditions': nc,\n",
    "                'cosine_shift': cs,\n",
    "                \"n_steps\": max_steps,\n",
    "                \"median\": np.nan,\n",
    "                \"rmse_global\":  np.nan,\n",
    "                \"c_error_global\":  np.nan,\n",
    "                \"contractions_global\":  np.nan,\n",
    "                \"rmse_local\":  np.nan,\n",
    "                \"c_error_local\":  np.nan,\n",
    "                \"contractions_local\":  np.nan,\n",
    "            })\n",
    "            df_results = pd.DataFrame(results)\n",
    "            df_results.to_csv(df_path)\n",
    "            continue\n",
    "\n",
    "        print(f\"Data Size: {n}, Mini Batch: {mb}, Conditions: {nc}, Cosine shift: {cs}, Damping Factor: {d_factor}\")\n",
    "        # Set current number of conditions\n",
    "        score_model.current_number_of_obs = nc\n",
    "\n",
    "        # Set cosine shit\n",
    "        score_model.sde.s_shift_cosine = cs\n",
    "\n",
    "        # Damping factor\n",
    "        if variable_of_interest == 'damping_factor_t':\n",
    "            t0_value = 1\n",
    "            t1_value = d_factor\n",
    "            damping_factor = lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t)\n",
    "            if mb is None:\n",
    "                mini_batch_arg = {'damping_factor': damping_factor}\n",
    "            else:\n",
    "                mini_batch_arg = {'size': mb, 'damping_factor': damping_factor}\n",
    "        else:\n",
    "            damping_factor = lambda t: torch.ones_like(t) * d_factor\n",
    "            if mb is None:\n",
    "                mini_batch_arg = {'damping_factor': damping_factor}\n",
    "            else:\n",
    "                mini_batch_arg = {'size': mb, 'damping_factor': damping_factor}\n",
    "\n",
    "        # Run adaptive sampling.\n",
    "        try:\n",
    "            print('global sampling')\n",
    "            test_global_samples, list_steps = adaptive_sampling(score_model, test_data, conditions=None,\n",
    "                                                         obs_n_time_steps=obs_n_time_steps,\n",
    "                                                         n_post_samples=n_post_samples,\n",
    "                                                         mini_batch_arg=mini_batch_arg,\n",
    "                                                         max_evals=max_steps*2,\n",
    "                                                         t_end=0, random_seed=0, device=torch_device,\n",
    "                                                         run_sampling_in_parallel=False,  # can actually be faster\n",
    "                                                         return_steps=True)\n",
    "\n",
    "            score_model.current_number_of_obs = 1\n",
    "            score_model.sde.s_shift_cosine = 0\n",
    "            print('local sampling')\n",
    "            test_local_samples = euler_maruyama_sampling(score_model, test_data, obs_n_time_steps=obs_n_time_steps,\n",
    "                                                       n_post_samples=test_global_samples.shape[1],  # in the case some samples failed\n",
    "                                                       conditions=test_global_samples,\n",
    "                                                       diffusion_steps=200,\n",
    "                                                       device=torch_device, verbose=False)\n",
    "            test_local_samples = score_model.prior.transform_local_params(test_local_samples)[..., 0]\n",
    "\n",
    "        except torch.OutOfMemoryError as e:\n",
    "            print(e)\n",
    "            results.append({\n",
    "                \"data_size\": n,\n",
    "                \"data_id\": -1,\n",
    "                \"mini_batch\": mb if mb is not None else n,\n",
    "                \"damping_factor\": d_factor,\n",
    "                'n_conditions': nc,\n",
    "                'cosine_shift': cs,\n",
    "                \"n_steps\": max_steps,\n",
    "                \"median\": np.nan,\n",
    "                \"rmse_global\":  np.nan,\n",
    "                \"c_error_global\":  np.nan,\n",
    "                \"contractions_global\":  np.nan,\n",
    "                \"rmse_local\":  np.nan,\n",
    "                \"c_error_local\":  np.nan,\n",
    "                \"contractions_local\":  np.nan,\n",
    "            })\n",
    "            df_results = pd.DataFrame(results)\n",
    "            df_results.to_csv(df_path)\n",
    "            continue\n",
    "\n",
    "        # Number of steps\n",
    "        if np.isnan(test_global_samples).any():\n",
    "            n_steps = np.inf\n",
    "            reached_max_evals.append((n, mb, nc, cs, d_factor))\n",
    "            print('nan in global samples')\n",
    "        else:\n",
    "            n_steps = np.mean([len(ls) for ls in list_steps])\n",
    "            if n_steps >= max_steps:\n",
    "                # others will also fail to converge\n",
    "                reached_max_evals.append((n, mb, nc, cs, d_factor))\n",
    "                print('max steps reached')\n",
    "\n",
    "        print('global shapes', test_global_samples.shape, true_params_global.shape)\n",
    "        rmse_global = diagnostics.root_mean_squared_error(test_global_samples, true_params_global)['values'].mean()\n",
    "        c_error_global = diagnostics.calibration_error(test_global_samples, true_params_global)['values'].mean()\n",
    "        contractions_global = diagnostics.posterior_contraction(test_global_samples, true_params_global)['values'].mean()\n",
    "\n",
    "        print('local shapes', test_local_samples.shape, true_params_local.shape)\n",
    "        rmse_local = diagnostics.root_mean_squared_error(test_local_samples, true_params_local)['values'].mean()\n",
    "        c_error_local = diagnostics.calibration_error(test_local_samples, true_params_local)['values'].mean()\n",
    "        contractions_local = diagnostics.posterior_contraction(test_local_samples, true_params_local)['values'].mean()\n",
    "\n",
    "        # Save results into a dictionary.\n",
    "        for i in range(n_samples_data):  # might be less than the actual data points because inference failed\n",
    "            results.append({\n",
    "                \"data_size\": n,\n",
    "                \"data_id\": i,\n",
    "                \"mini_batch\": mb if mb is not None else n,\n",
    "                \"damping_factor\": d_factor,\n",
    "                'n_conditions': nc,\n",
    "                'cosine_shift': cs,\n",
    "                \"n_steps\": n_steps,\n",
    "                \"median_global\": np.median(test_global_samples, axis=1)[i],\n",
    "                \"median_local\": np.median(test_local_samples, axis=1)[i],\n",
    "                \"rmse_global\": rmse_global,\n",
    "                \"c_error_global\": c_error_global,\n",
    "                \"contractions_global\": contractions_global,\n",
    "                \"rmse_local\": rmse_local,\n",
    "                \"c_error_local\": c_error_local,\n",
    "                \"contractions_local\": contractions_local,\n",
    "            })\n",
    "\n",
    "        # Create a DataFrame from the results list. Save intermediate results\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_csv(df_path)"
   ],
   "id": "6cf3d77e80646c31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8037a5538e462e73",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-abi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
