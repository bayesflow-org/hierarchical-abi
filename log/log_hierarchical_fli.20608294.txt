WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    4608    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    4608    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    1536    |
|     final_projection_linear.bias     |     6      |
+--------------------------------------+------------+
Total Trainable Params: 274182
FLI_1_22_256_5_split_TimeSeriesNetwork_global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    5376    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    5376    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    768     |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 274947
FLI_1_22_256_5_split_TimeSeriesNetwork_local_score_model_v_variance_preserving_cosine_likelihood_weighting
+-----------------------------------------------------------+------------+
|                          Modules                          | Parameters |
+-----------------------------------------------------------+------------+
|              summary_net.conv_blocks.0.weight             |     96     |
|               summary_net.conv_blocks.0.bias              |     32     |
|           summary_net.recurrent.skip_conv.weight          |   16384    |
|            summary_net.recurrent.skip_conv.bias           |    128     |
|        summary_net.recurrent.recurrent.weight_ih_l0       |   12288    |
|        summary_net.recurrent.recurrent.weight_hh_l0       |   49152    |
|         summary_net.recurrent.recurrent.bias_ih_l0        |    384     |
|         summary_net.recurrent.recurrent.bias_hh_l0        |    384     |
|    summary_net.recurrent.recurrent.weight_ih_l0_reverse   |   12288    |
|    summary_net.recurrent.recurrent.weight_hh_l0_reverse   |   49152    |
|     summary_net.recurrent.recurrent.bias_ih_l0_reverse    |    384     |
|     summary_net.recurrent.recurrent.bias_hh_l0_reverse    |    384     |
|     summary_net.recurrent.skip_recurrent.weight_ih_l0     |   49152    |
|     summary_net.recurrent.skip_recurrent.weight_hh_l0     |   49152    |
|      summary_net.recurrent.skip_recurrent.bias_ih_l0      |    384     |
|      summary_net.recurrent.skip_recurrent.bias_hh_l0      |    384     |
| summary_net.recurrent.skip_recurrent.weight_ih_l0_reverse |   49152    |
| summary_net.recurrent.skip_recurrent.weight_hh_l0_reverse |   49152    |
|  summary_net.recurrent.skip_recurrent.bias_ih_l0_reverse  |    384     |
|  summary_net.recurrent.skip_recurrent.bias_hh_l0_reverse  |    384     |
|            summary_net.output_projector.weight            |   11264    |
|             summary_net.output_projector.bias             |     22     |
|       global_model.blocks.res_blocks.0.dense.weight       |    4608    |
|        global_model.blocks.res_blocks.0.dense.bias        |    256     |
|     global_model.blocks.res_blocks.0.projector.weight     |    4608    |
|       global_model.blocks.res_blocks.1.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.1.dense.bias        |    256     |
|       global_model.blocks.res_blocks.2.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.2.dense.bias        |    256     |
|       global_model.blocks.res_blocks.3.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.3.dense.bias        |    256     |
|       global_model.blocks.res_blocks.4.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.4.dense.bias        |    256     |
|        global_model.final_projection_linear.weight        |    1536    |
|         global_model.final_projection_linear.bias         |     6      |
|        local_model.blocks.res_blocks.0.dense.weight       |    5376    |
|         local_model.blocks.res_blocks.0.dense.bias        |    256     |
|      local_model.blocks.res_blocks.0.projector.weight     |    5376    |
|        local_model.blocks.res_blocks.1.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.1.dense.bias        |    256     |
|        local_model.blocks.res_blocks.2.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.2.dense.bias        |    256     |
|        local_model.blocks.res_blocks.3.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.3.dense.bias        |    256     |
|        local_model.blocks.res_blocks.4.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.4.dense.bias        |    256     |
|         local_model.final_projection_linear.weight        |    768     |
|          local_model.final_projection_linear.bias         |     3      |
+-----------------------------------------------------------+------------+
Total Trainable Params: 899615
FLI_1_22_256_5_split_TimeSeriesNetwork_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
torch.Size([100, 1024, 256, 1]) 1
applying summary network to observations before sampling, might take a while...
applying summary network to observations before sampling, might take a while...
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:08<14:45,  8.95s/it]  2%|▏         | 2/100 [00:17<14:31,  8.89s/it]  3%|▎         | 3/100 [00:26<14:19,  8.86s/it]  4%|▍         | 4/100 [00:35<14:10,  8.86s/it]  5%|▌         | 5/100 [00:44<14:09,  8.94s/it]  6%|▌         | 6/100 [00:53<13:57,  8.91s/it]  7%|▋         | 7/100 [01:02<13:47,  8.90s/it]  8%|▊         | 8/100 [01:11<13:36,  8.88s/it]  9%|▉         | 9/100 [01:19<13:26,  8.86s/it] 10%|█         | 10/100 [01:28<13:16,  8.85s/it] 11%|█         | 11/100 [01:37<13:08,  8.86s/it] 12%|█▏        | 12/100 [01:46<12:58,  8.85s/it] 13%|█▎        | 13/100 [01:55<12:51,  8.87s/it] 14%|█▍        | 14/100 [02:04<12:42,  8.87s/it] 15%|█▌        | 15/100 [02:13<12:32,  8.86s/it] 16%|█▌        | 16/100 [02:21<12:24,  8.87s/it] 17%|█▋        | 17/100 [02:30<12:15,  8.86s/it] 18%|█▊        | 18/100 [02:39<12:06,  8.86s/it] 19%|█▉        | 19/100 [02:48<11:57,  8.86s/it] 20%|██        | 20/100 [02:57<11:48,  8.86s/it] 21%|██        | 21/100 [03:06<11:40,  8.86s/it] 22%|██▏       | 22/100 [03:15<11:31,  8.87s/it] 23%|██▎       | 23/100 [03:24<11:22,  8.87s/it] 24%|██▍       | 24/100 [03:33<11:19,  8.94s/it] 25%|██▌       | 25/100 [03:41<11:08,  8.91s/it] 26%|██▌       | 26/100 [03:50<10:58,  8.90s/it] 27%|██▋       | 27/100 [03:59<10:48,  8.88s/it] 28%|██▊       | 28/100 [04:08<10:39,  8.88s/it] 29%|██▉       | 29/100 [04:17<10:30,  8.87s/it] 30%|███       | 30/100 [04:26<10:21,  8.87s/it] 31%|███       | 31/100 [04:35<10:12,  8.87s/it] 32%|███▏      | 32/100 [04:44<10:03,  8.87s/it] 33%|███▎      | 33/100 [04:52<09:54,  8.87s/it] 34%|███▍      | 34/100 [05:01<09:44,  8.86s/it] 35%|███▌      | 35/100 [05:10<09:35,  8.85s/it] 36%|███▌      | 36/100 [05:19<09:26,  8.85s/it] 37%|███▋      | 37/100 [05:28<09:17,  8.85s/it] 38%|███▊      | 38/100 [05:37<09:08,  8.85s/it] 39%|███▉      | 39/100 [05:45<09:00,  8.86s/it] 40%|████      | 40/100 [05:54<08:51,  8.86s/it] 41%|████      | 41/100 [06:03<08:43,  8.87s/it] 42%|████▏     | 42/100 [06:12<08:33,  8.86s/it] 43%|████▎     | 43/100 [06:21<08:28,  8.92s/it] 44%|████▍     | 44/100 [06:30<08:18,  8.90s/it] 45%|████▌     | 45/100 [06:39<08:09,  8.89s/it] 46%|████▌     | 46/100 [06:48<07:59,  8.88s/it] 47%|████▋     | 47/100 [06:57<07:50,  8.88s/it] 48%|████▊     | 48/100 [07:05<07:41,  8.87s/it] 49%|████▉     | 49/100 [07:14<07:32,  8.87s/it] 50%|█████     | 50/100 [07:23<07:23,  8.87s/it] 51%|█████     | 51/100 [07:32<07:14,  8.86s/it] 52%|█████▏    | 52/100 [07:41<07:05,  8.87s/it] 53%|█████▎    | 53/100 [07:50<06:56,  8.87s/it] 54%|█████▍    | 54/100 [07:59<06:47,  8.87s/it] 55%|█████▌    | 55/100 [08:08<06:39,  8.87s/it] 56%|█████▌    | 56/100 [08:16<06:29,  8.86s/it] 57%|█████▋    | 57/100 [08:25<06:21,  8.87s/it] 58%|█████▊    | 58/100 [08:34<06:12,  8.87s/it] 59%|█████▉    | 59/100 [08:43<06:03,  8.87s/it] 60%|██████    | 60/100 [08:52<05:54,  8.86s/it] 61%|██████    | 61/100 [09:01<05:45,  8.86s/it] 62%|██████▏   | 62/100 [09:10<05:38,  8.92s/it] 63%|██████▎   | 63/100 [09:19<05:29,  8.90s/it] 64%|██████▍   | 64/100 [09:28<05:21,  8.92s/it] 65%|██████▌   | 65/100 [09:36<05:11,  8.90s/it] 66%|██████▌   | 66/100 [09:45<05:02,  8.90s/it] 67%|██████▋   | 67/100 [09:54<04:54,  8.92s/it] 68%|██████▊   | 68/100 [10:03<04:45,  8.93s/it] 69%|██████▉   | 69/100 [10:12<04:37,  8.94s/it] 70%|███████   | 70/100 [10:21<04:27,  8.91s/it] 71%|███████   | 71/100 [10:30<04:18,  8.93s/it] 72%|███████▏  | 72/100 [10:39<04:09,  8.92s/it] 73%|███████▎  | 73/100 [10:48<04:00,  8.92s/it] 74%|███████▍  | 74/100 [10:57<03:52,  8.94s/it] 75%|███████▌  | 75/100 [11:06<03:42,  8.91s/it] 76%|███████▌  | 76/100 [11:15<03:34,  8.92s/it] 77%|███████▋  | 77/100 [11:24<03:25,  8.93s/it] 78%|███████▊  | 78/100 [11:33<03:16,  8.95s/it] 79%|███████▉  | 79/100 [11:41<03:07,  8.93s/it] 80%|████████  | 80/100 [11:50<02:58,  8.92s/it] 81%|████████  | 81/100 [12:00<02:50,  9.00s/it] 82%|████████▏ | 82/100 [12:08<02:41,  8.95s/it] 83%|████████▎ | 83/100 [12:17<02:31,  8.92s/it] 84%|████████▍ | 84/100 [12:26<02:22,  8.91s/it] 85%|████████▌ | 85/100 [12:35<02:13,  8.89s/it] 86%|████████▌ | 86/100 [12:44<02:04,  8.88s/it] 87%|████████▋ | 87/100 [12:53<01:55,  8.90s/it] 88%|████████▊ | 88/100 [13:02<01:46,  8.90s/it] 89%|████████▉ | 89/100 [13:11<01:37,  8.91s/it] 90%|█████████ | 90/100 [13:19<01:28,  8.89s/it] 91%|█████████ | 91/100 [13:28<01:19,  8.87s/it] 92%|█████████▏| 92/100 [13:37<01:10,  8.87s/it] 93%|█████████▎| 93/100 [13:46<01:02,  8.87s/it] 94%|█████████▍| 94/100 [13:55<00:53,  8.87s/it] 95%|█████████▌| 95/100 [14:04<00:44,  8.90s/it] 96%|█████████▌| 96/100 [14:13<00:35,  8.89s/it] 97%|█████████▋| 97/100 [14:22<00:26,  8.88s/it] 98%|█████████▊| 98/100 [14:30<00:17,  8.87s/it] 99%|█████████▉| 99/100 [14:39<00:08,  8.90s/it]100%|██████████| 100/100 [14:48<00:00,  8.94s/it]100%|██████████| 100/100 [14:48<00:00,  8.89s/it]
