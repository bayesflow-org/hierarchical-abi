WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
[I 2025-04-22 19:03:57,351] A new study created in memory with name: no-name-44a5f413-26b7-49d8-ad5c-2f9dc5d656c9
