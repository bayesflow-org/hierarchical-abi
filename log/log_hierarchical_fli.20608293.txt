WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:288: RuntimeWarning: overflow encountered in exp
  tau = np.exp(log_tau)
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:289: RuntimeWarning: overflow encountered in exp
  tau_2 = tau + np.exp(log_delta_tau)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py:1615: UserWarning: KDE cannot be estimated (0 variance or perfect covariance). Pass `warn_singular=False` to disable this warning.
  func(x=x, y=y, **kwargs)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py:1615: UserWarning: KDE cannot be estimated (0 variance or perfect covariance). Pass `warn_singular=False` to disable this warning.
  func(x=x, y=y, **kwargs)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py:1615: UserWarning: KDE cannot be estimated (0 variance or perfect covariance). Pass `warn_singular=False` to disable this warning.
  func(x=x, y=y, **kwargs)
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    6400    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    6400    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    1536    |
|     final_projection_linear.bias     |     6      |
+--------------------------------------+------------+
Total Trainable Params: 277766
FLI_1_18_256_5_TimeSeriesNetwork_global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    7168    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    7168    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    768     |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 278531
FLI_1_18_256_5_TimeSeriesNetwork_local_score_model_v_variance_preserving_cosine_likelihood_weighting
+-----------------------------------------------------------+------------+
|                          Modules                          | Parameters |
+-----------------------------------------------------------+------------+
|              summary_net.conv_blocks.0.weight             |     96     |
|               summary_net.conv_blocks.0.bias              |     32     |
|           summary_net.recurrent.skip_conv.weight          |   16384    |
|            summary_net.recurrent.skip_conv.bias           |    128     |
|        summary_net.recurrent.recurrent.weight_ih_l0       |   12288    |
|        summary_net.recurrent.recurrent.weight_hh_l0       |   49152    |
|         summary_net.recurrent.recurrent.bias_ih_l0        |    384     |
|         summary_net.recurrent.recurrent.bias_hh_l0        |    384     |
|    summary_net.recurrent.recurrent.weight_ih_l0_reverse   |   12288    |
|    summary_net.recurrent.recurrent.weight_hh_l0_reverse   |   49152    |
|     summary_net.recurrent.recurrent.bias_ih_l0_reverse    |    384     |
|     summary_net.recurrent.recurrent.bias_hh_l0_reverse    |    384     |
|     summary_net.recurrent.skip_recurrent.weight_ih_l0     |   49152    |
|     summary_net.recurrent.skip_recurrent.weight_hh_l0     |   49152    |
|      summary_net.recurrent.skip_recurrent.bias_ih_l0      |    384     |
|      summary_net.recurrent.skip_recurrent.bias_hh_l0      |    384     |
| summary_net.recurrent.skip_recurrent.weight_ih_l0_reverse |   49152    |
| summary_net.recurrent.skip_recurrent.weight_hh_l0_reverse |   49152    |
|  summary_net.recurrent.skip_recurrent.bias_ih_l0_reverse  |    384     |
|  summary_net.recurrent.skip_recurrent.bias_hh_l0_reverse  |    384     |
|            summary_net.output_projector.weight            |    9216    |
|             summary_net.output_projector.bias             |     18     |
|       global_model.blocks.res_blocks.0.dense.weight       |    6400    |
|        global_model.blocks.res_blocks.0.dense.bias        |    256     |
|     global_model.blocks.res_blocks.0.projector.weight     |    6400    |
|       global_model.blocks.res_blocks.1.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.1.dense.bias        |    256     |
|       global_model.blocks.res_blocks.2.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.2.dense.bias        |    256     |
|       global_model.blocks.res_blocks.3.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.3.dense.bias        |    256     |
|       global_model.blocks.res_blocks.4.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.4.dense.bias        |    256     |
|        global_model.final_projection_linear.weight        |    1536    |
|         global_model.final_projection_linear.bias         |     6      |
|        local_model.blocks.res_blocks.0.dense.weight       |    7168    |
|         local_model.blocks.res_blocks.0.dense.bias        |    256     |
|      local_model.blocks.res_blocks.0.projector.weight     |    7168    |
|        local_model.blocks.res_blocks.1.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.1.dense.bias        |    256     |
|        local_model.blocks.res_blocks.2.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.2.dense.bias        |    256     |
|        local_model.blocks.res_blocks.3.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.3.dense.bias        |    256     |
|        local_model.blocks.res_blocks.4.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.4.dense.bias        |    256     |
|         local_model.final_projection_linear.weight        |    768     |
|          local_model.final_projection_linear.bias         |     3      |
+-----------------------------------------------------------+------------+
Total Trainable Params: 904731
FLI_1_18_256_5_TimeSeriesNetwork_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
torch.Size([100, 1024, 256, 1]) 1
applying summary network to observations before sampling, might take a while...
applying summary network to observations before sampling, might take a while...
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:08<14:34,  8.84s/it]  2%|▏         | 2/100 [00:17<14:20,  8.78s/it]  3%|▎         | 3/100 [00:26<14:11,  8.78s/it]  4%|▍         | 4/100 [00:35<14:01,  8.77s/it]  5%|▌         | 5/100 [00:43<13:51,  8.76s/it]  6%|▌         | 6/100 [00:52<13:44,  8.77s/it]  7%|▋         | 7/100 [01:01<13:34,  8.75s/it]  8%|▊         | 8/100 [01:10<13:24,  8.74s/it]  9%|▉         | 9/100 [01:18<13:14,  8.74s/it] 10%|█         | 10/100 [01:27<13:06,  8.73s/it] 11%|█         | 11/100 [01:36<12:56,  8.73s/it] 12%|█▏        | 12/100 [01:44<12:48,  8.73s/it] 13%|█▎        | 13/100 [01:54<12:47,  8.82s/it] 14%|█▍        | 14/100 [02:02<12:35,  8.78s/it] 15%|█▌        | 15/100 [02:11<12:25,  8.77s/it] 16%|█▌        | 16/100 [02:20<12:14,  8.74s/it] 17%|█▋        | 17/100 [02:28<12:04,  8.73s/it] 18%|█▊        | 18/100 [02:37<11:55,  8.72s/it] 19%|█▉        | 19/100 [02:46<11:46,  8.72s/it] 20%|██        | 20/100 [02:54<11:37,  8.72s/it] 21%|██        | 21/100 [03:03<11:29,  8.72s/it] 22%|██▏       | 22/100 [03:12<11:20,  8.72s/it] 23%|██▎       | 23/100 [03:21<11:11,  8.72s/it] 24%|██▍       | 24/100 [03:29<11:01,  8.71s/it] 25%|██▌       | 25/100 [03:38<10:53,  8.71s/it] 26%|██▌       | 26/100 [03:47<10:44,  8.71s/it] 27%|██▋       | 27/100 [03:55<10:36,  8.72s/it] 28%|██▊       | 28/100 [04:04<10:28,  8.72s/it] 29%|██▉       | 29/100 [04:13<10:19,  8.72s/it] 30%|███       | 30/100 [04:22<10:10,  8.72s/it] 31%|███       | 31/100 [04:30<10:01,  8.71s/it] 32%|███▏      | 32/100 [04:39<09:52,  8.71s/it] 33%|███▎      | 33/100 [04:48<09:48,  8.79s/it] 34%|███▍      | 34/100 [04:57<09:38,  8.76s/it] 35%|███▌      | 35/100 [05:05<09:28,  8.75s/it] 36%|███▌      | 36/100 [05:14<09:19,  8.74s/it] 37%|███▋      | 37/100 [05:23<09:10,  8.74s/it] 38%|███▊      | 38/100 [05:32<09:01,  8.74s/it] 39%|███▉      | 39/100 [05:40<08:52,  8.73s/it] 40%|████      | 40/100 [05:49<08:43,  8.72s/it] 41%|████      | 41/100 [05:58<08:33,  8.71s/it] 42%|████▏     | 42/100 [06:06<08:24,  8.70s/it] 43%|████▎     | 43/100 [06:15<08:17,  8.73s/it] 44%|████▍     | 44/100 [06:24<08:08,  8.72s/it] 45%|████▌     | 45/100 [06:33<07:59,  8.71s/it] 46%|████▌     | 46/100 [06:41<07:51,  8.73s/it] 47%|████▋     | 47/100 [06:50<07:42,  8.73s/it] 48%|████▊     | 48/100 [06:59<07:33,  8.72s/it] 49%|████▉     | 49/100 [07:07<07:24,  8.71s/it] 50%|█████     | 50/100 [07:16<07:15,  8.71s/it] 51%|█████     | 51/100 [07:25<07:06,  8.71s/it] 52%|█████▏    | 52/100 [07:34<06:59,  8.75s/it] 53%|█████▎    | 53/100 [07:42<06:50,  8.73s/it] 54%|█████▍    | 54/100 [07:51<06:40,  8.72s/it] 55%|█████▌    | 55/100 [08:00<06:35,  8.79s/it] 56%|█████▌    | 56/100 [08:09<06:25,  8.76s/it] 57%|█████▋    | 57/100 [08:17<06:15,  8.74s/it] 58%|█████▊    | 58/100 [08:26<06:06,  8.73s/it] 59%|█████▉    | 59/100 [08:35<05:57,  8.73s/it] 60%|██████    | 60/100 [08:44<05:48,  8.72s/it] 61%|██████    | 61/100 [08:52<05:40,  8.72s/it] 62%|██████▏   | 62/100 [09:01<05:31,  8.72s/it] 63%|██████▎   | 63/100 [09:10<05:22,  8.71s/it] 64%|██████▍   | 64/100 [09:18<05:13,  8.71s/it] 65%|██████▌   | 65/100 [09:27<05:04,  8.70s/it] 66%|██████▌   | 66/100 [09:36<04:56,  8.71s/it] 67%|██████▋   | 67/100 [09:45<04:47,  8.72s/it] 68%|██████▊   | 68/100 [09:53<04:39,  8.73s/it] 69%|██████▉   | 69/100 [10:02<04:30,  8.72s/it] 70%|███████   | 70/100 [10:11<04:21,  8.72s/it] 71%|███████   | 71/100 [10:19<04:12,  8.72s/it] 72%|███████▏  | 72/100 [10:28<04:04,  8.72s/it] 73%|███████▎  | 73/100 [10:37<03:55,  8.72s/it] 74%|███████▍  | 74/100 [10:46<03:46,  8.72s/it] 75%|███████▌  | 75/100 [10:54<03:38,  8.72s/it] 76%|███████▌  | 76/100 [11:03<03:31,  8.80s/it] 77%|███████▋  | 77/100 [11:12<03:21,  8.77s/it] 78%|███████▊  | 78/100 [11:21<03:12,  8.75s/it] 79%|███████▉  | 79/100 [11:29<03:03,  8.73s/it] 80%|████████  | 80/100 [11:38<02:54,  8.72s/it] 81%|████████  | 81/100 [11:47<02:45,  8.72s/it] 82%|████████▏ | 82/100 [11:56<02:36,  8.71s/it] 83%|████████▎ | 83/100 [12:04<02:28,  8.71s/it] 84%|████████▍ | 84/100 [12:13<02:19,  8.71s/it] 85%|████████▌ | 85/100 [12:22<02:10,  8.70s/it] 86%|████████▌ | 86/100 [12:30<02:01,  8.70s/it] 87%|████████▋ | 87/100 [12:39<01:52,  8.69s/it] 88%|████████▊ | 88/100 [12:48<01:44,  8.69s/it] 89%|████████▉ | 89/100 [12:56<01:35,  8.69s/it] 90%|█████████ | 90/100 [13:05<01:26,  8.69s/it] 91%|█████████ | 91/100 [13:14<01:18,  8.70s/it] 92%|█████████▏| 92/100 [13:22<01:09,  8.70s/it] 93%|█████████▎| 93/100 [13:31<01:00,  8.70s/it] 94%|█████████▍| 94/100 [13:40<00:52,  8.73s/it] 95%|█████████▌| 95/100 [13:49<00:43,  8.72s/it] 96%|█████████▌| 96/100 [13:57<00:34,  8.72s/it] 97%|█████████▋| 97/100 [14:06<00:26,  8.71s/it] 98%|█████████▊| 98/100 [14:15<00:17,  8.79s/it] 99%|█████████▉| 99/100 [14:24<00:08,  8.77s/it]100%|██████████| 100/100 [14:32<00:00,  8.75s/it]100%|██████████| 100/100 [14:32<00:00,  8.73s/it]
