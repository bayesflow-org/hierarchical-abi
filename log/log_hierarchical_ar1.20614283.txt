WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/metrics/posterior_contraction.py:59: RuntimeWarning: Degrees of freedom <= 0 for slice
  post_vars = samples["estimates"].var(axis=1, ddof=1)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in divide
  ret = um.true_divide(
Exp: 9 Model: 9 mini_batch
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    2304    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    2304    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    768     |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 268803
ar1_9_1global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    2560    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    2560    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    256     |
|     final_projection_linear.bias     |     1      |
+--------------------------------------+------------+
Total Trainable Params: 268801
ar1_9_1local_score_model_v_variance_preserving_cosine_likelihood_weighting
+---------------------------------------------------+------------+
|                      Modules                      | Parameters |
+---------------------------------------------------+------------+
|   global_model.blocks.res_blocks.0.dense.weight   |    2304    |
|    global_model.blocks.res_blocks.0.dense.bias    |    256     |
| global_model.blocks.res_blocks.0.projector.weight |    2304    |
|   global_model.blocks.res_blocks.1.dense.weight   |   65536    |
|    global_model.blocks.res_blocks.1.dense.bias    |    256     |
|   global_model.blocks.res_blocks.2.dense.weight   |   65536    |
|    global_model.blocks.res_blocks.2.dense.bias    |    256     |
|   global_model.blocks.res_blocks.3.dense.weight   |   65536    |
|    global_model.blocks.res_blocks.3.dense.bias    |    256     |
|   global_model.blocks.res_blocks.4.dense.weight   |   65536    |
|    global_model.blocks.res_blocks.4.dense.bias    |    256     |
|    global_model.final_projection_linear.weight    |    768     |
|     global_model.final_projection_linear.bias     |     3      |
|    local_model.blocks.res_blocks.0.dense.weight   |    2560    |
|     local_model.blocks.res_blocks.0.dense.bias    |    256     |
|  local_model.blocks.res_blocks.0.projector.weight |    2560    |
|    local_model.blocks.res_blocks.1.dense.weight   |   65536    |
|     local_model.blocks.res_blocks.1.dense.bias    |    256     |
|    local_model.blocks.res_blocks.2.dense.weight   |   65536    |
|     local_model.blocks.res_blocks.2.dense.bias    |    256     |
|    local_model.blocks.res_blocks.3.dense.weight   |   65536    |
|     local_model.blocks.res_blocks.3.dense.bias    |    256     |
|    local_model.blocks.res_blocks.4.dense.weight   |   65536    |
|     local_model.blocks.res_blocks.4.dense.bias    |    256     |
|     local_model.final_projection_linear.weight    |    256     |
|      local_model.final_projection_linear.bias     |     1      |
+---------------------------------------------------+------------+
Total Trainable Params: 537604
ar1_9_1hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
Model loaded
mini_batch
Data Size: 16, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
Finished after 10000 steps (20000 score evals) at time 0.8935651779174805.
Mean step size: 1.064862292888568e-05, min: 3.0332637379615335e-07, max: 0.00012277861242182553
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
global shapes (100, 4, 3) (100, 3)
local shapes (100, 4, 16) (100, 16)
Data Size: 16, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
Finished after 10000 steps (20000 score evals) at time 0.575289249420166.
Mean step size: 4.248385845873868e-05, min: 9.779226957107312e-07, max: 0.0007048454717732966
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
global shapes (100, 3, 3) (100, 3)
local shapes (100, 3, 16) (100, 16)
Data Size: 16, Mini Batch: None, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
applying summary network to observations before sampling, might take a while...
Finished after 10000 steps (20000 score evals) at time 0.3365853428840637.
Mean step size: 6.63609965485314e-05, min: 8.876409083313774e-07, max: 0.001976863481104374
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
max steps reached
global shapes (100, 1, 3) (100, 3)
local shapes (100, 1, 16) (100, 16)
Data Size: 256, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
Finished after 10000 steps (20000 score evals) at time 0.7063658833503723.
Mean step size: 2.9375085631727508e-05, min: 9.932981583915534e-07, max: 0.00010739116260083392
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
max steps reached
global shapes (100, 1, 3) (100, 3)
local shapes (100, 1, 256) (100, 256)
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
Data Size: 4096, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
Finished after 10000 steps (20000 score evals) at time 0.9960649013519287.
Mean step size: 3.941129759110964e-07, min: 5.975900307930715e-08, max: 1.7777630318960291e-06
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
max steps reached
global shapes (100, 1, 3) (100, 3)
local shapes (100, 1, 4096) (100, 4096)
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
Data Size: 16384, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
global sampling
Finished after 10000 steps (20000 score evals) at time 0.9996446371078491.
Mean step size: 3.460376895927333e-08, min: 1.622452749927561e-08, max: 8.318978217403128e-08
maximum steps reached, increase number of steps.
local sampling
applying summary network to observations before sampling, might take a while...
max steps reached
global shapes (100, 1, 3) (100, 3)
local shapes (100, 1, 16384) (100, 16384)
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 0
