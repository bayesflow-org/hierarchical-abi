
The following have been reloaded with a version change:
  1) linux-rocky8-x86_64/gcc/12.2.0/libxml2/2.10.3-h6soa57 => linux-rocky8-x86_64/gcc/12.2.0/libxml2/2.10.3-w7ngxar
  2) linux-rocky8-x86_64/gcc/12.2.0/xz/5.4.1-cqof5qs => linux-rocky8-x86_64/gcc/12.2.0/xz/5.4.1-c5gajon

WARNING:bayesflow:When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use
with torch.enable_grad():
in contexts where you need gradients (e.g. custom training loops).
/home/jonas/hierarchical-abi/.venv/lib/python3.11/site-packages/bayesflow/diagnostics/metrics/posterior_contraction.py:59: RuntimeWarning: Degrees of freedom <= 0 for slice
  post_vars = samples["estimates"].var(axis=1, ddof=1)
/home/jonas/hierarchical-abi/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in divide
  ret = um.true_divide(
Exp: 15 Model: 5 cosine_shift
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
Moving prior to device: cpu
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|        time_embedding.0.scale        |     1      |
|       time_embedding.1.weight        |     64     |
|        time_embedding.1.bias         |     8      |
|   blocks.res_blocks.0.dense.weight   |    7168    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    7168    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    2560    |
|     final_projection_linear.bias     |     10     |
+--------------------------------------+------------+
Total Trainable Params: 280403
gaussian_flat5_1score_model_v_variance_preserving_cosine_likelihood_weighting
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
Moving prior to device: cuda:0
KL: 129.72602516712934, #Steps: 54.04
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: -1, Damping Factor: 1
KL: 169.267265837647, #Steps: 48.15
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 1, Damping Factor: 1
KL: 123.3806103490396, #Steps: 56.57
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 69.27461693050316, #Steps: 63.95
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 15.333400259034404, #Steps: 37.64
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 8.911173620785, #Steps: 9.15
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 1
KL: 7.698389296547426, #Steps: 654.31
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: -1, Damping Factor: 1
KL: 7.943678398700758, #Steps: 690.04
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 1, Damping Factor: 1
KL: 7.297335536736253, #Steps: 599.07
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 6.760022796327885, #Steps: 527.09
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 6.505467369512354, #Steps: 275.91
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 6.521088211610355, #Steps: 11.36
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 1
KL: 23.65260982774365, #Steps: 5160.93
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: -1, Damping Factor: 1
KL: 22.314670400898322, #Steps: 5393.94
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 1, Damping Factor: 1
KL: 23.573598982901345, #Steps: 4764.87
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 23.4078581969675, #Steps: 4235.78
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 21.91483252372255, #Steps: 2244.88
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 20.217680696809143, #Steps: 24.94
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.998845636844635.
Mean step size: 1.1788874802157339e-07, min: 4.31172715309458e-08, max: 2.6077373149746563e-07
maximum steps reached, not computing any more posterior samples.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: -1, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9988433122634888.
Mean step size: 1.1803378515646158e-07, min: 4.018736277089374e-08, max: 2.6459025548319914e-07
maximum steps reached, not computing any more posterior samples.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 1, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9988498091697693.
Mean step size: 1.177319491881376e-07, min: 4.4781774732882695e-08, max: 2.794692761654005e-07
maximum steps reached, not computing any more posterior samples.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 2, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9988423585891724.
Mean step size: 1.1781651314940324e-07, min: 4.254451013707694e-08, max: 2.856433525266766e-07
maximum steps reached, not computing any more posterior samples.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 5, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9984635710716248.
Mean step size: 1.6766189099516785e-07, min: 1.9855686872460865e-08, max: 1.5581325669700163e-06
maximum steps reached, not computing any more posterior samples.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 82.41882415064534, #Steps: 163.41
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, -1
smaller mini batch size already failed, skipping 1, 1
smaller mini batch size already failed, skipping 1, 2
smaller mini batch size already failed, skipping 1, 5
Data Size: 100000, Mini Batch: 10000, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 266.00574117867257, #Steps: 1826.51
