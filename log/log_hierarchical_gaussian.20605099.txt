WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/metrics/posterior_contraction.py:59: RuntimeWarning: Degrees of freedom <= 0 for slice
  post_vars = samples["estimates"].var(axis=1, ddof=1)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in divide
  ret = um.true_divide(
Exp: 17 Model: 7 cosine_shift
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    5376    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    5376    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    2560    |
|     final_projection_linear.bias     |     10     |
+--------------------------------------+------------+
Total Trainable Params: 276746
gaussian_flat7_1score_model_v_variance_preserving_cosine_likelihood_weighting
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1
KL: 128.5173428626372, #Steps: 148.62
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 73.56357160531638, #Steps: 231.47
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 17.64314409038587, #Steps: 52.47
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 5.3804495091381375, #Steps: 9.37
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 1
KL: 16.38246843607974, #Steps: 1133.85
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 35.909159136378406, #Steps: 989.08
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 156.85777937879539, #Steps: 722.82
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 123.20518631031096, #Steps: 10.26
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 1
KL: 900.4128547078658, #Steps: 6444.9
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 2, Damping Factor: 1
KL: 968.3068366998672, #Steps: 5491.08
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 5, Damping Factor: 1
KL: 1285.6090792181194, #Steps: 3347.37
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 10, Damping Factor: 1
KL: 1764.3094142288035, #Steps: 25.25
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.998846709728241.
Mean step size: 1.1781265697577118e-07, min: 4.275620213434195e-08, max: 2.594983641301951e-07
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 2, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9988448023796082.
Mean step size: 1.1751599345652246e-07, min: 4.0274429125020106e-08, max: 3.243064554681041e-07
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 5, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.9977062344551086.
Mean step size: 2.2981475529262345e-07, min: 1.6735842933712775e-08, max: 9.74956719801412e-07
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 10, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.3711252510547638.
Mean step size: 0.0001247521321550671, min: 1.4025091843450355e-07, max: 0.10611529648303986
maximum steps reached, increase number of steps.
KL: 17960.571687758038, #Steps: 581.6
smaller mini batch size already failed, skipping 1, 0
smaller mini batch size already failed, skipping 1, 2
smaller mini batch size already failed, skipping 1, 5
Data Size: 100000, Mini Batch: 10000, Conditions: 1, Cosine shift: 10, Damping Factor: 1
Finished after 10000 steps (20000 score evals) at time 0.7152359485626221.
Mean step size: 5.5509768023878395e-05, min: 1.1530094212730546e-08, max: 0.0031715831719338894
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
