WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:288: RuntimeWarning: overflow encountered in exp
  tau = np.exp(log_tau)
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:289: RuntimeWarning: overflow encountered in exp
  tau_2 = tau + np.exp(log_delta_tau)
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    6144    |
|    blocks.res_blocks.0.dense.bias    |    512     |
| blocks.res_blocks.0.projector.weight |    6144    |
|   blocks.res_blocks.1.dense.weight   |   262144   |
|    blocks.res_blocks.1.dense.bias    |    512     |
|   blocks.res_blocks.2.dense.weight   |   262144   |
|    blocks.res_blocks.2.dense.bias    |    512     |
|   blocks.res_blocks.3.dense.weight   |   262144   |
|    blocks.res_blocks.3.dense.bias    |    512     |
|   blocks.res_blocks.4.dense.weight   |   262144   |
|    blocks.res_blocks.4.dense.bias    |    512     |
|    final_projection_linear.weight    |    3072    |
|     final_projection_linear.bias     |     6      |
+--------------------------------------+------------+
Total Trainable Params: 1066502
FLI_1_10_512_5_split_TimeSeriesNetwork_global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    7680    |
|    blocks.res_blocks.0.dense.bias    |    512     |
| blocks.res_blocks.0.projector.weight |    7680    |
|   blocks.res_blocks.1.dense.weight   |   262144   |
|    blocks.res_blocks.1.dense.bias    |    512     |
|   blocks.res_blocks.2.dense.weight   |   262144   |
|    blocks.res_blocks.2.dense.bias    |    512     |
|   blocks.res_blocks.3.dense.weight   |   262144   |
|    blocks.res_blocks.3.dense.bias    |    512     |
|   blocks.res_blocks.4.dense.weight   |   262144   |
|    blocks.res_blocks.4.dense.bias    |    512     |
|    final_projection_linear.weight    |    1536    |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 1068035
FLI_1_10_512_5_split_TimeSeriesNetwork_local_score_model_v_variance_preserving_cosine_likelihood_weighting
+-----------------------------------------------------------+------------+
|                          Modules                          | Parameters |
+-----------------------------------------------------------+------------+
|              summary_net.conv_blocks.0.weight             |     96     |
|               summary_net.conv_blocks.0.bias              |     32     |
|           summary_net.recurrent.skip_conv.weight          |   16384    |
|            summary_net.recurrent.skip_conv.bias           |    128     |
|        summary_net.recurrent.recurrent.weight_ih_l0       |   12288    |
|        summary_net.recurrent.recurrent.weight_hh_l0       |   49152    |
|         summary_net.recurrent.recurrent.bias_ih_l0        |    384     |
|         summary_net.recurrent.recurrent.bias_hh_l0        |    384     |
|    summary_net.recurrent.recurrent.weight_ih_l0_reverse   |   12288    |
|    summary_net.recurrent.recurrent.weight_hh_l0_reverse   |   49152    |
|     summary_net.recurrent.recurrent.bias_ih_l0_reverse    |    384     |
|     summary_net.recurrent.recurrent.bias_hh_l0_reverse    |    384     |
|     summary_net.recurrent.skip_recurrent.weight_ih_l0     |   49152    |
|     summary_net.recurrent.skip_recurrent.weight_hh_l0     |   49152    |
|      summary_net.recurrent.skip_recurrent.bias_ih_l0      |    384     |
|      summary_net.recurrent.skip_recurrent.bias_hh_l0      |    384     |
| summary_net.recurrent.skip_recurrent.weight_ih_l0_reverse |   49152    |
| summary_net.recurrent.skip_recurrent.weight_hh_l0_reverse |   49152    |
|  summary_net.recurrent.skip_recurrent.bias_ih_l0_reverse  |    384     |
|  summary_net.recurrent.skip_recurrent.bias_hh_l0_reverse  |    384     |
|            summary_net.output_projector.weight            |    5120    |
|             summary_net.output_projector.bias             |     10     |
|       global_model.blocks.res_blocks.0.dense.weight       |    6144    |
|        global_model.blocks.res_blocks.0.dense.bias        |    512     |
|     global_model.blocks.res_blocks.0.projector.weight     |    6144    |
|       global_model.blocks.res_blocks.1.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.1.dense.bias        |    512     |
|       global_model.blocks.res_blocks.2.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.2.dense.bias        |    512     |
|       global_model.blocks.res_blocks.3.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.3.dense.bias        |    512     |
|       global_model.blocks.res_blocks.4.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.4.dense.bias        |    512     |
|        global_model.final_projection_linear.weight        |    3072    |
|         global_model.final_projection_linear.bias         |     6      |
|        local_model.blocks.res_blocks.0.dense.weight       |    7680    |
|         local_model.blocks.res_blocks.0.dense.bias        |    512     |
|      local_model.blocks.res_blocks.0.projector.weight     |    7680    |
|        local_model.blocks.res_blocks.1.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.1.dense.bias        |    512     |
|        local_model.blocks.res_blocks.2.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.2.dense.bias        |    512     |
|        local_model.blocks.res_blocks.3.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.3.dense.bias        |    512     |
|        local_model.blocks.res_blocks.4.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.4.dense.bias        |    512     |
|         local_model.final_projection_linear.weight        |    1536    |
|          local_model.final_projection_linear.bias         |     3      |
+-----------------------------------------------------------+------------+
Total Trainable Params: 2478867
FLI_1_10_512_5_split_TimeSeriesNetwork_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
torch.Size([100, 1024, 256, 1]) 1
applying summary network to observations before sampling, might take a while...
applying summary network to observations before sampling, might take a while...
Traceback (most recent call last):
  File "/home/jarruda_hpc/hierarchical-abi/fli score matching.py", line 242, in <module>
    fig = diagnostics.pairs_posterior(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_posterior.py", line 91, in pairs_posterior
    g = _pairs_samples(
        ^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_samples.py", line 129, in _pairs_samples
    g.map_diag(
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py", line 1485, in map_diag
    return self._map_diag_iter_hue(func, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py", line 1552, in _map_diag_iter_hue
    func(data_k, label=label_k, color=color, **plot_kwargs)
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_samples.py", line 187, in histplot_twinx
    sns.histplot(x, **kwargs, ax=ax2)
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/distributions.py", line 1416, in histplot
    p.plot_univariate_histogram(
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/distributions.py", line 470, in plot_univariate_histogram
    bin_kws = estimator._define_bin_params(sub_data, orient, None)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/_stats/counting.py", line 152, in _define_bin_params
    bin_edges = self._define_bin_edges(
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/_stats/counting.py", line 137, in _define_bin_edges
    bin_edges = np.histogram_bin_edges(vals, bins, binrange, weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/lib/histograms.py", line 669, in histogram_bin_edges
    bin_edges, _ = _get_bin_edges(a, bins, range, weights)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/lib/histograms.py", line 446, in _get_bin_edges
    bin_edges = np.linspace(
                ^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/function_base.py", line 140, in linspace
    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 302. TiB for an array with shape (41539264447042,) and data type float64
