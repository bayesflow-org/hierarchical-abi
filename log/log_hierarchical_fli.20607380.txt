WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/hierarchical-abi/problems/plotting_helper.py:97: RuntimeWarning: overflow encountered in exp
  global_ci = [global_mean_est-1.96*np.mean(np.exp(global_samples[i, :, 1])),
/home/jarruda_hpc/hierarchical-abi/problems/plotting_helper.py:98: RuntimeWarning: overflow encountered in exp
  global_mean_est+1.96*np.mean(np.exp(global_samples[i, :, 1]))]
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |   19968    |
|    blocks.res_blocks.0.dense.bias    |    512     |
| blocks.res_blocks.0.projector.weight |   19968    |
|   blocks.res_blocks.1.dense.weight   |   262144   |
|    blocks.res_blocks.1.dense.bias    |    512     |
|   blocks.res_blocks.2.dense.weight   |   262144   |
|    blocks.res_blocks.2.dense.bias    |    512     |
|   blocks.res_blocks.3.dense.weight   |   262144   |
|    blocks.res_blocks.3.dense.bias    |    512     |
|   blocks.res_blocks.4.dense.weight   |   262144   |
|    blocks.res_blocks.4.dense.bias    |    512     |
|   blocks.res_blocks.5.dense.weight   |   262144   |
|    blocks.res_blocks.5.dense.bias    |    512     |
|    final_projection_linear.weight    |    3072    |
|     final_projection_linear.bias     |     6      |
+--------------------------------------+------------+
Total Trainable Params: 1356806
FLI_1_32_512_6_TimeSeriesNetwork_global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |   21504    |
|    blocks.res_blocks.0.dense.bias    |    512     |
| blocks.res_blocks.0.projector.weight |   21504    |
|   blocks.res_blocks.1.dense.weight   |   262144   |
|    blocks.res_blocks.1.dense.bias    |    512     |
|   blocks.res_blocks.2.dense.weight   |   262144   |
|    blocks.res_blocks.2.dense.bias    |    512     |
|   blocks.res_blocks.3.dense.weight   |   262144   |
|    blocks.res_blocks.3.dense.bias    |    512     |
|   blocks.res_blocks.4.dense.weight   |   262144   |
|    blocks.res_blocks.4.dense.bias    |    512     |
|   blocks.res_blocks.5.dense.weight   |   262144   |
|    blocks.res_blocks.5.dense.bias    |    512     |
|    final_projection_linear.weight    |    1536    |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 1358339
FLI_1_32_512_6_TimeSeriesNetwork_local_score_model_v_variance_preserving_cosine_likelihood_weighting
+-----------------------------------------------------------+------------+
|                          Modules                          | Parameters |
+-----------------------------------------------------------+------------+
|              summary_net.conv_blocks.0.weight             |     96     |
|               summary_net.conv_blocks.0.bias              |     32     |
|           summary_net.recurrent.skip_conv.weight          |   16384    |
|            summary_net.recurrent.skip_conv.bias           |    128     |
|        summary_net.recurrent.recurrent.weight_ih_l0       |   12288    |
|        summary_net.recurrent.recurrent.weight_hh_l0       |   49152    |
|         summary_net.recurrent.recurrent.bias_ih_l0        |    384     |
|         summary_net.recurrent.recurrent.bias_hh_l0        |    384     |
|    summary_net.recurrent.recurrent.weight_ih_l0_reverse   |   12288    |
|    summary_net.recurrent.recurrent.weight_hh_l0_reverse   |   49152    |
|     summary_net.recurrent.recurrent.bias_ih_l0_reverse    |    384     |
|     summary_net.recurrent.recurrent.bias_hh_l0_reverse    |    384     |
|     summary_net.recurrent.skip_recurrent.weight_ih_l0     |   49152    |
|     summary_net.recurrent.skip_recurrent.weight_hh_l0     |   49152    |
|      summary_net.recurrent.skip_recurrent.bias_ih_l0      |    384     |
|      summary_net.recurrent.skip_recurrent.bias_hh_l0      |    384     |
| summary_net.recurrent.skip_recurrent.weight_ih_l0_reverse |   49152    |
| summary_net.recurrent.skip_recurrent.weight_hh_l0_reverse |   49152    |
|  summary_net.recurrent.skip_recurrent.bias_ih_l0_reverse  |    384     |
|  summary_net.recurrent.skip_recurrent.bias_hh_l0_reverse  |    384     |
|            summary_net.output_projector.weight            |   16384    |
|             summary_net.output_projector.bias             |     32     |
|       global_model.blocks.res_blocks.0.dense.weight       |   19968    |
|        global_model.blocks.res_blocks.0.dense.bias        |    512     |
|     global_model.blocks.res_blocks.0.projector.weight     |   19968    |
|       global_model.blocks.res_blocks.1.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.1.dense.bias        |    512     |
|       global_model.blocks.res_blocks.2.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.2.dense.bias        |    512     |
|       global_model.blocks.res_blocks.3.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.3.dense.bias        |    512     |
|       global_model.blocks.res_blocks.4.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.4.dense.bias        |    512     |
|       global_model.blocks.res_blocks.5.dense.weight       |   262144   |
|        global_model.blocks.res_blocks.5.dense.bias        |    512     |
|        global_model.final_projection_linear.weight        |    3072    |
|         global_model.final_projection_linear.bias         |     6      |
|        local_model.blocks.res_blocks.0.dense.weight       |   21504    |
|         local_model.blocks.res_blocks.0.dense.bias        |    512     |
|      local_model.blocks.res_blocks.0.projector.weight     |   21504    |
|        local_model.blocks.res_blocks.1.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.1.dense.bias        |    512     |
|        local_model.blocks.res_blocks.2.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.2.dense.bias        |    512     |
|        local_model.blocks.res_blocks.3.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.3.dense.bias        |    512     |
|        local_model.blocks.res_blocks.4.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.4.dense.bias        |    512     |
|        local_model.blocks.res_blocks.5.dense.weight       |   262144   |
|         local_model.blocks.res_blocks.5.dense.bias        |    512     |
|         local_model.final_projection_linear.weight        |    1536    |
|          local_model.final_projection_linear.bias         |     3      |
+-----------------------------------------------------------+------------+
Total Trainable Params: 3070761
FLI_1_32_512_6_TimeSeriesNetwork_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
torch.Size([100, 1024, 256, 1]) 1
NaNs in theta at time 0.07300000637769699 with step size: tensor(0.0010, device='cuda:0')
NaNs in theta at time 1.0 with step size: tensor(0.0050, device='cuda:0')
Global Estimates
mu: -6.9392743e+31 inf
log sigma: -0.18657485 inf
True
mu: -0.9243212938308716
log sigma: 0.1204466000199318
