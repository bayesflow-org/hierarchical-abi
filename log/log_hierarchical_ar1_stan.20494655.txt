WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
[I 2025-04-22 11:29:39,086] A new study created in memory with name: no-name-394e3278-7a8b-4d22-9a48-2709f2efd5d5
/var/spool/slurmd/job20494655/slurm_script: line 23: 3919314 Killed                  python3.11 /home/jarruda_hpc/hierarchical-abi/ar\(1\)_score_matching.py 1
slurmstepd: error: Detected 1 oom_kill event in StepId=20494655.batch. Some of the step tasks have been OOM Killed.
