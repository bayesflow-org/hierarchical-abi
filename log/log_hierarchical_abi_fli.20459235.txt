WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
slurmstepd: error: *** JOB 20459235 ON mlgpu012 CANCELLED AT 2025-04-19T14:04:08 DUE TO TIME LIMIT ***
