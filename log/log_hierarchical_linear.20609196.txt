WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/metrics/posterior_contraction.py:59: RuntimeWarning: Degrees of freedom <= 0 for slice
  post_vars = samples["estimates"].var(axis=1, ddof=1)
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in divide
  ret = um.true_divide(
Exp: 28 Model: 8 damping_factor_t
Kernel type: variance_preserving, noise schedule: linear
t_min: 0.0005980199202895164, t_max: 3.872983455657959
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    5376    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    5376    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    2560    |
|     final_projection_linear.bias     |     10     |
+--------------------------------------+------------+
Total Trainable Params: 276746
gaussian_flat8_1score_model_v_variance_preserving_linear_likelihood_weighting
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1e-05
KL: 169.75552113025347, #Steps: 97.65
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 0.01
KL: 106.21211151193728, #Steps: 23.11
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 0.1
KL: 1.844222888703851, #Steps: 57.85
Data Size: 10, Mini Batch: 1, Conditions: 1, Cosine shift: 0, Damping Factor: 1.0
KL: 1.4728271386371632, #Steps: 347.58
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 1e-05
KL: 29.744236578261933, #Steps: 303.66
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 0.01
KL: 14.966230785648545, #Steps: 100.17
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 0.1
KL: 16.759035346026877, #Steps: 652.81
Data Size: 100, Mini Batch: 10, Conditions: 1, Cosine shift: 0, Damping Factor: 1.0
KL: 18.220270481449266, #Steps: 1027.9
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 1e-05
KL: 60.399271795085994, #Steps: 581.25
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 0.01
KL: 1694.6688297155008, #Steps: 367.19
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 0.1
KL: 1629.3610458279709, #Steps: 771.51
Data Size: 1000, Mini Batch: 100, Conditions: 1, Cosine shift: 0, Damping Factor: 1.0
KL: 1684.3740762646153, #Steps: 5271.74
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 1e-05
KL: 38753.33837307521, #Steps: 928.21
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 0.01
KL: 33014.66298799843, #Steps: 2217.02
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 0.1
KL: 40711.12410237398, #Steps: 4800.8
Data Size: 10000, Mini Batch: 1000, Conditions: 1, Cosine shift: 0, Damping Factor: 1.0
Finished after 10000 steps (20000 score evals) at time 0.8883364200592041.
Mean step size: 1.1167359902634826e-05, min: 8.499334398948122e-06, max: 6.666161789325997e-05
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 100000, Mini Batch: 10000, Conditions: 1, Cosine shift: 0, Damping Factor: 1e-05
Finished after 10000 steps (20000 score evals) at time 0.001099534216336906.
Mean step size: 0.00016876172441255175, min: 4.4573975621631234e-09, max: 0.5
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 100000, Mini Batch: 10000, Conditions: 1, Cosine shift: 0, Damping Factor: 0.01
Finished after 10000 steps (20000 score evals) at time 0.005033935885876417.
Mean step size: 0.00010669885467243313, min: 1.2911564262196862e-08, max: 0.043580785393714905
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
Data Size: 100000, Mini Batch: 10000, Conditions: 1, Cosine shift: 0, Damping Factor: 0.1
Finished after 10000 steps (20000 score evals) at time 0.46173176169395447.
Mean step size: 5.5480016383031315e-05, min: 6.8893095885869116e-06, max: 0.0002850467280950397
maximum steps reached, increase number of steps.
KL: nan, #Steps: 10000.0
smaller mini batch size already failed, skipping 1, 0
