WARNING:bayesflow:
When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use

with torch.enable_grad():
    ...

in contexts where you need gradients (e.g. custom training loops).
/home/jarruda_hpc/hierarchical-abi/problems/plotting_helper.py:97: RuntimeWarning: overflow encountered in exp
  global_ci = [global_mean_est-1.96*np.mean(np.exp(global_samples[i, :, 1])),
/home/jarruda_hpc/hierarchical-abi/problems/plotting_helper.py:98: RuntimeWarning: overflow encountered in exp
  global_mean_est+1.96*np.mean(np.exp(global_samples[i, :, 1]))]
/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:288: RuntimeWarning: overflow encountered in exp
  tau = np.exp(log_tau)
/home/jarruda_hpc/hierarchical-abi/problems/fli.py:289: RuntimeWarning: overflow encountered in exp
  tau_2 = tau + np.exp(log_delta_tau)
Kernel type: variance_preserving, noise schedule: cosine
t_min: 0.00035210439818911254, t_max: 0.999647855758667
alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    3584    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    3584    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    1536    |
|     final_projection_linear.bias     |     6      |
+--------------------------------------+------------+
Total Trainable Params: 272134
FLI_1_14_256_5_split_TimeSeriesNetwork_global_score_model_v_variance_preserving_cosine_likelihood_weighting
+--------------------------------------+------------+
|               Modules                | Parameters |
+--------------------------------------+------------+
|   blocks.res_blocks.0.dense.weight   |    4352    |
|    blocks.res_blocks.0.dense.bias    |    256     |
| blocks.res_blocks.0.projector.weight |    4352    |
|   blocks.res_blocks.1.dense.weight   |   65536    |
|    blocks.res_blocks.1.dense.bias    |    256     |
|   blocks.res_blocks.2.dense.weight   |   65536    |
|    blocks.res_blocks.2.dense.bias    |    256     |
|   blocks.res_blocks.3.dense.weight   |   65536    |
|    blocks.res_blocks.3.dense.bias    |    256     |
|   blocks.res_blocks.4.dense.weight   |   65536    |
|    blocks.res_blocks.4.dense.bias    |    256     |
|    final_projection_linear.weight    |    768     |
|     final_projection_linear.bias     |     3      |
+--------------------------------------+------------+
Total Trainable Params: 272899
FLI_1_14_256_5_split_TimeSeriesNetwork_local_score_model_v_variance_preserving_cosine_likelihood_weighting
+-----------------------------------------------------------+------------+
|                          Modules                          | Parameters |
+-----------------------------------------------------------+------------+
|              summary_net.conv_blocks.0.weight             |     96     |
|               summary_net.conv_blocks.0.bias              |     32     |
|           summary_net.recurrent.skip_conv.weight          |   16384    |
|            summary_net.recurrent.skip_conv.bias           |    128     |
|        summary_net.recurrent.recurrent.weight_ih_l0       |   12288    |
|        summary_net.recurrent.recurrent.weight_hh_l0       |   49152    |
|         summary_net.recurrent.recurrent.bias_ih_l0        |    384     |
|         summary_net.recurrent.recurrent.bias_hh_l0        |    384     |
|    summary_net.recurrent.recurrent.weight_ih_l0_reverse   |   12288    |
|    summary_net.recurrent.recurrent.weight_hh_l0_reverse   |   49152    |
|     summary_net.recurrent.recurrent.bias_ih_l0_reverse    |    384     |
|     summary_net.recurrent.recurrent.bias_hh_l0_reverse    |    384     |
|     summary_net.recurrent.skip_recurrent.weight_ih_l0     |   49152    |
|     summary_net.recurrent.skip_recurrent.weight_hh_l0     |   49152    |
|      summary_net.recurrent.skip_recurrent.bias_ih_l0      |    384     |
|      summary_net.recurrent.skip_recurrent.bias_hh_l0      |    384     |
| summary_net.recurrent.skip_recurrent.weight_ih_l0_reverse |   49152    |
| summary_net.recurrent.skip_recurrent.weight_hh_l0_reverse |   49152    |
|  summary_net.recurrent.skip_recurrent.bias_ih_l0_reverse  |    384     |
|  summary_net.recurrent.skip_recurrent.bias_hh_l0_reverse  |    384     |
|            summary_net.output_projector.weight            |    7168    |
|             summary_net.output_projector.bias             |     14     |
|       global_model.blocks.res_blocks.0.dense.weight       |    3584    |
|        global_model.blocks.res_blocks.0.dense.bias        |    256     |
|     global_model.blocks.res_blocks.0.projector.weight     |    3584    |
|       global_model.blocks.res_blocks.1.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.1.dense.bias        |    256     |
|       global_model.blocks.res_blocks.2.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.2.dense.bias        |    256     |
|       global_model.blocks.res_blocks.3.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.3.dense.bias        |    256     |
|       global_model.blocks.res_blocks.4.dense.weight       |   65536    |
|        global_model.blocks.res_blocks.4.dense.bias        |    256     |
|        global_model.final_projection_linear.weight        |    1536    |
|         global_model.final_projection_linear.bias         |     6      |
|        local_model.blocks.res_blocks.0.dense.weight       |    4352    |
|         local_model.blocks.res_blocks.0.dense.bias        |    256     |
|      local_model.blocks.res_blocks.0.projector.weight     |    4352    |
|        local_model.blocks.res_blocks.1.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.1.dense.bias        |    256     |
|        local_model.blocks.res_blocks.2.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.2.dense.bias        |    256     |
|        local_model.blocks.res_blocks.3.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.3.dense.bias        |    256     |
|        local_model.blocks.res_blocks.4.dense.weight       |   65536    |
|         local_model.blocks.res_blocks.4.dense.bias        |    256     |
|         local_model.final_projection_linear.weight        |    768     |
|          local_model.final_projection_linear.bias         |     3      |
+-----------------------------------------------------------+------------+
Total Trainable Params: 891415
FLI_1_14_256_5_split_TimeSeriesNetwork_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting
torch.Size([100, 1024, 256, 1]) 1
NaNs in theta at time 0.07300000637769699 with step size: tensor(0.0010, device='cuda:0')
NaNs in theta at time 1.0 with step size: tensor(0.0050, device='cuda:0')
Global Estimates
mu: -1.2056491 0.033229128
log sigma: -0.089083225 0.024875073
True
mu: -0.9243212938308716
log sigma: 0.1204466000199318
NaNs in theta at time 0.007000000216066837 with step size: tensor(0.0010, device='cuda:0')
Traceback (most recent call last):
  File "/home/jarruda_hpc/hierarchical-abi/fli score matching.py", line 279, in <module>
    fig = diagnostics.pairs_posterior(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_posterior.py", line 91, in pairs_posterior
    g = _pairs_samples(
        ^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_samples.py", line 129, in _pairs_samples
    g.map_diag(
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py", line 1485, in map_diag
    return self._map_diag_iter_hue(func, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/axisgrid.py", line 1552, in _map_diag_iter_hue
    func(data_k, label=label_k, color=color, **plot_kwargs)
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/bayesflow/diagnostics/plots/pairs_samples.py", line 187, in histplot_twinx
    sns.histplot(x, **kwargs, ax=ax2)
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/distributions.py", line 1416, in histplot
    p.plot_univariate_histogram(
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/distributions.py", line 470, in plot_univariate_histogram
    bin_kws = estimator._define_bin_params(sub_data, orient, None)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/_stats/counting.py", line 152, in _define_bin_params
    bin_edges = self._define_bin_edges(
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/seaborn/_stats/counting.py", line 137, in _define_bin_edges
    bin_edges = np.histogram_bin_edges(vals, bins, binrange, weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/lib/histograms.py", line 669, in histogram_bin_edges
    bin_edges, _ = _get_bin_edges(a, bins, range, weights)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/lib/histograms.py", line 446, in _get_bin_edges
    bin_edges = np.linspace(
                ^^^^^^^^^^^^
  File "/home/jarruda_hpc/.conda/envs/habi/lib/python3.11/site-packages/numpy/core/function_base.py", line 140, in linspace
    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.
