{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FLI with compositional score matching\n",
   "id": "4f81f1b56f48a923"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "\n",
    "from bayesflow import diagnostics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import HierarchicalScoreModel, SDE, euler_maruyama_sampling, train_score_model\n",
    "from diffusion_model.helper_networks import ShallowSet\n",
    "from diffusion_model.time_series_summary_nets import TimeSeriesNetwork\n",
    "from problems.fli import FLIProblem, FLI_Prior, generate_synthetic_data\n",
    "from problems import plot_shrinkage, visualize_simulation_output"
   ],
   "id": "96ee56a8ec2f2e45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_device = torch.device(\"mps\")",
   "id": "6d4f87155d29abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prior = FLI_Prior()\n",
    "batch_size = 64\n",
    "number_of_obs = 1#[4]\n",
    "max_number_of_obs = number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs)\n",
    "\n",
    "current_sde = SDE(\n",
    "    kernel_type='variance_preserving',\n",
    "    noise_schedule='cosine'\n",
    ")\n",
    "\n",
    "dataset = FLIProblem(\n",
    "    n_data=20000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    online_learning=True,\n",
    "    number_of_obs=number_of_obs,\n",
    ")\n",
    "\n",
    "dataset_valid = FLIProblem(\n",
    "    n_data=1000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    number_of_obs=number_of_obs\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for test in dataloader:\n",
    "    print(test[0].shape)\n",
    "    print(test[2].shape)\n",
    "    print(test[4].shape)\n",
    "    break"
   ],
   "id": "5548aafbab738f25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "n_blocks = [5,6][0]\n",
    "hidden_dim = [256, 512][0]\n",
    "hidden_dim_summary = [10, 14, 18, 22, 32][0]\n",
    "split_summary_vector = [True, False][0]\n",
    "#n_blocks, hidden_dim, hidden_dim_summary, split_summary_vector = list(itertools.product(n_blocks, hidden_dim, hidden_dim_summary, split_summary_vector))[0]\n",
    "\n",
    "summary_net = TimeSeriesNetwork(input_dim=1, recurrent_dim=256, summary_dim=hidden_dim_summary)\n",
    "\n",
    "global_summary_dim = hidden_dim_summary\n",
    "global_summary_net = ShallowSet(dim_input=hidden_dim_summary, dim_output=global_summary_dim, dim_hidden=128)\n",
    "\n",
    "score_model = HierarchicalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_theta_local=prior.n_params_local,\n",
    "    input_dim_x_global=global_summary_dim,\n",
    "    input_dim_x_local=hidden_dim_summary,\n",
    "    summary_net=summary_net,\n",
    "    global_summary_net=global_summary_net if isinstance(number_of_obs, list) else None,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_blocks=n_blocks,\n",
    "    max_number_of_obs=max_number_of_obs,\n",
    "    prediction_type='v',\n",
    "    sde=current_sde,\n",
    "    weighting_type='likelihood_weighting',\n",
    "    prior=prior,\n",
    "    dropout_rate=0.1,\n",
    "    name_prefix=f'FLI_{max_number_of_obs}_{hidden_dim_summary}_{hidden_dim}_{n_blocks}{\"_split\" if split_summary_vector else \"\"}_{summary_net.name}_',\n",
    "    split_summary_vector=split_summary_vector\n",
    ")\n",
    "\n",
    "# make dir for plots\n",
    "if not os.path.exists(f\"plots/{score_model.name}\"):\n",
    "    os.makedirs(f\"plots/{score_model.name}\")"
   ],
   "id": "4f470346ef85a725",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(f\"models/{score_model.name}.pt\"):\n",
    "    # train model\n",
    "    loss_history = train_score_model(score_model, dataloader, dataloader_valid=dataloader_valid, hierarchical=True,\n",
    "                                                  epochs=3000, device=torch_device)\n",
    "    score_model.eval()\n",
    "    torch.save(score_model.state_dict(), f\"models/{score_model.name}.pt\")\n",
    "\n",
    "    # plot loss history\n",
    "    plt.figure(figsize=(16, 4), tight_layout=True)\n",
    "    plt.plot(loss_history[:, 0], label='Training', color=\"#132a70\", lw=2.0, alpha=0.9)\n",
    "    plt.plot(loss_history[:, 1], label='Validation', linestyle=\"--\", marker=\"o\", color='black')\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.xlabel('Training epoch #')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/{score_model.name}/loss_training.png')\n",
    "else:\n",
    "    score_model.load_state_dict(torch.load(f\"models/{score_model.name}.pt\", map_location=torch_device, weights_only=True))\n",
    "    score_model.eval()"
   ],
   "id": "c9fe7ce7ea0b4005",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "1b24b217c58a5c6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_local_samples = 32**2\n",
    "valid_prior_global, valid_prior_local, valid_data = generate_synthetic_data(prior=prior, n_data=100,\n",
    "                                                                            n_local_samples=n_local_samples,\n",
    "                                                                            random_seed=0)\n",
    "n_post_samples = 100\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_local_samples)\n",
    "#score_model.current_number_of_obs = 4  # we can choose here, how many observations are passed together through the score\n",
    "score_model.current_number_of_obs = max_number_of_obs\n",
    "print(valid_data.shape, score_model.current_number_of_obs)"
   ],
   "id": "3d23f06d13b52fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t1_value = 0.01\n",
    "t0_value = 0.01\n",
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) * 1/(n_local_samples-500) + 0.01,\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) * 1/(n_local_samples-900) + 0.01,\n",
    "    #'damping_factor': lambda t: torch.ones_like(t) * 1e-10 + 0.0001,\n",
    "    #'sampling_chunk_size': 512,\n",
    "}\n",
    "score_model.sde.s_shift_cosine = 0"
   ],
   "id": "70d2338ce86a6066",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#score_model.sde.s_shift_cosine = 4\n",
    "# posterior_global_samples_valid = adaptive_sampling(score_model, valid_data, obs_n_time_steps=obs_n_time_steps,\n",
    "#                                                    n_post_samples=n_post_samples,\n",
    "#                                                    #sampling_arg=sampling_arg,\n",
    "#                                                    run_sampling_in_parallel=False,\n",
    "#                                                    device=torch_device, verbose=True)\n",
    "\n",
    "posterior_global_samples_valid = euler_maruyama_sampling(score_model, valid_data,\n",
    "                                                         n_post_samples=n_post_samples,\n",
    "                                                         sampling_arg=sampling_arg,\n",
    "                                                         diffusion_steps=300, device=torch_device, verbose=True)"
   ],
   "id": "8f96a036226bae1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global.png')"
   ],
   "id": "8003eb9ec33cb427",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "score_model.current_number_of_obs = 1\n",
    "posterior_local_samples_valid = euler_maruyama_sampling(score_model, valid_data[:, :12],\n",
    "                                                        n_post_samples=n_post_samples, conditions=posterior_global_samples_valid,\n",
    "                                                        diffusion_steps=50, device=torch_device, verbose=True)"
   ],
   "id": "6acfbedafd9c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_local_samples_valid.reshape(valid_data.shape[0], n_post_samples, -1)[:, :, :12],\n",
    "                          np.array(valid_prior_local).reshape(valid_data.shape[0], -1)[:, :12],\n",
    "                          variable_names=local_param_names[:12])\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_local.png')"
   ],
   "id": "d4dddf9e04028c15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_shrinkage(posterior_global_samples_valid[:12], posterior_local_samples_valid[:12], min_max=(-10, 10))",
   "id": "d7353606c5d613d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Apply the Model to Real Data",
   "id": "c7192828dfeb7edd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "global_param_names = prior.global_param_names",
   "id": "6ea431e95ac280da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid_data = 512\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(grid_data * grid_data)\n",
    "\n",
    "x_offset = 0#225\n",
    "y_offset = 0#245\n",
    "binned_data = np.load('problems/FLI/exp_binned_data.npy')[x_offset:x_offset+grid_data, y_offset:y_offset+grid_data]\n",
    "binned_data = binned_data.reshape(1, grid_data * grid_data, 256, 1)\n",
    "\n",
    "data = np.load('problems/FLI/final_Data.npy')[:, x_offset:x_offset+grid_data, y_offset:y_offset+grid_data]\n",
    "data = data.reshape(1, grid_data * grid_data, 256, 1)\n",
    "cut_off = 17\n",
    "binary_mask = (np.sum(data, axis=2, keepdims=True) > cut_off)\n",
    "norm = np.max(binned_data, axis=2, keepdims=True)\n",
    "norm[~binary_mask] = 1\n",
    "real_data = binned_data / norm\n",
    "\n",
    "plt.imshow(np.sum(data[0], axis=(1,2)).reshape(grid_data, grid_data), cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ],
   "id": "2b0db50cf830dcf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t1_value = 0.0009\n",
    "t0_value = 1\n",
    "n_post_samples = 100\n",
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    #'damping_factor': lambda t: (torch.ones_like(t) / real_data.shape[1] * 100) * (t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t)),\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) / real_data.shape[1] + 0.1,\n",
    "    #'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) * 1/(grid_data**2) * 0.0001 + 0.001,\n",
    "    #'damping_factor': lambda t: torch.ones_like(t) * 1/(grid_data**2) + 0.1,\n",
    "    'damping_factor': lambda t: torch.ones_like(t) * 1e-10 + 0.0001,\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) * 1e-7 + 2e-4,\n",
    "    #'sampling_chunk_size': 512,\n",
    "    \"sampling_weights\": binary_mask.flatten() * 1,\n",
    "}\n",
    "score_model.sde.s_shift_cosine = 0"
   ],
   "id": "5411497490f1e33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_real = euler_maruyama_sampling(score_model, real_data,\n",
    "                                                         n_post_samples=n_post_samples,\n",
    "                                                         sampling_arg=sampling_arg,\n",
    "                                                         diffusion_steps=300, device=torch_device, verbose=True)"
   ],
   "id": "45d0edca0916bdb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prior_dict = {}\n",
    "posterior_dict = {}\n",
    "prior_tranf_dict = {}\n",
    "posterior_tranf_dict = {}\n",
    "for i in range(len(global_param_names)):\n",
    "    prior_dict[global_param_names[i]] = valid_prior_global[:, i]\n",
    "    posterior_dict[global_param_names[i]] = posterior_global_samples_real[0, :, i]\n",
    "\n",
    "tau, tau_2, A = prior.transform_raw_params(\n",
    "        log_tau=prior_dict[global_param_names[0]],\n",
    "        log_delta_tau=prior_dict[global_param_names[2]],\n",
    "        a=prior_dict[global_param_names[4]]\n",
    "    )\n",
    "prior_tranf_dict = {\n",
    "    r'$\\tau$': tau,\n",
    "    r'$\\tau_2$': tau_2,\n",
    "    r'$A$': A\n",
    "}\n",
    "\n",
    "tau, tau_2, A = prior.transform_raw_params(\n",
    "        log_tau=posterior_dict[global_param_names[0]],\n",
    "        log_delta_tau=posterior_dict[global_param_names[2]],\n",
    "        a=posterior_dict[global_param_names[4]]\n",
    "    )\n",
    "posterior_tranf_dict = {\n",
    "    r'$\\tau$': tau,\n",
    "    r'$\\tau_2$': tau_2,\n",
    "    r'$A$': A\n",
    "}\n",
    "print(r'$\\tau$', np.median(tau))\n",
    "print(r'$\\tau_2$', np.median(tau_2))\n",
    "print(r'$A$', np.median(A))"
   ],
   "id": "3555e88c13d0d693",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.pairs_posterior(\n",
    "    posterior_dict,\n",
    "    priors=prior_dict,\n",
    ")\n",
    "#fig.savefig(f'plots/real_data_global_posterior.pdf')\n",
    "\n",
    "fig = diagnostics.pairs_posterior(\n",
    "    posterior_tranf_dict,\n",
    "    priors=prior_tranf_dict,\n",
    ")\n",
    "#fig.savefig(f'plots/real_data_global_posterior_transf.pdf')"
   ],
   "id": "df842550cb0372d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.median(posterior_global_samples_real[0], axis=0)",
   "id": "3579802271c479b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "posterior_local_samples_real = euler_maruyama_sampling(score_model, real_data,\n",
    "                                                        conditions=posterior_global_samples_real,\n",
    "                                                        n_post_samples=n_post_samples,\n",
    "                                                        diffusion_steps=100, device=torch_device, verbose=True)"
   ],
   "id": "b27e37389798b1a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tau, tau_2, A = prior.transform_raw_params(\n",
    "    log_tau=posterior_local_samples_real[0, :, :, 0].reshape(n_post_samples, grid_data, grid_data),\n",
    "    log_delta_tau=posterior_local_samples_real[0, :, :, 1].reshape(n_post_samples, grid_data, grid_data),\n",
    "    a=posterior_local_samples_real[0, :, :, 2].reshape(n_post_samples, grid_data, grid_data),\n",
    ")\n",
    "tau_mean = A * tau + (1-A) * tau_2\n",
    "ps = np.concatenate([tau[:, :, :, np.newaxis], tau_2[:, :, :, np.newaxis], A[:, :, :, np.newaxis], tau_mean[:, :, :, np.newaxis]], axis=-1)\n",
    "transf_local_param_names = [r'$\\tau_1^L$', r'$\\tau_2^L$', r'$A^L$', r'$\\tau^\\text{mean}$']\n",
    "\n",
    "med = np.median(ps, axis=0)\n",
    "posterior_mad = mad(ps, axis=0)\n",
    "visualize_simulation_output(med,\n",
    "                            mask=binary_mask.reshape(grid_data, grid_data),\n",
    "                            title_prefix=['Posterior Median ' + p for p in transf_local_param_names],\n",
    "                            cmap='jet', scales=[(0,1), (0, 2), (0,1), (0, 2)], add_scale_bar=False)#, save_path=f\"plots/real_data_median.pdf\")\n",
    "visualize_simulation_output(posterior_mad,\n",
    "                            mask=binary_mask.reshape(grid_data, grid_data),\n",
    "                            title_prefix=['Posterior MAD ' + p for p in transf_local_param_names],\n",
    "                            cmap='jet', scales=[(0,1), (0, 2), (0,1), (0, 2)], add_scale_bar=False)#, save_path=f\"plots/real_data_mad.pdf\")\n",
    "\n",
    "#np.save('fli_local_median', med)\n",
    "#np.save('fli_local_mad', posterior_mad)"
   ],
   "id": "a7595e0620328cd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axis = plt.subplots(1, 1, figsize=(7, 2.5), tight_layout=True, sharex=True, sharey=True)\n",
    "axis = [axis]#.flatten()\n",
    "for ax in axis:\n",
    "    while True:\n",
    "        pixel_ids = [np.random.randint(0, grid_data), np.random.randint(0, grid_data)]\n",
    "        pixel_ids = [[16, 15], [21, 15]][1]\n",
    "        if binary_mask.reshape(grid_data, grid_data)[pixel_ids[0], pixel_ids[1]]:\n",
    "            break  # only plot meaningful data\n",
    "    plot_index = np.random.randint(0, tau.shape[0])\n",
    "\n",
    "    simulations = np.array([\n",
    "        prior.simulator.decay_gen_single(\n",
    "            tau_L=tau[post_index, pixel_ids[0], pixel_ids[1]],\n",
    "            tau_L_2=tau_2[post_index, pixel_ids[0], pixel_ids[1]],\n",
    "            A_L=A[post_index, pixel_ids[0], pixel_ids[1]]\n",
    "        ) for post_index in range(tau.shape[0])\n",
    "    ])\n",
    "\n",
    "    ax.plot(real_data.reshape(grid_data, grid_data, 256)[pixel_ids[0], pixel_ids[1]], label='data', color='black')\n",
    "    ax.plot(np.median(simulations, axis=0), label='posterior median', alpha=0.8, color='red')\n",
    "    # ax.fill_between(\n",
    "    #     np.arange(simulations.shape[1]),\n",
    "    #     np.quantile(simulations, 0.025, axis=0),\n",
    "    #     np.quantile(simulations, 0.975, axis=0),\n",
    "    #     alpha=0.4,\n",
    "    #     color='orange',\n",
    "    #     label='posterior 95% CI'\n",
    "    # )\n",
    "    ax.set_xlabel('Time [s]')\n",
    "axis[0].set_ylabel('Normalized Photon Count')\n",
    "fig.legend(labels=['Data', 'Posterior Median', 'Posterior 95% CI'][:2], bbox_to_anchor=(0.5, -0.07),\n",
    "           ncol=3, loc='lower center')\n",
    "plt.savefig(f'plots/real_data_fit_1.pdf', transparent=True, bbox_inches='tight')\n",
    "plt.show()\n",
    "pixel_ids"
   ],
   "id": "43dc651cc485485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.max(real_data)",
   "id": "ecd4a543b4a20dd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3a53d53ea043093c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-abi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
