{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FLI with compositional score matching\n",
   "id": "80db02ba5075c403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:45:29.142368Z",
     "start_time": "2025-04-15T14:45:23.730101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.special import expit\n",
    "\n",
    "from bayesflow import diagnostics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import HierarchicalScoreModel, SDE, euler_maruyama_sampling, adaptive_sampling, train_score_model\n",
    "from diffusion_model.helper_networks import LSTM, GaussianFourierProjection\n",
    "#from bayesflow.wrappers.mamba import Mamba\n",
    "from bayesflow.networks import TimeSeriesNetwork\n",
    "from problems.fli import FLIProblem, FLI_Prior, generate_synthetic_data\n",
    "from problems import plot_shrinkage, visualize_simulation_output"
   ],
   "id": "c1947461daedf5a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bayesflow:\n",
      "When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use\n",
      "\n",
      "with torch.enable_grad():\n",
      "    ...\n",
      "\n",
      "in contexts where you need gradients (e.g. custom training loops).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:45:29.146956Z",
     "start_time": "2025-04-15T14:45:29.145310Z"
    }
   },
   "cell_type": "code",
   "source": "torch_device = torch.device(\"cpu\")",
   "id": "e2cd8befc359fbb7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:47:03.392745Z",
     "start_time": "2025-04-15T14:47:01.505312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior = FLI_Prior()\n",
    "batch_size = 64\n",
    "number_of_obs = 1 #[16]\n",
    "\n",
    "current_sde = SDE(\n",
    "    kernel_type=['variance_preserving', 'sub_variance_preserving'][0],\n",
    "    noise_schedule=['linear', 'cosine', 'flow_matching'][1]\n",
    ")\n",
    "\n",
    "dataset = FLIProblem(\n",
    "    n_data=10000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    online_learning=False,\n",
    "    number_of_obs=number_of_obs,\n",
    ")\n",
    "\n",
    "dataset_valid = FLIProblem(\n",
    "    n_data=1000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    number_of_obs=number_of_obs\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for test in dataloader:\n",
    "    print(test[0].shape)\n",
    "    print(test[2].shape)\n",
    "    print(test[4].shape)\n",
    "    break"
   ],
   "id": "281bf48b6335aa28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel type: variance_preserving, noise schedule: cosine\n",
      "t_min: 0.00035210439818911254, t_max: 0.999647855758667\n",
      "alpha, sigma: (tensor(1.0000), tensor(0.0006)) (tensor(0.0006), tensor(1.0000))\n",
      "Moving prior to device: cpu\n",
      "torch.Size([64, 6])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 201, 1])\n",
      "torch.Size([64, 18])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:45:40.415675Z",
     "start_time": "2025-04-15T14:45:40.380171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "hidden_dim_summary = 18\n",
    "summary_net = TimeSeriesNetwork(summary_dim=hidden_dim_summary) #LSTM(input_size=1, hidden_dim=hidden_dim_summary, max_batch_size=1024)\n",
    "summary_net.to(torch_device)\n",
    "\n",
    "global_summary_dim = 18\n",
    "#global_summary_net = ShallowSet(dim_input=hidden_dim_summary, dim_output=global_summary_dim, dim_hidden=16)\n",
    "\n",
    "time_embedding_local = nn.Sequential(\n",
    "    GaussianFourierProjection(8),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.Mish()\n",
    ")\n",
    "time_embedding_global = nn.Sequential(\n",
    "    GaussianFourierProjection(8),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.Mish()\n",
    ")\n",
    "\n",
    "score_model = HierarchicalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_theta_local=prior.n_params_local,\n",
    "    input_dim_x_global=global_summary_dim,\n",
    "    input_dim_x_local=hidden_dim_summary,\n",
    "    summary_net=summary_net,\n",
    "    #global_summary_net=global_summary_net,\n",
    "    time_embedding_local=time_embedding_local,\n",
    "    time_embedding_global=time_embedding_global,\n",
    "    hidden_dim=512,\n",
    "    n_blocks=6,\n",
    "    max_number_of_obs=number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs),\n",
    "    prediction_type=['score', 'e', 'x', 'v'][3],\n",
    "    sde=current_sde,\n",
    "    weighting_type=[None, 'likelihood_weighting', 'flow_matching', 'sigmoid'][1],\n",
    "    prior=prior,\n",
    "    name_prefix='FLI_'\n",
    ")\n",
    "\n",
    "# make dir for plots\n",
    "if not os.path.exists(f\"plots/{score_model.name}\"):\n",
    "    os.makedirs(f\"plots/{score_model.name}\")"
   ],
   "id": "8264d867ba480846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------+\n",
      "|               Modules                | Parameters |\n",
      "+--------------------------------------+------------+\n",
      "|        time_embedding.0.scale        |     1      |\n",
      "|       time_embedding.1.weight        |     64     |\n",
      "|        time_embedding.1.bias         |     8      |\n",
      "|   blocks.res_blocks.0.dense.weight   |   16384    |\n",
      "|    blocks.res_blocks.0.dense.bias    |    512     |\n",
      "| blocks.res_blocks.0.projector.weight |   16384    |\n",
      "|   blocks.res_blocks.1.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.1.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.2.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.2.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.3.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.3.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.4.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.4.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.5.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.5.dense.bias    |    512     |\n",
      "|    final_projection_linear.weight    |    3072    |\n",
      "|     final_projection_linear.bias     |     6      |\n",
      "+--------------------------------------+------------+\n",
      "Total Trainable Params: 1349711\n",
      "FLI_global_score_model_v_variance_preserving_cosine_likelihood_weighting\n",
      "+--------------------------------------+------------+\n",
      "|               Modules                | Parameters |\n",
      "+--------------------------------------+------------+\n",
      "|        time_embedding.0.scale        |     1      |\n",
      "|       time_embedding.1.weight        |     64     |\n",
      "|        time_embedding.1.bias         |     8      |\n",
      "|   blocks.res_blocks.0.dense.weight   |   17920    |\n",
      "|    blocks.res_blocks.0.dense.bias    |    512     |\n",
      "| blocks.res_blocks.0.projector.weight |   17920    |\n",
      "|   blocks.res_blocks.1.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.1.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.2.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.2.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.3.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.3.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.4.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.4.dense.bias    |    512     |\n",
      "|   blocks.res_blocks.5.dense.weight   |   262144   |\n",
      "|    blocks.res_blocks.5.dense.bias    |    512     |\n",
      "|    final_projection_linear.weight    |    1536    |\n",
      "|     final_projection_linear.bias     |     3      |\n",
      "+--------------------------------------+------------+\n",
      "Total Trainable Params: 1351244\n",
      "FLI_local_score_model_v_variance_preserving_cosine_likelihood_weighting\n",
      "+---------------------------------------------------+------------+\n",
      "|                      Modules                      | Parameters |\n",
      "+---------------------------------------------------+------------+\n",
      "|        global_model.time_embedding.0.scale        |     1      |\n",
      "|        global_model.time_embedding.1.weight       |     64     |\n",
      "|         global_model.time_embedding.1.bias        |     8      |\n",
      "|   global_model.blocks.res_blocks.0.dense.weight   |   16384    |\n",
      "|    global_model.blocks.res_blocks.0.dense.bias    |    512     |\n",
      "| global_model.blocks.res_blocks.0.projector.weight |   16384    |\n",
      "|   global_model.blocks.res_blocks.1.dense.weight   |   262144   |\n",
      "|    global_model.blocks.res_blocks.1.dense.bias    |    512     |\n",
      "|   global_model.blocks.res_blocks.2.dense.weight   |   262144   |\n",
      "|    global_model.blocks.res_blocks.2.dense.bias    |    512     |\n",
      "|   global_model.blocks.res_blocks.3.dense.weight   |   262144   |\n",
      "|    global_model.blocks.res_blocks.3.dense.bias    |    512     |\n",
      "|   global_model.blocks.res_blocks.4.dense.weight   |   262144   |\n",
      "|    global_model.blocks.res_blocks.4.dense.bias    |    512     |\n",
      "|   global_model.blocks.res_blocks.5.dense.weight   |   262144   |\n",
      "|    global_model.blocks.res_blocks.5.dense.bias    |    512     |\n",
      "|    global_model.final_projection_linear.weight    |    3072    |\n",
      "|     global_model.final_projection_linear.bias     |     6      |\n",
      "|         local_model.time_embedding.0.scale        |     1      |\n",
      "|        local_model.time_embedding.1.weight        |     64     |\n",
      "|         local_model.time_embedding.1.bias         |     8      |\n",
      "|    local_model.blocks.res_blocks.0.dense.weight   |   17920    |\n",
      "|     local_model.blocks.res_blocks.0.dense.bias    |    512     |\n",
      "|  local_model.blocks.res_blocks.0.projector.weight |   17920    |\n",
      "|    local_model.blocks.res_blocks.1.dense.weight   |   262144   |\n",
      "|     local_model.blocks.res_blocks.1.dense.bias    |    512     |\n",
      "|    local_model.blocks.res_blocks.2.dense.weight   |   262144   |\n",
      "|     local_model.blocks.res_blocks.2.dense.bias    |    512     |\n",
      "|    local_model.blocks.res_blocks.3.dense.weight   |   262144   |\n",
      "|     local_model.blocks.res_blocks.3.dense.bias    |    512     |\n",
      "|    local_model.blocks.res_blocks.4.dense.weight   |   262144   |\n",
      "|     local_model.blocks.res_blocks.4.dense.bias    |    512     |\n",
      "|    local_model.blocks.res_blocks.5.dense.weight   |   262144   |\n",
      "|     local_model.blocks.res_blocks.5.dense.bias    |    512     |\n",
      "|     local_model.final_projection_linear.weight    |    1536    |\n",
      "|      local_model.final_projection_linear.bias     |     3      |\n",
      "+---------------------------------------------------+------------+\n",
      "Total Trainable Params: 2700955\n",
      "FLI_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:45:42.216559Z",
     "start_time": "2025-04-15T14:45:41.773356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train model\n",
    "loss_history = train_score_model(score_model, dataloader, dataloader_valid=dataloader_valid, hierarchical=True,\n",
    "                                              epochs=3000, device=torch_device)\n",
    "score_model.eval()\n",
    "torch.save(score_model.state_dict(), f\"models/{score_model.name}.pt\")\n",
    "\n",
    "# plot loss history\n",
    "plt.figure(figsize=(16, 4), tight_layout=True)\n",
    "plt.plot(loss_history[:, 0], label='Training', color=\"#132a70\", lw=2.0, alpha=0.9)\n",
    "plt.plot(loss_history[:, 1], label='Validation', linestyle=\"--\", marker=\"o\", color='black')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('Training epoch #')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/{score_model.name}/loss_training.png')"
   ],
   "id": "7ee0d728a42e40fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training v-model for 3000 epochs with learning rate 0.0005 and likelihood_weighting weighting.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): all input tensors must be on the same device. Received mps:0 and cpu",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# train model\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m loss_history = \u001B[43mtrain_score_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscore_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_valid\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataloader_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhierarchical\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m                                              \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch_device\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m score_model.eval()\n\u001B[32m      5\u001B[39m torch.save(score_model.state_dict(), \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mmodels/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscore_model.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.pt\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/hierarchical-abi/diffusion_model/train_score_models.py:117\u001B[39m, in \u001B[36mtrain_score_model\u001B[39m\u001B[34m(model, dataloader, hierarchical, dataloader_valid, epochs, lr, cosine_annealing, clip_norm, device)\u001B[39m\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[32m    115\u001B[39m     \u001B[38;5;66;03m# initialize the gradients\u001B[39;00m\n\u001B[32m    116\u001B[39m     optimizer.zero_grad()\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     loss = \u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhierarchical\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhierarchical\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m     loss.backward()\n\u001B[32m    119\u001B[39m     \u001B[38;5;66;03m# gradient clipping\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/hierarchical-abi/diffusion_model/train_score_models.py:70\u001B[39m, in \u001B[36mcompute_loss\u001B[39m\u001B[34m(model, batch, hierarchical, device)\u001B[39m\n\u001B[32m     68\u001B[39m     diffusion_time = diffusion_time.to(device)\n\u001B[32m     69\u001B[39m     \u001B[38;5;66;03m# calculate the loss\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m70\u001B[39m     loss = \u001B[43mcompute_hierarchical_score_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtheta_global_noisy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtheta_global_noisy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mtarget_global\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_global\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mtheta_local_noisy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtheta_local_noisy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mtarget_local\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mdiffusion_time\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdiffusion_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     77\u001B[39m     theta_noisy, target, x_batch, diffusion_time = batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/hierarchical-abi/diffusion_model/train_score_models.py:27\u001B[39m, in \u001B[36mcompute_hierarchical_score_loss\u001B[39m\u001B[34m(theta_global_noisy, target_global, theta_local_noisy, target_local, x_batch, diffusion_time, model)\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_hierarchical_score_loss\u001B[39m(\n\u001B[32m     23\u001B[39m         theta_global_noisy, target_global, theta_local_noisy, target_local, x_batch,\n\u001B[32m     24\u001B[39m         diffusion_time, model\n\u001B[32m     25\u001B[39m ):\n\u001B[32m     26\u001B[39m     \u001B[38;5;66;03m# predict from perturbed theta\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     pred_global, pred_local = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtheta_global\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtheta_global_noisy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtheta_local\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtheta_local_noisy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m                                    \u001B[49m\u001B[43mtime\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdiffusion_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_score\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m     weight = weighting_function(diffusion_time, sde=model.sde, weighting_type=model.weighting_type,\n\u001B[32m     31\u001B[39m                                           prediction_type=model.prediction_type)\n\u001B[32m     32\u001B[39m     \u001B[38;5;66;03m# calculate the loss\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/hierarchical-score-matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/hierarchical-score-matching/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/hierarchical-abi/diffusion_model/diffusion_sde_model.py:377\u001B[39m, in \u001B[36mHierarchicalScoreModel.forward\u001B[39m\u001B[34m(self, theta_global, theta_local, time, x, pred_score, clip_x)\u001B[39m\n\u001B[32m    375\u001B[39m     local_out = local_out_flat.contiguous().view(batch_size, n_obs, -\u001B[32m1\u001B[39m)\n\u001B[32m    376\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m377\u001B[39m     global_out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mglobal_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtheta\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtheta_global\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx_emb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m                                           \u001B[49m\u001B[43mconditions\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpred_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip_x\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclip_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    379\u001B[39m     local_out = \u001B[38;5;28mself\u001B[39m.local_model.forward(theta=theta_local, time=time, x=x_emb,\n\u001B[32m    380\u001B[39m                                          conditions=theta_global, pred_score=pred_score, clip_x=clip_x)\n\u001B[32m    381\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m global_out, local_out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/hierarchical-abi/diffusion_model/diffusion_sde_model.py:156\u001B[39m, in \u001B[36mScoreModel.forward\u001B[39m\u001B[34m(self, theta, time, x, conditions, pred_score, clip_x)\u001B[39m\n\u001B[32m    154\u001B[39m     h_update = conditions\n\u001B[32m    155\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m     cond = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_emb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_emb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    157\u001B[39m     h_update = theta.clone()\n\u001B[32m    159\u001B[39m \u001B[38;5;66;03m# initial input\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: torch.cat(): all input tensors must be on the same device. Received mps:0 and cpu"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.load_state_dict(torch.load(f\"models/{score_model.name}.pt\", weights_only=True))\n",
    "score_model.eval();"
   ],
   "id": "ef923235fe4b33b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "b4df928ac8ce9cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_local_samples = 16\n",
    "valid_prior_global, valid_prior_local, valid_data = generate_synthetic_data(prior=prior, n_data=100,\n",
    "                                                                            n_local_samples=n_local_samples,\n",
    "                                                                            random_seed=0)\n",
    "n_post_samples = 100\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_local_samples)\n",
    "#score_model.current_number_of_obs = 4  # we can choose here, how many observations are passed together through the score\n",
    "#score_model.current_number_of_obs = 4\n",
    "print(valid_data.shape, score_model.current_number_of_obs)"
   ],
   "id": "2025f449937da875",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mini_batch_size = 10\n",
    "t1_value = 0.01\n",
    "t0_value = 1\n",
    "mini_batch_arg = {\n",
    "    'size': mini_batch_size,\n",
    "    'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "}\n",
    "#plt.plot(torch.linspace(0, 1, 100), mini_batch_arg['damping_factor'](torch.linspace(0, 1, 100)))\n",
    "#plt.show()\n",
    "\n",
    "t0_value, t1_value"
   ],
   "id": "b6beb94daf12115e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#score_model.sde.s_shift_cosine = 4\n",
    "# posterior_global_samples_valid = adaptive_sampling(score_model, valid_data, obs_n_time_steps=201,\n",
    "#                                                    n_post_samples=n_post_samples,\n",
    "#                                                    #mini_batch_arg=mini_batch_arg,\n",
    "#                                                    run_sampling_in_parallel=False,\n",
    "#                                                    device=torch_device, verbose=True)\n",
    "\n",
    "posterior_global_samples_valid = euler_maruyama_sampling(score_model, valid_data,\n",
    "                                                         obs_n_time_steps=201,\n",
    "                                                         n_post_samples=n_post_samples,\n",
    "                                                         diffusion_steps=100, device=torch_device, verbose=True)"
   ],
   "id": "a9ecff4368f5da80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=global_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global.png')"
   ],
   "id": "5b3e0546bd196017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conditions_global = (np.median(posterior_global_samples_valid, axis=0), posterior_global_samples_valid)[1]\n",
    "score_model.sde.s_shift_cosine = 0\n",
    "posterior_local_samples_valid = euler_maruyama_sampling(score_model, valid_data, obs_n_time_steps=201,\n",
    "                                                        n_post_samples=n_post_samples, conditions=conditions_global,\n",
    "                                                        diffusion_steps=50, device=torch_device, verbose=True)"
   ],
   "id": "a0afa10c0eae06db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_local_samples_valid.reshape(valid_data.shape[0], n_post_samples, -1),\n",
    "                          np.array(valid_prior_local).reshape(valid_data.shape[0], -1),\n",
    "                          variable_names=local_param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_local.png')"
   ],
   "id": "396d980ecc94ee94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_shrinkage(posterior_global_samples_valid[:12], posterior_local_samples_valid[:12], min_max=(-10, 10))",
   "id": "fb4ff93ba40e5f0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "valid_id = 0\n",
    "print('Global Estimates')\n",
    "print('mu:', np.median(posterior_global_samples_valid[valid_id, :, 0]), np.std(posterior_global_samples_valid[valid_id, :, 0]))\n",
    "print('log sigma:', np.median(posterior_global_samples_valid[valid_id, :, 1]), np.std(posterior_global_samples_valid[valid_id, :, 1]))\n",
    "print('True')\n",
    "print('mu:', valid_prior_global[valid_id][0].item())\n",
    "print('log sigma:', valid_prior_global[valid_id][1].item())"
   ],
   "id": "14919d3f7a2c375e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_grid = int(np.sqrt(n_local_samples))\n",
    "ps = posterior_local_samples_valid[valid_id, :, :n_grid*n_grid].reshape(n_post_samples, n_grid, n_grid, 3).copy()\n",
    "true = valid_prior_local[valid_id, :n_grid*n_grid].numpy().copy().reshape(n_grid, n_grid, 3)\n",
    "ps[:, :, :, 0] = np.exp(ps[:, :, :, 0])\n",
    "true[:, :, 0] = np.exp(true[:, :, 0])\n",
    "ps[:, :, :, 1] = ps[:, :, :, 0] + np.exp(ps[:, :, :, 1])\n",
    "true[:, :, 1] = true[:, :, 0] + np.exp(true[:, :, 1])\n",
    "ps[:, :, :, 2] = expit(ps[:, :, :, 2])\n",
    "true[:, :, 2] = expit(true[:, :, 2])\n",
    "transf_local_param_names = [r'$\\tau_1^L$', r'$\\tau_2^L$', r'$A^L$']\n",
    "\n",
    "med = np.median(ps, axis=0)\n",
    "std = np.std(ps, axis=0)\n",
    "error = (med-true)**2\n",
    "visualize_simulation_output(med, title_prefix=['Posterior Median ' + p for p in transf_local_param_names],\n",
    "                            cmap='turbo', save_path=f\"plots/{score_model.name}/simulation_median_{valid_id}.png\")\n",
    "visualize_simulation_output(true, title_prefix=['True ' + p for p in transf_local_param_names],\n",
    "                            cmap='turbo', save_path=f\"plots/{score_model.name}/simulation_true_{valid_id}.png\")\n",
    "\n",
    "visualize_simulation_output(std, title_prefix=['Posterior Std ' + p for p in transf_local_param_names],\n",
    "                            cmap='turbo', save_path=f\"plots/{score_model.name}/simulation_std_{valid_id}.png\")\n",
    "visualize_simulation_output(error, title_prefix=['Error ' + p for p in transf_local_param_names],\n",
    "                            cmap='turbo', save_path=f\"plots/{score_model.name}/simulation_error_{valid_id}.png\")"
   ],
   "id": "22186b2ba02c2afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), tight_layout=True)\n",
    "for i in range(3):\n",
    "    ax[i].errorbar(x=true[:, :, i].flatten(), y=med[:, :, i].flatten(), yerr=1.96*std[:, :, i].flatten(), fmt='o')\n",
    "    #ax[i].plot([np.min(true[:, :, i]), np.max(true[:, :, i])], [np.min(true[:, :, i]), np.max(true[:, :, i])], 'k--')\n",
    "    ax[i].axhline(np.median(posterior_global_samples_valid[valid_id, :, i], axis=0), color='red', linestyle='--',\n",
    "                label='Global posterior mean', alpha=0.75)\n",
    "    ax[i].set_ylabel('Prediction')\n",
    "    ax[i].set_xlabel('True')\n",
    "    ax[i].legend()\n",
    "plt.show()"
   ],
   "id": "ba0c1b429bf02d3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "36d38b81a0f739b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-abi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
