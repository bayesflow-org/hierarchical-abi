{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Ar(1) on a Grid Test with compositional score matching\n",
    "\n",
    "In this notebook, we will test the compositional score matching on a hierarchical problem defined on a grid.\n",
    "- The observations are on grid with `n_grid` x `n_grid` points.\n",
    "- The global parameters are the same for all grid points with hyper-priors:\n",
    "$$ \\alpha \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\mu_\\beta \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\log\\text{std}_\\beta \\sim \\mathcal{N}(0, 1);$$\n",
    "\n",
    "- The local parameters are different for each grid point\n",
    "$$ \\eta_{i,j}^\\text{raw} \\sim \\mathcal{N}(0, I), \\qquad \\eta_{i,j} = 2\\operatorname{sigmoid}(\\beta + \\sigma\\cdot\\eta_{i,j}^\\text{raw})-1$$\n",
    "\n",
    "-  In each grid point, we have a time series of `T` observations.\n",
    "$$ y_{i,j} \\sim \\mathcal{N}(\\alpha + \\eta_{i,j}y_{i,j-1}, 0.1 I), y_{i,0} \\sim \\mathcal{N}(0, 0.1 I)$$\n",
    "- We observe $T=5$ time points for each grid point. We can also amortize over the time dimension."
   ],
   "id": "4a0d18647558ec5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "import torch\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "from bayesflow import diagnostics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import HierarchicalScoreModel, SDE, ShallowSet, euler_maruyama_sampling, adaptive_sampling, \\\n",
    "    train_score_model\n",
    "from problems import AR1GridProblem, AR1GridPrior\n",
    "from problems import visualize_simulation_output"
   ],
   "id": "7f7768fe022c9d30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_device = torch.device(\"mps\")",
   "id": "65551a01126c99a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prior = AR1GridPrior()\n",
    "\n",
    "# test the simulator\n",
    "sim_test = prior.sample(1, n_local_samples=16, get_grid=True)['data'][0]\n",
    "visualize_simulation_output(np.array(sim_test))"
   ],
   "id": "d3a8406ca57a2712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "number_of_obs = 1\n",
    "max_number_of_obs = number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs)\n",
    "current_sde = SDE(\n",
    "    kernel_type='variance_preserving',\n",
    "    noise_schedule='cosine'\n",
    ")\n",
    "\n",
    "dataset = AR1GridProblem(\n",
    "    n_data=10000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    online_learning=False,\n",
    "    number_of_obs=number_of_obs,\n",
    "    amortize_time=False,\n",
    "    as_set=True\n",
    ")\n",
    "\n",
    "dataset_valid = AR1GridProblem(\n",
    "    n_data=1000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    number_of_obs=number_of_obs,\n",
    "    as_set=True,\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for test in dataloader:\n",
    "    print(test[4].shape)\n",
    "    break"
   ],
   "id": "16ddeda02f8004be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "global_summary_dim = 5\n",
    "global_summary_net = ShallowSet(dim_input=5, dim_output=global_summary_dim, dim_hidden=128)\n",
    "\n",
    "score_model = HierarchicalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_theta_local=prior.n_params_local,\n",
    "    input_dim_x_global=global_summary_dim,\n",
    "    input_dim_x_local=global_summary_dim,\n",
    "    global_summary_net=global_summary_net if isinstance(number_of_obs, list) else None,\n",
    "    hidden_dim=256,\n",
    "    n_blocks=5,\n",
    "    dropout_rate=0.1,\n",
    "    max_number_of_obs=max_number_of_obs,\n",
    "    prediction_type='v',\n",
    "    sde=current_sde,\n",
    "    weighting_type='likelihood_weighting',\n",
    "    prior=prior,\n",
    "    name_prefix=f'ar1_{max_number_of_obs}',\n",
    ")"
   ],
   "id": "f2521ba7c2d35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(f\"models/ar1/{score_model.name}.pt\"):\n",
    "    # train model\n",
    "    loss_history = train_score_model(score_model, dataloader,\n",
    "                                     dataloader_valid=dataloader_valid, hierarchical=True,\n",
    "                                     epochs=1000, device=torch_device)\n",
    "    score_model.eval()\n",
    "    torch.save(score_model.state_dict(), f\"models/ar1/{score_model.name}.pt\")\n",
    "\n",
    "    # plot loss history\n",
    "    plt.figure(figsize=(16, 4), tight_layout=True)\n",
    "    plt.plot(loss_history[:, 0], label='Training', color=\"#132a70\", lw=2.0, alpha=0.9)\n",
    "    plt.plot(loss_history[:, 1], label='Validation', linestyle=\"--\", marker=\"o\", color='black')\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.xlabel('Training epoch #')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'models/ar1/{score_model.name}_loss_training.png')\n",
    "else:\n",
    "    score_model.load_state_dict(torch.load(f\"models/ar1/{score_model.name}.pt\",\n",
    "                                           map_location=torch_device, weights_only=True))\n",
    "    score_model.eval()"
   ],
   "id": "49bee847ec5d30fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "12de73036512734b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_grid = [4, 16, 128][1]\n",
    "print(f'Grid size: {n_grid}x{n_grid}')\n",
    "prior_dict = prior.sample(batch_size=100, n_local_samples=n_grid*n_grid)\n",
    "\n",
    "valid_prior_global, valid_prior_local, valid_data = prior_dict['global_params'], prior_dict['local_params'], prior_dict['data']\n",
    "n_post_samples = 300\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_grid*n_grid)\n",
    "\n",
    "score_model.current_number_of_obs = 1\n",
    "print(valid_data.shape, score_model.current_number_of_obs)"
   ],
   "id": "ca6b043ac24ff58c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(valid_data[0].reshape(5, n_grid, n_grid).numpy())",
   "id": "95fd7a6a865d22ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t1_value = 1/np.sqrt(2*n_grid*n_grid)\n",
    "t0_value = 0.95\n",
    "print(t1_value, t0_value)\n",
    "\n",
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * t),\n",
    "}\n",
    "score_model.sde.s_shift_cosine = 0.03\n",
    "\n",
    "posterior_global_samples_valid = adaptive_sampling(score_model, valid_data,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   sampling_arg=sampling_arg,\n",
    "                                                   device=torch_device,\n",
    "                                                   #diffusion_steps=300,\n",
    "                                                   #max_evals=1000,\n",
    "                                                   verbose=True)"
   ],
   "id": "72d1b9f7a44165c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names,\n",
    "                           figsize=(6, 2.5))\n",
    "print('RMSE:', diagnostics.metrics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "fig.savefig(f'plots/ar1/recovery_global_n_grid_{n_grid}.pdf')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                   difference=True, variable_names=global_param_names, figsize=(6, 2.5), stacked=True)\n",
    "leg = plt.legend()\n",
    "leg.set_visible(False)\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "fig.savefig(f'plots/ar1/ecdf_global_n_grid_{n_grid}.pdf')"
   ],
   "id": "4e42fe3aca8e6194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "score_model.current_number_of_obs = 1\n",
    "first_n_samples = valid_data.shape[1]\n",
    "posterior_local_samples_valid = euler_maruyama_sampling(score_model, valid_data[:, :first_n_samples],\n",
    "                                                        conditions=posterior_global_samples_valid,\n",
    "                                                        n_post_samples=n_post_samples,\n",
    "                                                        diffusion_steps=100, device=torch_device,\n",
    "                                                        verbose=True)\n",
    "\n",
    "posterior_local_samples_valid = score_model.prior.transform_local_params(beta=posterior_global_samples_valid[..., 1:2], eta_raw=posterior_local_samples_valid[..., 0])"
   ],
   "id": "7c01126af68728ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_local_samples_valid.reshape(valid_data.shape[0], n_post_samples, -1),\n",
    "                          np.array(valid_prior_local)[:, :first_n_samples],\n",
    "                          variable_names=local_param_names[:first_n_samples]);"
   ],
   "id": "e741e702eac3033e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "global_rmse = diagnostics.metrics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                                          aggregation=np.median)['values'].mean().round(2)\n",
    "global_rmse_mad = diagnostics.metrics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                                              aggregation=mad)['values'].mean().round(2)\n",
    "print('Global RMSE:', global_rmse, global_rmse_mad)\n",
    "\n",
    "posterior_local_samples_reshaped = posterior_local_samples_valid.reshape(posterior_global_samples_valid.shape[0], n_post_samples, -1)\n",
    "valid_prior_local_ = np.array(valid_prior_local)[:, :first_n_samples]\n",
    "\n",
    "global_rmse = diagnostics.metrics.root_mean_squared_error(posterior_local_samples_reshaped, valid_prior_local_,\n",
    "                                                          aggregation=np.median)['values'].mean().round(2)\n",
    "global_rmse_mad = diagnostics.metrics.root_mean_squared_error(posterior_local_samples_reshaped, valid_prior_local_,\n",
    "                                                              aggregation=mad)['values'].mean().round(2)\n",
    "print('Local RMSE:', global_rmse, global_rmse_mad)\n",
    "\n",
    "global_rmse = diagnostics.posterior_contraction(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                                aggregation=np.median)['values'].mean().round(2)\n",
    "global_rmse_mad = diagnostics.posterior_contraction(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                                    aggregation=mad)['values'].mean().round(2)\n",
    "print('Global Contraction:', global_rmse, global_rmse_mad)\n",
    "\n",
    "global_rmse = diagnostics.posterior_contraction(posterior_local_samples_reshaped, valid_prior_local_,\n",
    "                                                aggregation=np.median)['values'].mean().round(2)\n",
    "global_rmse_mad = diagnostics.posterior_contraction(posterior_local_samples_reshaped, valid_prior_local_,\n",
    "                                                    aggregation=mad)['values'].mean().round(2)\n",
    "print('Local Contraction:', global_rmse, global_rmse_mad)"
   ],
   "id": "87b1b4453d110d7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference-Time Hyperparameter Optimization",
   "id": "cfacccab17b81a44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "\n",
    "def decay(t, d0, d1, alpha, beta):\n",
    "    shaped = 1 - (1 - t.pow(alpha)).pow(beta)\n",
    "    return d0 + (d1 - d0) * shaped\n",
    "\n",
    "def objective(trial):\n",
    "    t0_value = trial.suggest_float('t0_value', 1e-3, 1)\n",
    "    t1_value = trial.suggest_float('t1_value', 1e-5, 1e-3)\n",
    "    s_shift_cosine = trial.suggest_float('s_shift_cosine', 0, 2)\n",
    "    alpha = trial.suggest_float('alpha', 0.3, 2)\n",
    "    beta = trial.suggest_float('beta', 0.3, 2)\n",
    "\n",
    "    sampling_arg = {\n",
    "        'size': 2,\n",
    "        'damping_factor': lambda t: decay(t, d0=t0_value, d1=t1_value, alpha=alpha, beta=beta),\n",
    "    }\n",
    "    score_model.sde.s_shift_cosine = s_shift_cosine\n",
    "\n",
    "    test_global_samples = adaptive_sampling(score_model, valid_data,\n",
    "                                            n_post_samples=n_post_samples,\n",
    "                                            sampling_arg=sampling_arg,\n",
    "                                            max_evals=1000,\n",
    "                                            device=torch_device, verbose=False)\n",
    "    if np.isnan(test_global_samples).any():\n",
    "        return np.inf\n",
    "\n",
    "    rmse = diagnostics.metrics.root_mean_squared_error(test_global_samples, np.array(valid_prior_global))['values'].mean()\n",
    "    cerror = diagnostics.calibration_error(test_global_samples, np.array(valid_prior_global))['values'].mean()\n",
    "    return rmse + cerror\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=20)\n",
    "study.best_params"
   ],
   "id": "ea5df72bc4cb4c53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the optimal decay function\n",
    "t = torch.linspace(0, 1, 100)\n",
    "dt = decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'],\n",
    "           alpha=study.best_params['alpha'], beta=study.best_params['beta'])\n",
    "plt.plot(t, dt, label='Decay function')\n",
    "plt.legend()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Damping factor')\n",
    "plt.show()\n",
    "\n",
    "print(study.best_params)"
   ],
   "id": "f3d337fc7c7444c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    'damping_factor': lambda t: decay(t,\n",
    "                                      d0=study.best_params['t0_value'],\n",
    "                                      d1=study.best_params['t1_value'],\n",
    "                                      alpha=study.best_params['alpha'],\n",
    "                                      beta=study.best_params['beta']),\n",
    "}\n",
    "score_model.sde.s_shift_cosine = study.best_params['s_shift_cosine']\n",
    "\n",
    "posterior_global_samples_valid = adaptive_sampling(score_model, valid_data,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   sampling_arg=sampling_arg,\n",
    "                                                   device=torch_device,\n",
    "                                                   verbose=True)"
   ],
   "id": "5642e0affe94ad33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names,\n",
    "                           figsize=(6, 2.5))\n",
    "print('RMSE:', diagnostics.metrics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/ar1/recovery_global_n_grid_{n_grid}.pdf')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                   difference=True, variable_names=global_param_names, figsize=(6, 2.5), stacked=True)\n",
    "leg = plt.legend()\n",
    "leg.set_visible(False)\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/ar1/ecdf_global_n_grid_{n_grid}.pdf')"
   ],
   "id": "7d44f45c82411cfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3ee8a3f403727100",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-abi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
