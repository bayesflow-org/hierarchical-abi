{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Ar(1) on a Grid Test with compositional score matching\n",
    "\n",
    "In this notebook, we will test the compositional score matching on a hierarchical problem defined on a grid.\n",
    "- The observations are on grid with `n_grid` x `n_grid` points.\n",
    "- The global parameters are the same for all grid points with hyper-priors:\n",
    "$$ \\alpha \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\mu_\\beta \\sim \\mathcal{N}(0, 1) \\quad\n",
    "  \\log\\text{std}_\\beta \\sim \\mathcal{N}(0, 1);$$\n",
    "\n",
    "- The local parameters are different for each grid point\n",
    "$$ \\eta_{i,j}^\\text{raw} \\sim \\mathcal{N}(0, I), \\qquad \\eta_{i,j} = 2\\operatorname{sigmoid}(\\beta + \\sigma\\cdot\\eta_{i,j}^\\text{raw})-1$$\n",
    "\n",
    "-  In each grid point, we have a time series of `T` observations.\n",
    "$$ y_{i,j} \\sim \\mathcal{N}(\\alpha + \\eta_{i,j}y_{i,j-1}, 0.1 I), y_{i,0} \\sim \\mathcal{N}(0, 0.1 I)$$\n",
    "- We observe $T=5$ time points for each grid point. We can also amortize over the time dimension."
   ],
   "id": "4a0d18647558ec5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "from bayesflow import diagnostics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import HierarchicalScoreModel, SDE, ShallowSet, euler_maruyama_sampling, adaptive_sampling, \\\n",
    "    train_score_model, probability_ode_solving\n",
    "from problems.ar1_grid import AR1GridProblem, Prior\n",
    "from problems import visualize_simulation_output"
   ],
   "id": "7f7768fe022c9d30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_device = torch.device(\"mps\")",
   "id": "65551a01126c99a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prior = Prior()\n",
    "\n",
    "# test the simulator\n",
    "sim_test = prior.sample(1, n_local_samples=16, get_grid=True)['data'][0]\n",
    "visualize_simulation_output(np.array(sim_test))"
   ],
   "id": "d3a8406ca57a2712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "number_of_obs = 1  # [1, 4, 8, 16, 64, 128]  # or a list\n",
    "max_number_of_obs = number_of_obs if isinstance(number_of_obs, int) else max(number_of_obs)\n",
    "current_sde = SDE(\n",
    "    kernel_type='variance_preserving',\n",
    "    noise_schedule='cosine'\n",
    ")\n",
    "\n",
    "dataset = AR1GridProblem(\n",
    "    n_data=10000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    online_learning=True,\n",
    "    number_of_obs=number_of_obs,\n",
    "    amortize_time=False,\n",
    "    as_set=True\n",
    ")\n",
    "\n",
    "dataset_valid = AR1GridProblem(\n",
    "    n_data=1000,\n",
    "    prior=prior,\n",
    "    sde=current_sde,\n",
    "    number_of_obs=number_of_obs,\n",
    "    as_set=True,\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for test in dataloader:\n",
    "    print(test[4].shape)\n",
    "    break"
   ],
   "id": "16ddeda02f8004be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "global_summary_dim = 5\n",
    "global_summary_net = ShallowSet(dim_input=5, dim_output=global_summary_dim, dim_hidden=128)\n",
    "\n",
    "score_model = HierarchicalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_theta_local=prior.n_params_local,\n",
    "    input_dim_x_global=global_summary_dim,\n",
    "    input_dim_x_local=global_summary_dim,\n",
    "    global_summary_net=global_summary_net if isinstance(number_of_obs, list) else None,\n",
    "    hidden_dim=256,\n",
    "    n_blocks=5,\n",
    "    dropout_rate=0.1,\n",
    "    max_number_of_obs=max_number_of_obs,\n",
    "    prediction_type='v',\n",
    "    sde=current_sde,\n",
    "    weighting_type='likelihood_weighting',\n",
    "    prior=prior,\n",
    "    name_prefix=f'ar1_5_{max_number_of_obs}',\n",
    ")\n",
    "\n",
    "# make dir for plots\n",
    "if not os.path.exists(f\"plots/{score_model.name}\"):\n",
    "    os.makedirs(f\"plots/{score_model.name}\")"
   ],
   "id": "f2521ba7c2d35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(f\"models/{score_model.name}.pt\"):\n",
    "    # train model\n",
    "    loss_history = train_score_model(score_model, dataloader, dataloader_valid=dataloader_valid, hierarchical=True,\n",
    "                                                  epochs=3000, device=torch_device)\n",
    "    score_model.eval()\n",
    "    torch.save(score_model.state_dict(), f\"models/{score_model.name}.pt\")\n",
    "\n",
    "    # plot loss history\n",
    "    plt.figure(figsize=(16, 4), tight_layout=True)\n",
    "    plt.plot(loss_history[:, 0], label='Training', color=\"#132a70\", lw=2.0, alpha=0.9)\n",
    "    plt.plot(loss_history[:, 1], label='Validation', linestyle=\"--\", marker=\"o\", color='black')\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.xlabel('Training epoch #')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/{score_model.name}/loss_training.png')\n",
    "else:\n",
    "    score_model.load_state_dict(torch.load(f\"models/{score_model.name}.pt\", map_location=torch_device, weights_only=True))\n",
    "    score_model.eval()"
   ],
   "id": "49bee847ec5d30fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "12de73036512734b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_grid = 128\n",
    "prior_dict = prior.sample(batch_size=100, n_local_samples=n_grid*n_grid)\n",
    "\n",
    "valid_prior_global, valid_prior_local, valid_data = prior_dict['global_params'], prior_dict['local_params'], prior_dict['data']\n",
    "n_post_samples = 300\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_grid*n_grid)\n",
    "\n",
    "score_model.current_number_of_obs = 1\n",
    "#valid_data = valid_data.reshape(100, n_grid*n_grid, 5, 1)\n",
    "print(valid_data.shape, score_model.current_number_of_obs)"
   ],
   "id": "ca6b043ac24ff58c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(prior.normalize_data(valid_data[0]).reshape(5, n_grid, n_grid).numpy())",
   "id": "c0a3cee6c27e9c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(valid_data[0].reshape(5, n_grid, n_grid).numpy())",
   "id": "95fd7a6a865d22ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t1_value = 0.044240666535491316\n",
    "t0_value = 1\n",
    "\n",
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    #'damping_factor': lambda t: (1-torch.ones_like(t)) * 1e-5 + 1e-3,\n",
    "    'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * t),\n",
    "    'MC-dropout': False\n",
    "}\n",
    "score_model.sde.s_shift_cosine = 0#3.71213313557092-2"
   ],
   "id": "72d1b9f7a44165c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = euler_maruyama_sampling(score_model, valid_data,\n",
    "                                                         n_post_samples=n_post_samples,\n",
    "                                                         sampling_arg=sampling_arg,\n",
    "                                                         diffusion_steps=300, device=torch_device,\n",
    "                                                         verbose=True)"
   ],
   "id": "a9ad215a94a8e3d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=global_param_names,\n",
    "                           figsize=(6, 2.5))\n",
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_n_grid_{n_grid}.pdf')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                   difference=True, variable_names=global_param_names, figsize=(6, 2.5), stacked=True)\n",
    "leg = plt.legend()\n",
    "leg.set_visible(False)\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'])\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_n_grid_{n_grid}.pdf')"
   ],
   "id": "4e42fe3aca8e6194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "score_model.current_number_of_obs = 1\n",
    "posterior_local_samples_valid = euler_maruyama_sampling(score_model, valid_data[:, :12],\n",
    "                                                        conditions=posterior_global_samples_valid,\n",
    "                                                        n_post_samples=n_post_samples,\n",
    "                                                        diffusion_steps=100, device=torch_device,\n",
    "                                                        verbose=True)\n",
    "\n",
    "posterior_local_samples_valid = score_model.prior.transform_local_params(beta=posterior_global_samples_valid[..., 1:2], eta_raw=posterior_local_samples_valid[..., 0])"
   ],
   "id": "7c01126af68728ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_local_samples_valid.reshape(valid_data.shape[0], n_post_samples, -1),\n",
    "                          np.array(valid_prior_local)[:, :12],\n",
    "                          variable_names=local_param_names[:12]);"
   ],
   "id": "e741e702eac3033e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'].mean().round(2), diagnostics.root_mean_squared_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'].std().round(2))\n",
    "print('RMSE Local:', diagnostics.root_mean_squared_error(posterior_local_samples_valid.reshape(posterior_global_samples_valid.shape[0], n_post_samples, -1), np.array(valid_prior_local)[:, :12])['values'].mean().round(2),  diagnostics.root_mean_squared_error(posterior_local_samples_valid.reshape(posterior_global_samples_valid.shape[0], n_post_samples, -1), np.array(valid_prior_local)[:, :12])['values'].std().round(2))\n",
    "\n",
    "print('Contraction:', diagnostics.posterior_contraction(posterior_global_samples_valid, np.array(valid_prior_global))['values'].mean().round(2), diagnostics.posterior_contraction(posterior_global_samples_valid, np.array(valid_prior_global))['values'].std().round(2))\n",
    "print('Contraction Local:', diagnostics.posterior_contraction(posterior_local_samples_valid.reshape(posterior_global_samples_valid.shape[0], n_post_samples, -1), np.array(valid_prior_local)[:, :12])['values'].mean().round(2), diagnostics.posterior_contraction(posterior_local_samples_valid.reshape(posterior_global_samples_valid.shape[0], n_post_samples, -1), np.array(valid_prior_local)[:, :12])['values'].std().round(2))"
   ],
   "id": "380a6414339dac60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare to STAN\n",
    "\n",
    "First, you need to run the notebook `ar(1) STAN.ipynb` to generate the STAN posterior samples."
   ],
   "id": "cfacccab17b81a44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = [4*4, 32*32, 128*128][2]\n",
    "if N > 32*32:\n",
    "    test_data = valid_data\n",
    "    true_global = np.array(valid_prior_global)\n",
    "    true_local = np.array(valid_prior_local)\n",
    "else:\n",
    "    global_posterior_stan = np.load(f'problems/ar1/global_posterior_{N}.npy')\n",
    "    local_posterior_stan = np.load(f'problems/ar1/local_posterior_{N}.npy')\n",
    "    true_global = np.load(f'problems/ar1/true_global_{N}.npy')\n",
    "    true_local = np.load(f'problems/ar1/true_local_{N}.npy')\n",
    "\n",
    "    n_grid_stan = int(np.sqrt(true_local.shape[1]))\n",
    "    test_data = []\n",
    "    for g, l in zip(true_global, true_local):\n",
    "        sim_dict = {'alpha': g[0],\n",
    "                    'eta': l}\n",
    "        td = prior.simulator(sim_dict)['observable']\n",
    "        test_data.append(td.reshape(1, n_grid_stan*n_grid_stan, 5))\n",
    "    test_data = np.concatenate(test_data)\n",
    "\n",
    "    n_obs = n_grid_stan*n_grid_stan\n",
    "    batch_size = test_data.shape[0]\n",
    "    n_post_samples = 300\n",
    "\n",
    "n_grid_stan = int(np.sqrt(true_local.shape[1]))\n",
    "print(n_grid_stan*n_grid_stan, test_data.shape)"
   ],
   "id": "b9d1f66d4b95e1bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "\n",
    "def decay(t, d0, d1, alpha, beta):\n",
    "    shaped = 1 - (1 - t.pow(alpha)).pow(beta)\n",
    "    return d0 + (d1 - d0) * shaped\n",
    "\n",
    "def exponential_decay(t, d0, d1):\n",
    "    return d0 * torch.exp(-np.log(d0 / d1) * t)\n",
    "\n",
    "def linear_decay(t, d0, d1):\n",
    "    start = torch.as_tensor(d0, dtype=t.dtype, device=t.device)\n",
    "    end = torch.as_tensor(d1, dtype=t.dtype, device=t.device)\n",
    "    return torch.lerp(input=start, end=end, weight=t)\n",
    "\n",
    "def cosine_decay(t, d0, d1):\n",
    "    return d1 + 0.5 * (d0 - d1) * (1 + torch.cos(torch.pi * t))\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    #t0_value = trial.suggest_float('t0_value', 1e-3, 1)\n",
    "    #t1_value = trial.suggest_float('t1_value', 1e-5, 1e-1)\n",
    "    t0_value = trial.suggest_float('t0_value', 1e-3, 1e-2)\n",
    "    t1_value = trial.suggest_float('t1_value', 1e-5, 1e-3)\n",
    "    s_shift_cosine = trial.suggest_float('s_shift_cosine', 0, 4)\n",
    "    alpha = trial.suggest_float('alpha', 0.3, 2)\n",
    "    beta = trial.suggest_float('beta', 0.3, 2)\n",
    "\n",
    "    sampling_arg = {\n",
    "        'size': 2,\n",
    "        #'damping_factor': lambda t: exp_decay(t, d0=t0_value, d1=t1_value),\n",
    "        'damping_factor': lambda t: decay(t, d0=t0_value, d1=t1_value, alpha=alpha, beta=beta),\n",
    "    }\n",
    "    score_model.sde.s_shift_cosine = s_shift_cosine\n",
    "\n",
    "    test_global_samples = euler_maruyama_sampling(score_model, test_data,\n",
    "                                            n_post_samples=n_post_samples,\n",
    "                                            sampling_arg=sampling_arg,\n",
    "                                            diffusion_steps=300,\n",
    "                                            device=torch_device, verbose=False, return_time=True)\n",
    "    if test_global_samples.ndim == 0:\n",
    "        # time was returned instead of samples because of an error\n",
    "        return 10 + float(test_global_samples) * 10  # penalize the error, but with an informative value\n",
    "    #if np.isnan(test_global_samples).any():\n",
    "    #    return np.inf\n",
    "\n",
    "    rmse = diagnostics.root_mean_squared_error(test_global_samples, true_global)['values'].mean()\n",
    "    cerror = diagnostics.calibration_error(test_global_samples, true_global)['values'].mean()\n",
    "    return cerror + rmse\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params"
   ],
   "id": "ea5df72bc4cb4c53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# no daming factor for N=16",
   "id": "ffa42460b2421bdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the optimal decay function\n",
    "t = torch.linspace(0, 1, 100)\n",
    "dt = decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'],\n",
    "           alpha=study.best_params['alpha'], beta=study.best_params['beta'])\n",
    "dt_exp = exponential_decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'])\n",
    "dt_linear = linear_decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'])\n",
    "dt_cosine = cosine_decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'])\n",
    "\n",
    "plt.plot(t, dt, label='Decay function')\n",
    "plt.plot(t, dt_exp, label='Exponential decay function')\n",
    "plt.plot(t, dt_linear, label='Linear decay function')\n",
    "plt.plot(t, dt_cosine, label='Cosine decay function')\n",
    "plt.legend()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Damping factor')\n",
    "plt.show()\n",
    "\n",
    "print(study.best_params)"
   ],
   "id": "f3d337fc7c7444c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#t0_value, t1_value = 0.1, 0.01\n",
    "sampling_arg = {\n",
    "    'size': 2,\n",
    "    'damping_factor': lambda t: decay(t, d0=study.best_params['t0_value'], d1=study.best_params['t1_value'],\n",
    "           alpha=study.best_params['alpha'], beta=study.best_params['beta']),\n",
    "    'MC-dropout': False\n",
    "}\n",
    "global_param_names = prior.global_param_names\n",
    "local_param_names = prior.get_local_param_names(n_grid_stan*n_grid_stan)\n",
    "param_names_stan = ['STAN '+ p for p in global_param_names]\n",
    "score_model.sde.s_shift_cosine = study.best_params['s_shift_cosine']\n",
    "\n",
    "print(sampling_arg)"
   ],
   "id": "2ae5a6d50469d98a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_test = euler_maruyama_sampling(score_model, test_data,\n",
    "                                                   n_post_samples=n_post_samples,\n",
    "                                                   sampling_arg=sampling_arg,\n",
    "                                                   diffusion_steps=300,\n",
    "                                                   device=torch_device, verbose=True)"
   ],
   "id": "d6b3153beb59a050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_test, true_global, variable_names=global_param_names)\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_ours.png')\n",
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_test, true_global)['values'].mean())\n",
    "fig = diagnostics.recovery(posterior_global_samples_test, np.median(global_posterior_stan, axis=1),\n",
    "                     variable_names=global_param_names, xlabel='STAN Median Estimate')\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_ours_vs_STAN.png')\n",
    "fig = diagnostics.recovery(global_posterior_stan, true_global, variable_names=param_names_stan)\n",
    "#fig.savefig(f'plots/{score_model.name}/recovery_global_STAN.png')\n",
    "print('RMSE STAN:', diagnostics.root_mean_squared_error(global_posterior_stan, true_global)['values'].mean())"
   ],
   "id": "88e4350365822703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_test, true_global, difference=True,\n",
    "                             variable_names=global_param_names)\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_global_ours.png')\n",
    "print('ECDF:', diagnostics.calibration_error(posterior_global_samples_test, true_global)['values'].mean())\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(global_posterior_stan, true_global, difference=True, variable_names=param_names_stan)\n",
    "#fig.savefig(f'plots/{score_model.name}/ecdf_global_STAN.png')\n",
    "print('ECDF STAN:', diagnostics.calibration_error(global_posterior_stan, true_global)['values'].mean())"
   ],
   "id": "fd98fcb141c0ce4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.sde.s_shift_cosine = 0\n",
    "score_model.current_number_of_obs = 1\n",
    "posterior_local_samples_test = euler_maruyama_sampling(score_model, test_data, #[:, :12],\n",
    "                                                       n_post_samples=n_post_samples,\n",
    "                                                       conditions=posterior_global_samples_test,\n",
    "                                                       diffusion_steps=100,\n",
    "                                                       device=torch_device, verbose=True)\n",
    "\n",
    "posterior_local_samples_test = score_model.prior.transform_local_params(beta=posterior_global_samples_test[..., 1:2], eta_raw=posterior_local_samples_test[..., 0])"
   ],
   "id": "e9bf31e2095eb007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('RMSE:', diagnostics.root_mean_squared_error(posterior_global_samples_test, np.array(true_global))['values'].mean().round(2), diagnostics.root_mean_squared_error(posterior_global_samples_test, np.array(true_global))['values'].std().round(2))\n",
    "print('RMSE Local:', diagnostics.root_mean_squared_error(posterior_local_samples_test.reshape(posterior_global_samples_test.shape[0], n_post_samples, -1), np.array(true_local))['values'].mean().round(2), diagnostics.root_mean_squared_error(posterior_local_samples_test.reshape(posterior_global_samples_test.shape[0], n_post_samples, -1), np.array(true_local))['values'].std().round(2))\n",
    "\n",
    "print('Contraction:', diagnostics.posterior_contraction(posterior_global_samples_test, np.array(true_global))['values'].mean().round(2), diagnostics.posterior_contraction(posterior_global_samples_test, np.array(true_global))['values'].std().round(2))\n",
    "print('Contraction Local:', diagnostics.posterior_contraction(posterior_local_samples_test.reshape(posterior_global_samples_test.shape[0], n_post_samples, -1), np.array(true_local))['values'].mean().round(2), diagnostics.posterior_contraction(posterior_local_samples_test.reshape(posterior_global_samples_test.shape[0], n_post_samples, -1), np.array(true_local))['values'].std().round(2))"
   ],
   "id": "e7ac1b3aa5248fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_local_samples_test.reshape(test_data.shape[0], n_post_samples, -1)[:, :, :12],\n",
    "                     true_local[:, :12],\n",
    "                     variable_names=local_param_names[:12])\n",
    "diagnostics.recovery(local_posterior_stan[:, :, :12], true_local[:, :12],\n",
    "                     variable_names=local_param_names[:12]);"
   ],
   "id": "e3dab9569f8bf5fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5642e0affe94ad33",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-abi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
