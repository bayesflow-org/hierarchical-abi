{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize Results",
   "id": "219b7b571653bab8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "d6d2a84ede85592"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- we compare score model with only one condition, and with $k$-conditions\n",
    "- we show that the scaling in the number of needed sampling steps only depends on the Bayesian Units used\n",
    "- error reduces when using more conditions, but since network size stays the same, increases at some point again\n",
    "- we show how mini batching effects the posterior\n",
    "\n",
    "Metrics:\n",
    "- KL divergence between true and estimated posterior samples\n",
    "- RMSE between the medians of true and estimated posterior samples\n",
    "- Posterior contraction: (1 - var_empirical_posterior / var_prior) / (1 - var_true_posterior / var_prior), and using the mean variances over all parameters"
   ],
   "id": "8c4c8a4de857f8c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load results\n",
    "problem_id = 0  # 0: Gaussian, 1: AR(1), 2: Gaussian with linear schedule, 3: Gaussian with EDM\n",
    "var_index = 0  # 0: mini_batch, 1: cosine_shift, 2: damping_factor_t, 3: n_conditions\n",
    "save_plots = True\n",
    "\n",
    "if problem_id == 0:\n",
    "    score_model_names = lambda m_id, n_obs: f'gaussian_archiv/gaussian_flat{m_id}_{n_obs}score_model_v_variance_preserving_cosine_likelihood_weighting'\n",
    "    score_model_name = 'gaussian_flat_score_model_v_variance_preserving_cosine_likelihood_weighting'\n",
    "elif problem_id == 1:\n",
    "    score_model_names = lambda m_id, n_obs: f'ar1_{m_id}_{n_obs}hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting'\n",
    "    score_model_name = 'ar1_hierarchical_score_model_v_variance_preserving_cosine_likelihood_weighting'\n",
    "elif problem_id == 2:\n",
    "    score_model_names = lambda m_id, n_obs: f'gaussian_flat{m_id}_{n_obs}score_model_v_variance_preserving_linear_likelihood_weighting'\n",
    "    score_model_name = 'gaussian_flat_score_model_v_variance_preserving_linear_likelihood_weighting'\n",
    "elif problem_id == 3:\n",
    "    score_model_names = lambda m_id, n_obs: f'gaussian_flat{m_id}_{n_obs}score_model_F_variance_preserving_edm-sampling_edm'\n",
    "    score_model_name = 'gaussian_flat_score_model_F_variance_preserving_edm-sampling_edm'\n",
    "else:\n",
    "    raise ValueError('Unknown problem_id')\n",
    "\n",
    "if not os.path.exists('plots/'+score_model_name):\n",
    "    os.makedirs('plots/'+score_model_name)\n",
    "\n",
    "variables_of_interest = ['mini_batch', 'cosine_shift', 'damping_factor_t']\n",
    "variables_of_interest.append('n_conditions')\n",
    "variable_of_interest = variables_of_interest[var_index]\n",
    "print(variable_of_interest)\n",
    "\n",
    "m_ids = np.arange(10)\n",
    "n_obs = 1 if variable_of_interest != 'n_conditions' else (128 if score_model_name[:2] == 'ar' else 100)\n",
    "\n",
    "results_list = []\n",
    "for m_id in m_ids:\n",
    "    file_name = f'plots/{score_model_names(m_id, n_obs)}/df_results_{variable_of_interest}.csv'\n",
    "    results_list.append(pd.read_csv(file_name, index_col=0))\n",
    "df_results = pd.concat(results_list)\n",
    "\n",
    "# rename column name\n",
    "df_results['damping_factor_t'] = df_results['damping_factor']\n",
    "\n",
    "# Ensure we generate enough synthetic data samples.\n",
    "max_steps = 10000\n",
    "\n",
    "if variable_of_interest == 'mini_batch':\n",
    "    show_values = df_results.mini_batch.unique()\n",
    "    second_variable_of_interest = 'data_size'\n",
    "elif variable_of_interest == 'n_conditions':\n",
    "    show_values = df_results.n_conditions.unique()\n",
    "    second_variable_of_interest = 'data_size'\n",
    "elif variable_of_interest == 'cosine_shift':\n",
    "    show_values = df_results.cosine_shift.unique()\n",
    "    show_values = [0, 5, 10]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "elif variable_of_interest == 'damping_factor_t':\n",
    "    show_values = df_results.damping_factor_t.unique()\n",
    "    show_values = [1e-5, 0.01, 1.0]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "else:\n",
    "    raise ValueError('Unknown variable_of_interest')\n",
    "\n",
    "# only show parts of the experiments\n",
    "df_results = df_results[df_results[variable_of_interest].isin(show_values)]\n",
    "\n",
    "colors = ['#a6cee3', '#1f77b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a']\n",
    "\n",
    "if score_model_name[:2] != 'ar':\n",
    "    metrics = {\n",
    "        'kl': 'KL Divergence',\n",
    "        'median_rmse': 'RMSE',\n",
    "        'contractions': 'Posterior Contraction',\n",
    "        'c_error': 'Calibration Error'\n",
    "    }\n",
    "\n",
    "    # Define the metrics to plot: key is dataframe column, value is label for y-axis.\n",
    "    y_limits = {\n",
    "        #'kl': (0, 100),\n",
    "        'median_rmse': (-0.1, 1),\n",
    "        'contractions': (-0.1, 1.2),\n",
    "        'c_error': (-0.05, 0.55)\n",
    "    }\n",
    "else:\n",
    "    metrics = {\n",
    "        'rmse_global': 'RMSE Global',\n",
    "        'c_error_global': 'Calibration Error Global',\n",
    "        'contractions_global': 'Posterior Contraction Global',\n",
    "        'rmse_local': 'RMSE Local',\n",
    "        #'c_error_local': 'Calibration Error Local',\n",
    "        'contractions_local': 'Posterior Contraction Local'\n",
    "    }\n",
    "\n",
    "    # Define the metrics to plot: key is dataframe column, value is label for y-axis.\n",
    "    y_limits = {\n",
    "        #'kl': (0, 100),\n",
    "        'rmse_global': (-0.1, 1),\n",
    "        'rmse_local': (-0.1, 1),\n",
    "        'contractions_global': (-0.1, 1.2),\n",
    "        'contractions_local': (-0.1, 1.2),\n",
    "        'c_error_global': (-0.05, 0.55),\n",
    "        'c_error_local': (-0.05, 0.55)\n",
    "    }\n",
    "\n",
    "experiment_names = {\n",
    "    #'damping_factor': 'Damping Factor',\n",
    "    'damping_factor_t': 'Damping Factor',\n",
    "    #'damping_factor_prior': 'Damping Factor Prior',\n",
    "    'n_conditions': 'Number of Conditions',\n",
    "    'cosine_shift': 'Cosine Shift',\n",
    "    'data_size': 'Data Size',\n",
    "    'mini_batch': 'Mini Batch Size'\n",
    "}"
   ],
   "id": "2247d1193c4f3edc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_results.mini_batch.unique()",
   "id": "32b787ffaad2f4cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5976bd6032a4ae2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mad = lambda x: np.median(np.abs(x - np.median(x)))",
   "id": "a7428580519e5ea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=len(metrics)+1, sharex=True, figsize=(15, 3), tight_layout=True)\n",
    "ax = axis[0]\n",
    "\n",
    "# Group by both second_variable_of_interest and variable_of_interest to compute median and standard deviation of n_steps.\n",
    "grouped_bar = df_results.groupby([second_variable_of_interest, variable_of_interest])['n_steps'].agg(\n",
    "    ['median',  mad]\n",
    ").reset_index()\n",
    "mad_name = grouped_bar.columns[-1]\n",
    "\n",
    "# Determine unique second_variable_of_interest and variable_of_interest values.\n",
    "second_variable_of_interest_values = sorted(grouped_bar[second_variable_of_interest].unique())\n",
    "variable_batch_values = sorted(grouped_bar[variable_of_interest].unique())\n",
    "\n",
    "# Set up errorbar plot parameters.\n",
    "n_groups = len(second_variable_of_interest_values)\n",
    "n_series = len(variable_batch_values)\n",
    "x = np.arange(n_groups)  # base x locations for groups\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "# Plot an errorbar for each variable_of_interest value within each second_variable_of_interest group.\n",
    "labels = []\n",
    "handles = []\n",
    "for i, mb in enumerate(variable_batch_values):\n",
    "    subset = grouped_bar[grouped_bar[variable_of_interest] == mb]\n",
    "    medians = []\n",
    "    mads = []\n",
    "    for ds in second_variable_of_interest_values:\n",
    "        row = subset[subset[second_variable_of_interest] == ds]\n",
    "        if not row.empty:\n",
    "            medians.append(row['median'].values[0])\n",
    "            mads.append(row[mad_name].values[0])\n",
    "        else:\n",
    "            medians.append(np.nan)\n",
    "            mads.append(0)\n",
    "\n",
    "    # Use 'o-' for markers connected by lines.\n",
    "    h = ax.errorbar(second_variable_of_interest_values, medians, yerr=mads, fmt='o-', capsize=5, label=f'{mb}', alpha=0.75, color=colors[i])\n",
    "    labels.append(f'{mb}')\n",
    "    handles.append(h)\n",
    "\n",
    "ax.axhline(max_steps, color='k', linestyle='--')\n",
    "ax.text(1, max_steps-3500, \"Maximal Number of Steps\", fontsize=8, color='k')\n",
    "\n",
    "# Center the x-axis ticks and label them.\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(second_variable_of_interest_values)\n",
    "ax.set_xlabel(experiment_names[second_variable_of_interest])\n",
    "ax.set_ylabel('Number of Steps')\n",
    "#ax.set_title(f'Number of Steps by {experiment_names[second_variable_of_interest]} and {experiment_names[variable_of_interest]}')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(10, max_steps*2)\n",
    "#ax.legend(title=experiment_names[variable_of_interest], loc='upper left', bbox_to_anchor=(1, 1), frameon=False)\n",
    "\n",
    "#if save_plots:\n",
    "#    plt.savefig(f'plots/{score_model_name}/{variable_of_interest}_n_steps.png', bbox_inches='tight')\n",
    "#plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# Plot 2: Errorbar plots for MMD, RMSE, and Contraction vs. variable_of_interest.\n",
    "# ------------------------------\n",
    "# switch axis\n",
    "temp = variable_of_interest\n",
    "variable_of_interest = second_variable_of_interest\n",
    "second_variable_of_interest = temp\n",
    "\n",
    "# Filter rows with a variable_of_interest value (skip full-batch rows).\n",
    "df_mb = df_results[df_results[variable_of_interest].notnull()].copy()\n",
    "# Convert mini_batch to float (if not already) to allow proper plotting on the x-axis.\n",
    "df_mb[variable_of_interest] = df_mb[variable_of_interest].astype(float)\n",
    "\n",
    "# Identify the unique data sizes (to plot different lines per data size).\n",
    "unique_second_variable_of_interest = sorted(df_mb[second_variable_of_interest].unique())\n",
    "\n",
    "# Create one figure per metric.\n",
    "#fig, ax = plt.subplots(nrows=1, ncols=len(metrics), figsize=(15, 3), tight_layout=True)\n",
    "ax = axis[1:]\n",
    "for j, (metric, metric_label) in enumerate(metrics.items()):\n",
    "    #labels = []\n",
    "    #plt.figure(figsize=(5, 3), tight_layout=True)\n",
    "    for i, ds in enumerate(unique_second_variable_of_interest):\n",
    "        # Select the rows for this particular data size.\n",
    "        df_sub = df_mb[(df_mb[second_variable_of_interest] == ds) & (df_mb['n_steps'] != max_steps)]\n",
    "        # Group by variable_of_interest size to get median and mad of the metric.\n",
    "        grouped = df_sub.groupby(variable_of_interest)[metric].agg(['median', mad]).reset_index()\n",
    "        if not np.isfinite(grouped['median']).all() or grouped.empty:\n",
    "            continue\n",
    "        ax[j].errorbar(grouped[variable_of_interest], grouped['median'], yerr=grouped[mad_name],\n",
    "                       marker='o', capsize=5, alpha=0.75, color=colors[i])\n",
    "        #labels.append(f'{ds}')\n",
    "    ax[j].set_xlabel(experiment_names[variable_of_interest])\n",
    "    ax[j].set_ylabel(metric_label)\n",
    "    #plt.title(f'{metric_label} vs {experiment_names[variable_of_interest]}')\n",
    "    # Using a logarithmic scale for the x-axis since mini-batch sizes vary widely.\n",
    "    if metric == 'rel_contraction':\n",
    "        ax[j].axhline(1, linestyle='--', color='k')\n",
    "        if variable_of_interest == 'mini_batch':\n",
    "            ax[j].text(1, 1.05, \"Optimal\", fontsize=8, color='k')\n",
    "        elif variable_of_interest == 'n_conditions':\n",
    "            ax[j].text(1, 1.05, \"Optimal\", fontsize=8, color='k')\n",
    "        elif variable_of_interest == 'cosine_shift':\n",
    "            ax[j].text(1, 1.05, \"Optimal\", fontsize=8, color='k')\n",
    "        elif variable_of_interest == 'damping_factor_t':\n",
    "            ax[j].text(0.1, 1.05, \"Optimal\", fontsize=8, color='k')\n",
    "\n",
    "    if variable_of_interest == 'mini_batch' or variable_of_interest == 'damping_factor_t' or variable_of_interest == 'data_size':\n",
    "        ax[j].set_xscale('log')\n",
    "    if metric == 'kl':\n",
    "        ax[j].set_yscale('log')\n",
    "    else:\n",
    "        ax[j].set_ylim(y_limits[metric])\n",
    "fig.legend(title=experiment_names[second_variable_of_interest],\n",
    "           handles=handles, labels=labels, ncols=len(labels), frameon=False,\n",
    "           loc='center', bbox_to_anchor=(0.5, -0.05))\n",
    "if save_plots:\n",
    "    fig.savefig(f'plots/{score_model_name}/{second_variable_of_interest}.png', bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ],
   "id": "d323b51e1d4888d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare Number of Step per Information Unit",
   "id": "331f2639597da19e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "variable_of_interest = 'mini_batch'\n",
    "results_list = []\n",
    "for m_id in m_ids:\n",
    "    file_name = f'plots/{score_model_names(m_id, 1)}/df_results_{variable_of_interest}.csv'\n",
    "    results_list.append(pd.read_csv(file_name, index_col=0))\n",
    "df_results_mini = pd.concat(results_list)\n",
    "n_steps_raw = df_results_mini[['n_steps', 'data_size']].groupby('data_size').agg(['median', mad])\n",
    "\n",
    "variable_of_interest = 'n_conditions'\n",
    "results_list = []\n",
    "for m_id in m_ids:\n",
    "    file_name = f'plots/{score_model_names(m_id, 128 if score_model_name[:2] == \"ar\" else 100)}/df_results_{variable_of_interest}.csv'\n",
    "    results_list.append(pd.read_csv(file_name, index_col=0))\n",
    "df_results_cond = pd.concat(results_list)\n",
    "\n",
    "df_results_cond = df_results_cond[df_results_cond[variable_of_interest].isin([1, 50, 100])]"
   ],
   "id": "b94d9098476e391a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axis = plt.subplots(ncols=1, figsize=(4, 3), tight_layout=True)\n",
    "\n",
    "second_variable_of_interest = 'data_size'\n",
    "axis = [axis]\n",
    "#axis[0].errorbar(n_steps_raw.index, n_steps_raw.n_steps.values[:, 0], yerr=n_steps_raw.n_steps.values[:, 1],\n",
    "#                 fmt='o-', capsize=5, alpha=0.75, color=colors[0])\n",
    "\n",
    "for df_results, ax, variable_of_interest in zip([df_results_cond],\n",
    "                                                [axis[-1]],\n",
    "                                                ['n_conditions']):\n",
    "\n",
    "    # Group by both second_variable_of_interest and variable_of_interest to compute median and standard deviation of n_steps.\n",
    "    grouped_bar = df_results.groupby([second_variable_of_interest, variable_of_interest])['n_steps'].agg(['median', mad]).reset_index()\n",
    "\n",
    "    # Determine unique second_variable_of_interest and variable_of_interest values.\n",
    "    second_variable_of_interest_values = sorted(grouped_bar[second_variable_of_interest].unique())\n",
    "    variable_batch_values = sorted(grouped_bar[variable_of_interest].unique())\n",
    "\n",
    "    # Set up errorbar plot parameters.\n",
    "    n_groups = len(second_variable_of_interest_values)\n",
    "    n_series = len(variable_batch_values)\n",
    "    x = np.arange(n_groups)  # base x locations for groups\n",
    "\n",
    "    # Plot an errorbar for each variable_of_interest value within each second_variable_of_interest group.\n",
    "    for i, mb in enumerate(variable_batch_values):\n",
    "        subset = grouped_bar[grouped_bar[variable_of_interest] == mb]\n",
    "        medians = []\n",
    "        mads = []\n",
    "        for ds in second_variable_of_interest_values:\n",
    "            row = subset[subset[second_variable_of_interest] == ds]\n",
    "            if not row.empty:\n",
    "                medians.append(row['median'].values[0])\n",
    "                mads.append(row[mad_name].values[0])\n",
    "            else:\n",
    "                medians.append(np.nan)\n",
    "                mads.append(0)\n",
    "\n",
    "        medians = np.array(medians)\n",
    "        medians[medians > max_steps] = max_steps\n",
    "\n",
    "        # Center the x-axis ticks and label them.\n",
    "        if variable_of_interest == 'n_conditions':\n",
    "            ax.errorbar(second_variable_of_interest_values / mb, medians,\n",
    "                        yerr=mads, fmt='o-', capsize=5, label=f'{mb}', alpha=0.75, color=colors[i])\n",
    "            #if i == 0:\n",
    "            #    axis[0].errorbar(second_variable_of_interest_values / mb, medians,\n",
    "            #            yerr=mads, fmt='o-', capsize=5, label=f'{mb}', alpha=0.75, color=colors[i])\n",
    "        else:\n",
    "            # Use 'o-' for markers connected by lines.\n",
    "            ax.errorbar(second_variable_of_interest_values, medians, yerr=mads, fmt='o-', capsize=5, label=f'{mb}', alpha=0.75, color=colors[i])\n",
    "\n",
    "fig.legend(title=experiment_names[variable_of_interest], loc='upper right', ncols=1, frameon=False,\n",
    "              bbox_to_anchor=(1.4, 0.95))\n",
    "\n",
    "for ax in axis:\n",
    "    ax.axhline(max_steps, color='k', linestyle='--')\n",
    "    ax.text(1, max_steps-3500, \"Maximal Number of Steps\", fontsize=8, color='k')\n",
    "    ax.set_xticks(second_variable_of_interest_values)\n",
    "    ax.set_xticklabels(second_variable_of_interest_values)\n",
    "    ax.set_xlabel('Information Units')\n",
    "    ax.set_ylabel('Number of Steps')\n",
    "    #ax.set_title(f'Number of Steps by {experiment_names[second_variable_of_interest]} and {experiment_names[variable_of_interest]}')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f'plots/{score_model_name}/{variable_of_interest}_n_steps_conditions.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "d89ce2b3ae03ed24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78855afb94cf6770"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
