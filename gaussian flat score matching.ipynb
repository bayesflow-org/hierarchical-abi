{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Flat Gaussian with compositional score matching\n",
    "\n",
    "\n",
    "In this notebook, we will use the compositional score matching to learn the posterior of a flat Gaussian model.\n",
    "The problem is defined as follows:\n",
    "- The prior is a Gaussian distribution with mean 0 and standard deviation 0.1.\n",
    "- The simulator/likelihood is a Gaussian distribution with mean 0 and standard deviation 0.1.\n",
    "- We have an analytical solution for the posterior.\n",
    "- We set the dimension of the problem to $D=10$."
   ],
   "id": "2ad8a59872e571c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "from bayesflow import diagnostics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion_model import CompositionalScoreModel, SDE, weighting_function, train_score_model, sde_sampling, \\\n",
    "    adaptive_sampling, probability_ode_solving, langevin_sampling, generate_diffusion_time, count_parameters\n",
    "from problems.gaussian_flat import GaussianProblem, Prior, Simulator, visualize_simulation_output, \\\n",
    "    generate_synthetic_data, \\\n",
    "    sample_posterior, analytical_posterior_mean_std, posterior_contraction"
   ],
   "id": "b93e54b97fb0cf86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_device = torch.device(\"cpu\")",
   "id": "5e3cab3df9bd3e8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prior = Prior()\n",
    "simulator_test = Simulator()\n",
    "\n",
    "# test the simulator\n",
    "prior_test = prior.sample(2)\n",
    "sim_test = simulator_test(prior_test, n_obs=1000)\n",
    "visualize_simulation_output(sim_test['observable'])"
   ],
   "id": "e5822fbf73492599",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "max_number_of_obs = 1  # larger than one means we condition the score on multiple observations\n",
    "\n",
    "dataset = GaussianProblem(\n",
    "    n_data=10000,\n",
    "    prior=prior,\n",
    "    online_learning=True,\n",
    "    max_number_of_obs=max_number_of_obs\n",
    ")\n",
    "dataset_valid = GaussianProblem(\n",
    "    n_data=batch_size*2,\n",
    "    prior=prior,\n",
    "    max_number_of_obs=max_number_of_obs\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ],
   "id": "5ed21a551165cd71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define diffusion model\n",
    "current_sde = SDE(\n",
    "    kernel_type=['variance_preserving', 'sub_variance_preserving'][0],\n",
    "    noise_schedule=['linear', 'cosine', 'flow_matching'][1]\n",
    ")\n",
    "\n",
    "score_model = CompositionalScoreModel(\n",
    "    input_dim_theta_global=prior.n_params_global,\n",
    "    input_dim_x=prior.D,\n",
    "    hidden_dim=64,\n",
    "    n_blocks=3,\n",
    "    max_number_of_obs=max_number_of_obs,\n",
    "    prediction_type=['score', 'e', 'x', 'v'][3],\n",
    "    sde=current_sde,\n",
    "    time_embed_dim=16,\n",
    "    use_film=False,\n",
    "    weighting_type=[None, 'likelihood_weighting', 'flow_matching', 'sigmoid'][1],\n",
    "    prior=prior,\n",
    ")\n",
    "count_parameters(score_model)\n",
    "print(score_model.name)\n",
    "\n",
    "# make dir for plots\n",
    "if not os.path.exists(f\"plots/{score_model.name}\"):\n",
    "    os.makedirs(f\"plots/{score_model.name}\")"
   ],
   "id": "7691c75da10edd3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train model\n",
    "loss_history = train_score_model(score_model, dataloader, dataloader_valid=dataloader_valid,\n",
    "                                 epochs=500, device=torch_device)\n",
    "score_model.eval()\n",
    "torch.save(score_model.state_dict(), f\"models/{score_model.name}.pt\")\n",
    "\n",
    "# plot loss history\n",
    "plt.figure(figsize=(6, 3), tight_layout=True)\n",
    "plt.plot(loss_history[:, 0], label='Mean Train')\n",
    "plt.plot(loss_history[:, 1], label='Mean Valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/{score_model.name}/loss_training.png')\n",
    "plt.show()"
   ],
   "id": "90cddb5e004338e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "score_model.load_state_dict(torch.load(f\"models/{score_model.name}.pt\", weights_only=True, map_location=torch.device(torch_device)))\n",
    "score_model.eval();"
   ],
   "id": "4d8d75d234d8ecbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize Loss",
   "id": "78442cbf2732b06d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check the error prediction: is it close to the noise?\n",
    "loss_list_target = {}\n",
    "loss_list_score = {}\n",
    "loss_list_error_w_global = {}\n",
    "loss_list_error = {}\n",
    "\n",
    "score_model.to(torch_device)\n",
    "with torch.no_grad():\n",
    "    # Generate diffusion time and step size\n",
    "    diffusion_time = generate_diffusion_time(size=100, device=torch_device)\n",
    "    for t in diffusion_time:\n",
    "        loss_list_target[t.item()] = 0\n",
    "        loss_list_score[t.item()] = 0\n",
    "        loss_list_error_w_global[t.item()] = 0\n",
    "        loss_list_error[t.item()] = 0\n",
    "\n",
    "        for theta_global_batch, _, x_batch in dataloader_valid:\n",
    "            theta_global_batch = theta_global_batch.to(torch_device)\n",
    "            x_batch = x_batch.to(torch_device)\n",
    "\n",
    "            # sample from the Gaussian kernel, just learn the noise\n",
    "            epsilon_global = torch.randn_like(theta_global_batch, dtype=torch.float32, device=torch_device)\n",
    "\n",
    "            # perturb the theta batch\n",
    "            t_tensor = torch.full((theta_global_batch.shape[0], 1), t,\n",
    "                                  dtype=torch.float32, device=torch_device)\n",
    "            # perturb the theta batch\n",
    "            snr = score_model.sde.get_snr(t=t_tensor)\n",
    "            alpha, sigma = score_model.sde.kernel(log_snr=snr)\n",
    "            z_global = alpha * theta_global_batch + sigma * epsilon_global\n",
    "\n",
    "            # predict from perturbed theta\n",
    "            pred_epsilon_global = score_model(theta_global=z_global, time=t_tensor, x=x_batch, pred_score=False)\n",
    "            pred_score_global = score_model(theta_global=z_global, time=t_tensor, x=x_batch, pred_score=True)\n",
    "            true_score_global = score_model.sde.grad_log_kernel(x=z_global,\n",
    "                                                                x0=theta_global_batch, t=t_tensor)\n",
    "\n",
    "            if score_model.prediction_type == 'score':\n",
    "                target_global = -epsilon_global / sigma\n",
    "                pred_target_global = -pred_epsilon_global / sigma\n",
    "            elif score_model.prediction_type == 'e':\n",
    "                target_global = epsilon_global\n",
    "                pred_target_global = pred_epsilon_global\n",
    "            elif score_model.prediction_type == 'v':\n",
    "                target_global = alpha*epsilon_global - sigma * theta_global_batch\n",
    "                pred_target_global = alpha*pred_epsilon_global - sigma * theta_global_batch\n",
    "            elif score_model.prediction_type == 'x':\n",
    "                target_global = theta_global_batch\n",
    "                pred_target_global = (z_global - pred_epsilon_global * sigma) / alpha\n",
    "            else:\n",
    "                raise ValueError(\"Invalid prediction type.\")\n",
    "\n",
    "            # calculate the loss (sum over the last dimension, mean over the batch)\n",
    "            loss_global = torch.mean(torch.sum(torch.square(pred_target_global - target_global), dim=-1))\n",
    "            loss = loss_global\n",
    "            loss_list_target[t.item()] += loss.item()\n",
    "\n",
    "            # calculate the error of the true score\n",
    "            loss_global = torch.mean(torch.sum(torch.square(pred_score_global - true_score_global), dim=-1))\n",
    "            loss = loss_global\n",
    "            loss_list_score[t.item()] += loss.item()\n",
    "\n",
    "            # calculate the weighted loss\n",
    "            w = weighting_function(t_tensor, sde=score_model.sde,\n",
    "                                   weighting_type=score_model.weighting_type, prediction_type=score_model.prediction_type)\n",
    "            loss_global = torch.mean(w * torch.sum(torch.square(pred_epsilon_global - epsilon_global), dim=-1))\n",
    "            loss_list_error_w_global[t.item()] += loss_global.item()\n",
    "\n",
    "            # check if the weighting function is correct\n",
    "            loss_global = torch.mean(torch.sum(torch.square(pred_epsilon_global - epsilon_global), dim=-1))\n",
    "            loss = loss_global\n",
    "            loss_list_error[t.item()] += loss.item()"
   ],
   "id": "160bc1c3143eaed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_target = pd.DataFrame(loss_list_target.items(), columns=['Time', 'Loss'])\n",
    "df_score = pd.DataFrame(loss_list_score.items(), columns=['Time', 'Loss'])\n",
    "df_error_w_global = pd.DataFrame(loss_list_error_w_global.items(), columns=['Time', 'Loss'])\n",
    "df_error = pd.DataFrame(loss_list_error.items(), columns=['Time', 'Loss'])\n",
    "\n",
    "# compute snr\n",
    "snr = score_model.sde.get_snr(diffusion_time).cpu()\n",
    "#upper_bound_loss = (np.sqrt(2) + 1) / (std.numpy()**2)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, sharex=True, figsize=(16, 3), tight_layout=True)\n",
    "ax[0].plot(df_target['Time'], np.log(df_target['Loss']), label=f'Unscaled {score_model.prediction_type} Loss')\n",
    "ax[1].plot(df_score['Time'], np.log(df_score['Loss']), label='Score Loss')\n",
    "#ax[1].plot(df_score['Time'], df_score['Loss'] / upper_bound_loss, label='Score Loss')\n",
    "ax[1].plot(diffusion_time.cpu(), snr, label='log snr', alpha=0.5)\n",
    "ax[2].plot(df_error_w_global['Time'], np.log(df_error_w_global['Loss']), label='Weighted Loss (as in Optimization)')\n",
    "ax[3].plot(df_error['Time'], np.log(df_error['Loss']), label='Loss on Error')\n",
    "for a in ax:\n",
    "    a.set_xlabel('Diffusion Time')\n",
    "    a.set_ylabel('Log Loss')\n",
    "    a.legend()\n",
    "plt.savefig(f'plots/{score_model.name}/losses_diffusion_time.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 3), tight_layout=True)\n",
    "plt.plot(diffusion_time.cpu(),\n",
    "         weighting_function(diffusion_time, sde=score_model.sde, weighting_type=score_model.weighting_type,\n",
    "                            prediction_type=score_model.prediction_type).cpu(),\n",
    "         label='weighting')\n",
    "plt.xlabel('Diffusion Time')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "548ee65f9b466af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation",
   "id": "8a783be484c2f9f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_size = 100  # number of observations\n",
    "valid_prior_global, valid_data = generate_synthetic_data(prior, n_samples=100, data_size=data_size,\n",
    "                                                         normalize=False, random_seed=0)\n",
    "param_names = ['$D_{' + str(i+1) + '}$' for i in range(prior.D)]\n",
    "n_post_samples = 100\n",
    "score_model.current_number_of_obs = 1\n",
    "score_model.sde.s_shift_cosine = 0"
   ],
   "id": "48a8ef4c77661540",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_simulation_output(valid_data)",
   "id": "dad6ce4a9104542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_posterior_single = lambda vd: sample_posterior(\n",
    "    vd,\n",
    "    prior_sigma=prior.scale,\n",
    "    sigma=prior.simulator.scale,\n",
    "    n_samples=n_post_samples\n",
    ")\n",
    "posterior_global_samples_true = np.array([sample_posterior_single(vd) for vd in valid_data])"
   ],
   "id": "130d587a6f86d98a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics.recovery(posterior_global_samples_true, np.array(valid_prior_global), variable_names=param_names)\n",
    "diagnostics.calibration_ecdf(posterior_global_samples_true, np.array(valid_prior_global),\n",
    "                             difference=True, variable_names=param_names);"
   ],
   "id": "e084cd9ae3c449d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mini_batch_size = 10\n",
    "t1_value = mini_batch_size /( data_size //score_model.current_number_of_obs)\n",
    "t0_value = 1\n",
    "mini_batch_arg = {\n",
    "    'size': mini_batch_size,\n",
    "    #'damping_factor': lambda t: t1_value + (t0_value - t1_value) * 0.5 * (1 + torch.cos(torch.pi * t)),\n",
    "    #'damping_factor': lambda t: t0_value + (t1_value - t0_value) * score_model.sde.kernel(log_snr=score_model.sde.get_snr(t))[1],\n",
    "    'damping_factor': lambda t: 0.1, #t1_value,\n",
    "    #'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'damping_factor': lambda t: t0_value + (t1_value - t0_value) * torch.sigmoid(20*(t-0.3))\n",
    "}\n",
    "#plt.plot(torch.linspace(0, 1, 100), mini_batch_arg['damping_factor'](torch.linspace(0, 1, 100)))\n",
    "#plt.show()\n",
    "\n",
    "t0_value, t1_value"
   ],
   "id": "c0fdc343115905a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = langevin_sampling(score_model, valid_data, n_post_samples=n_post_samples,\n",
    "                                                   mini_batch_arg=mini_batch_arg,\n",
    "                                                   diffusion_steps=300, langevin_steps=5, step_size_factor=0.05,\n",
    "                                                   device=torch_device, verbose=True)"
   ],
   "id": "1fe89835b609ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_langevin_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_langevin_sampler{score_model.current_number_of_obs}.png')"
   ],
   "id": "43b7a372db84d70b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = sde_sampling(score_model, valid_data, n_post_samples=n_post_samples, diffusion_steps=300,\n",
    "                                              method=['euler', 'milstein_grad_free', 'srk1w1'][1],\n",
    "                                           device=torch_device, verbose=True)"
   ],
   "id": "c38c79c5d98b368a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_euler_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_euler_sampler{score_model.current_number_of_obs}.png')"
   ],
   "id": "ee0dba7eae532c3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = sde_sampling(score_model, valid_data, n_post_samples=n_post_samples, diffusion_steps=100,\n",
    "                                              method=['euler', 'milstein_grad_free', 'srk1w1'][1],\n",
    "                                              mini_batch_arg=mini_batch_arg,\n",
    "                                              device=torch_device, verbose=True)"
   ],
   "id": "d7b30f5752765d9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_euler_sub_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                difference=True, variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_euler_sub_sampler{score_model.current_number_of_obs}.png')"
   ],
   "id": "6d8aa4052881d96b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mini_batch_size = 10\n",
    "t1_value = 0.01 #mini_batch_size /( data_size //score_model.current_number_of_obs)\n",
    "t0_value = 1\n",
    "mini_batch_arg = {\n",
    "    'size': mini_batch_size,\n",
    "    #'damping_factor': lambda t: t1_value + (t0_value - t1_value) * 0.5 * (1 + torch.cos(torch.pi * t)),\n",
    "    #'damping_factor': lambda t: t0_value + (t1_value - t0_value) * score_model.sde.kernel(log_snr=score_model.sde.get_snr(t))[1],\n",
    "    'damping_factor': lambda t: torch.ones_like(t)*0.1, #t1_value,\n",
    "    'damping_factor_prior': lambda t: torch.ones_like(t)*0.1, #t1_value,\n",
    "    #'damping_factor': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'damping_factor_prior': lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t),\n",
    "    #'damping_factor': lambda t: t0_value + (t1_value - t0_value) * torch.sigmoid(20*(t-0.3))\n",
    "}\n",
    "#plt.plot(torch.linspace(0, 1, 100), mini_batch_arg['damping_factor'](torch.linspace(0, 1, 100)))\n",
    "#plt.show()\n",
    "\n",
    "t0_value, t1_value"
   ],
   "id": "adbcb218809d8e17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = adaptive_sampling(score_model, valid_data, n_post_samples=n_post_samples,\n",
    "                                                   mini_batch_arg=mini_batch_arg,\n",
    "                                                   run_sampling_in_parallel=False,\n",
    "                                                   device=torch_device, verbose=True)"
   ],
   "id": "b62172f017bca773",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_adaptive_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                difference=True, variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_adaptive_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.z_score_contraction(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                                            variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/z_score_global_adaptive_sampler{score_model.current_number_of_obs}.png')\n",
    "\n",
    "diagnostics.calibration_error(posterior_global_samples_valid, np.array(valid_prior_global))['values'].mean()"
   ],
   "id": "6591e3614e31a37e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "posterior_global_samples_valid = probability_ode_solving(score_model, valid_data, n_post_samples=n_post_samples,\n",
    "                                                         #run_sampling_in_parallel=False,\n",
    "                                                         method=['RK45', 'RK23', 'Radau', 'LSODA'][0],\n",
    "                                                         device=torch_device, verbose=True)"
   ],
   "id": "e3773806341007dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = diagnostics.recovery(posterior_global_samples_valid, np.array(valid_prior_global), variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/recovery_global_ode{score_model.current_number_of_obs}.png')\n",
    "\n",
    "fig = diagnostics.calibration_ecdf(posterior_global_samples_valid, np.array(valid_prior_global),\n",
    "                          difference=True, variable_names=param_names)\n",
    "fig.savefig(f'plots/{score_model.name}/ecdf_global_ode{score_model.current_number_of_obs}.png')"
   ],
   "id": "2d9bd75b07078d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step Size for different Grid Sizes\n",
    "\n",
    "- we compare score model with only one condition, and with $k$-conditions\n",
    "- we show that the scaling in the number of needed sampling steps only depends on the Bayesian Units used\n",
    "- error reduces when using more conditions, but since network size stays the same, increases at some point again\n",
    "- we show how mini batching effects the posterior\n",
    "\n",
    "Metrics:\n",
    "- MMD between true and estimated posterior samples\n",
    "- RMSE between the medians of true and estimated posterior samples\n",
    "- Posterior contraction: (1 - var_empirical_posterior / var_prior) / (1 - var_true_posterior / var_prior), and using the mean variances over all parameters"
   ],
   "id": "67f13655f71dbf37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def gaussian_kernel(x, y, sigma):\n",
    "    \"\"\"Compute Gaussian kernel between two sets of samples.\"\"\"\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "    sq_dists = np.sum((x[:, None, :] - y[None, :, :]) ** 2, axis=2)\n",
    "    return np.exp(-sq_dists / (2 * sigma ** 2))\n",
    "\n",
    "def compute_mmd(x, y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Maximum Mean Discrepancy (MMD) between two sets of samples.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Samples from distribution P, shape (n, d).\n",
    "        y (np.ndarray): Samples from distribution Q, shape (m, d).\n",
    "        sigma (float): Bandwidth for the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated MMD^2 value.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Compute kernel matrices\n",
    "    K_xx = gaussian_kernel(x, x, sigma)\n",
    "    K_yy = gaussian_kernel(y, y, sigma)\n",
    "    K_xy = gaussian_kernel(x, y, sigma)\n",
    "\n",
    "    # Compute MMD^2\n",
    "    mmd_squared = (np.mean(K_xx) + np.mean(K_yy) - 2 * np.mean(K_xy))\n",
    "    return mmd_squared\n",
    "\n",
    "\n",
    "def kl_divergence(x, samples_q):\n",
    "    try:\n",
    "        mu_p, std_p = analytical_posterior_mean_std(x, prior_std=prior.scale, likelihood_std=prior.simulator.scale)\n",
    "        cov_p = np.diag(std_p**2)\n",
    "\n",
    "        mu_q = np.mean(samples_q, axis=0)\n",
    "        cov_q = np.cov(samples_q, rowvar=False)\n",
    "\n",
    "        d = mu_p.shape[0]\n",
    "        cov_q_inv = np.linalg.inv(cov_q)\n",
    "\n",
    "        term1 = np.log(np.linalg.det(cov_q) / np.linalg.det(cov_p))\n",
    "        term2 = np.trace(cov_q_inv @ cov_p)\n",
    "        term3 = (mu_q - mu_p).T @ cov_q_inv @ (mu_q - mu_p)\n",
    "\n",
    "        return 0.5 * (term1 - d + term2 + term3)\n",
    "    except Exception as e:  # sometimes a linalg error occurs\n",
    "        print(e)\n",
    "        return np.inf"
   ],
   "id": "2f3122f8a1b63af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure we generate enough synthetic data samples.\n",
    "n_samples_data = 100\n",
    "n_post_samples = 100\n",
    "score_model.current_number_of_obs = 1\n",
    "max_steps = 10000\n",
    "variable_of_interest = ['mini_batch', 'n_conditions',\n",
    "                        'cosine_shift', 'damping_factor', 'damping_factor_prior', 'damping_factor_t'][5]\n",
    "print(variable_of_interest)\n",
    "\n",
    "\n",
    "#for variable_of_interest in ['mini_batch']:#['mini_batch', 'cosine_shift', 'damping_factor', 'damping_factor_prior', 'damping_factor_t'][::-1]:\n",
    "mini_batch = [None]\n",
    "n_conditions = [1]\n",
    "cosine_shifts = [2]\n",
    "d_factors = [1]  # using the d factor depending on the mini batch size\n",
    "\n",
    "if variable_of_interest == 'mini_batch':\n",
    "    # Set up your data sizes and mini-batch parameters.\n",
    "    data_sizes = np.array([1, 10, 100, 1000, 10000])\n",
    "    mini_batch = [1, 10, 100, 1000, 10000, None]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest == 'n_conditions':\n",
    "    # Set up your data sizes and mini-batch parameters.\n",
    "    data_sizes = np.array([1, 10, 100, 1000, 10000, 100000])\n",
    "    n_conditions = [1, 5, 10, 20, 50, 100]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest == 'cosine_shift':\n",
    "    # Set up your data sizes and mini-batch parameters.\n",
    "    data_sizes = np.array([1, 10, 100, 1000, 10000])\n",
    "    mini_batch = [10]\n",
    "    cosine_shifts = [0, -1, 1, 2, 5, 10]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "\n",
    "elif variable_of_interest in ['damping_factor', 'damping_factor_prior', 'damping_factor_t']:\n",
    "    # Set up your data sizes and mini-batch parameters.\n",
    "    data_sizes = np.array([10, 100, 1000, 10000, 100000])\n",
    "    mini_batch = [10]\n",
    "    d_factors = [0.001, 0.01, 0.1, 0.5, 0.75, 0.9, 1]\n",
    "    second_variable_of_interest = 'data_size'\n",
    "else:\n",
    "    raise ValueError('Unknown variable_of_interest')\n",
    "\n",
    "df_path = f'plots/{score_model.name}/df_results_{variable_of_interest}.csv'\n",
    "if os.path.exists(df_path):\n",
    "    # Load CSV\n",
    "    df_results = pd.read_csv(df_path, index_col=0)\n",
    "    # Convert string representations back to lists\n",
    "    df_results['list_steps'] = df_results['list_steps'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    if variable_of_interest == 'damping_factor_prior':\n",
    "        df_results['damping_factor_prior'] = df_results['damping_factor']\n",
    "    elif variable_of_interest == 'damping_factor_t':\n",
    "        df_results['damping_factor_t'] = df_results['damping_factor']\n",
    "else:\n",
    "    df_results = None"
   ],
   "id": "9d0c8c24e2223588",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List to store results.\n",
    "results = []\n",
    "reached_max_evals = []\n",
    "\n",
    "# Iterate over data sizes.\n",
    "for n in data_sizes:\n",
    "    # Generate synthetic data with enough samples\n",
    "    true_params, test_data = generate_synthetic_data(prior, n_samples=n_samples_data, data_size=n,\n",
    "                                                     normalize=False, random_seed=0)\n",
    "    true_params = true_params.numpy()\n",
    "    # Iterate over experimental setting\n",
    "    for mb, nc, cs, d_factor in itertools.product(mini_batch, n_conditions, cosine_shifts, d_factors):\n",
    "        # Skip mini-batch settings that are larger than or equal to the data size.\n",
    "        if mb is not None and mb > n:\n",
    "            continue\n",
    "        if mb == n:\n",
    "            mb = None\n",
    "        if nc > n:\n",
    "            continue\n",
    "\n",
    "        for max_reached in reached_max_evals:\n",
    "            if max_reached[1] == nc and max_reached[2] == cs and max_reached[3] == d_factor:\n",
    "                # for this condition, if a lower mini batch size already failed we can skip that as well\n",
    "                if max_reached[0] is None or mb is None:\n",
    "                    pass\n",
    "                elif max_reached[0] <= mb:\n",
    "                    print(f'smaller mini batch size already failed, skipping {nc}, {cs}')\n",
    "                    continue\n",
    "\n",
    "        print(f\"Data Size: {n}, Mini Batch: {mb}, Conditions: {nc}, Cosine shift: {cs}, Damping Factor: {d_factor}\")\n",
    "        # Set current number of conditions\n",
    "        score_model.current_number_of_obs = nc\n",
    "\n",
    "        # Set cosine shit\n",
    "        score_model.sde.s_shift_cosine = cs\n",
    "\n",
    "        # Damping factor\n",
    "        if variable_of_interest == 'damping_factor_t':\n",
    "            t0_value = 1\n",
    "            t1_value = d_factor\n",
    "            damping_factor = lambda t: t0_value * torch.exp(-np.log(t0_value / t1_value) * 2*t)\n",
    "            if mb is None:\n",
    "                mini_batch_arg = {'damping_factor': damping_factor, 'damping_factor_prior': damping_factor}\n",
    "            else:\n",
    "                mini_batch_arg = {'size': mb, 'damping_factor': damping_factor,\n",
    "                                  'damping_factor_prior': damping_factor}\n",
    "        elif variable_of_interest == 'damping_factor_prior':\n",
    "            damping_factor = lambda t: torch.ones_like(t) * d_factor\n",
    "            if mb is None:\n",
    "                mini_batch_arg = {'damping_factor': damping_factor, 'damping_factor_prior': damping_factor}\n",
    "            else:\n",
    "                mini_batch_arg = {'size': mb, 'damping_factor': damping_factor, 'damping_factor_prior': damping_factor}\n",
    "        else:\n",
    "            damping_factor = lambda t: torch.ones_like(t) * d_factor\n",
    "            if mb is None:\n",
    "                mini_batch_arg = {'damping_factor': damping_factor}\n",
    "            else:\n",
    "                mini_batch_arg = {'size': mb, 'damping_factor': damping_factor}\n",
    "\n",
    "        # Run adaptive sampling.\n",
    "        test_samples, list_steps = adaptive_sampling(score_model, test_data, conditions=None,\n",
    "                                                     n_post_samples=n_post_samples,\n",
    "                                                     mini_batch_arg=mini_batch_arg,\n",
    "                                                     max_evals=max_steps*2,\n",
    "                                                     t_end=0, random_seed=0, device=torch_device,\n",
    "                                                     run_sampling_in_parallel=False,  # can actually be faster\n",
    "                                                     return_steps=True)\n",
    "        # Sample the true posterior.\n",
    "        true_samples = np.stack([sample_posterior(x, prior_sigma=prior.scale,\n",
    "                                                  sigma=prior.simulator.scale, n_samples=n_post_samples) for x in test_data], axis=0)\n",
    "\n",
    "        # Compute metrics.\n",
    "        mmd = [compute_mmd(test_samples[i], true_samples[i]) for i in range(n_samples_data)]\n",
    "        if test_samples.shape[1] > 1:\n",
    "            kl = [kl_divergence(test_data[i], test_samples[i]) for i in range(n_samples_data)]\n",
    "        else:\n",
    "            kl = [np.inf for i in range(n_samples_data)]\n",
    "\n",
    "        rmse = diagnostics.root_mean_squared_error(test_samples, true_params)['values'].mean()\n",
    "        c_error = diagnostics.calibration_error(test_samples, true_params)['values'].mean()\n",
    "\n",
    "        contractions = diagnostics.posterior_contraction(test_samples, true_params)['values'].mean()\n",
    "        true_contraction = posterior_contraction(prior_std=prior.scale, likelihood_std=prior.simulator.scale, n_obs=n).mean()\n",
    "        rel_contraction = (contractions / true_contraction)\n",
    "\n",
    "        # Number of steps\n",
    "        if np.isnan(test_samples).any():\n",
    "            n_steps = np.inf\n",
    "            reached_max_evals.append((mb, nc, cs, d_factor))\n",
    "        else:\n",
    "            n_steps = np.mean([len(ls) for ls in list_steps])\n",
    "            if n_steps >= max_steps:\n",
    "                # no need to check larger mini batches, will also fail to converge\n",
    "                reached_max_evals.append((mb, nc, cs, d_factor))\n",
    "\n",
    "        # Print current metrics.\n",
    "        print(f\"KL: {np.mean(kl)}, #Steps: {n_steps}\")\n",
    "\n",
    "        # Save results into a dictionary.\n",
    "        for i in range(n_samples_data):  # might be less than the actual data points because inference failed\n",
    "            results.append({\n",
    "                \"data_size\": n,\n",
    "                \"data_id\": i,\n",
    "                \"mini_batch\": mb if mb is not None else n,\n",
    "                \"damping_factor\": d_factor,\n",
    "                'n_conditions': nc,\n",
    "                'cosine_shift': cs,\n",
    "                \"n_steps\": n_steps,\n",
    "                \"list_steps\": np.where(np.isnan(list_steps[0]), None, list_steps[0]).tolist(),  # only for the first sample\n",
    "                \"mmd\": mmd[i],\n",
    "                \"kl\": kl[i],\n",
    "                \"median\": np.median(test_samples, axis=1)[i],\n",
    "                \"median_rmse\": rmse,\n",
    "                \"c_error\": c_error,\n",
    "                \"contractions\": contractions,\n",
    "                \"rel_contraction\": rel_contraction\n",
    "            })\n",
    "\n",
    "        # Create a DataFrame from the results list. Save intermediate results\n",
    "        df_results = pd.DataFrame(results)\n",
    "        # Convert lists to strings for CSV storage\n",
    "        df_results['list_steps'] = df_results['list_steps'].apply(lambda x: str(x))\n",
    "        df_results.to_csv(df_path)\n",
    "\n",
    "# Convert string representations back to lists\n",
    "df_results['list_steps'] = df_results['list_steps'].apply(lambda x: ast.literal_eval(x))"
   ],
   "id": "ca4319839736a603",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = ['#a6cee3', '#1f77b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a']\n",
    "\n",
    "metrics = {\n",
    "    'kl': 'KL Divergence',\n",
    "    #'mmd': 'MMD',\n",
    "    'median_rmse': 'RMSE',\n",
    "    'rel_contraction': 'Relative Posterior Contraction',\n",
    "    'c_error': 'Calibration Error'\n",
    "}\n",
    "\n",
    "experiment_names = {\n",
    "    'damping_factor': 'Damping Factor',\n",
    "    'damping_factor_t': 'Damping Factor\\nTime Dependent',\n",
    "    'damping_factor_prior': 'Damping Factor Prior',\n",
    "    'n_conditions': 'Number of Conditions',\n",
    "    'cosine_shift': 'Cosine Shift',\n",
    "    'data_size': 'Data Size',\n",
    "    'mini_batch': 'Mini Batch Size'\n",
    "}"
   ],
   "id": "e14dba8988cb82b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by both second_variable_of_interest and variable_of_interest to compute mean and standard deviation of n_steps.\n",
    "grouped_bar = df_results.groupby([second_variable_of_interest, variable_of_interest])['n_steps'].agg(['mean','std']).reset_index()\n",
    "\n",
    "# Determine unique second_variable_of_interest and variable_of_interest values.\n",
    "second_variable_of_interest_values = sorted(grouped_bar[second_variable_of_interest].unique())\n",
    "variable_batch_values = sorted(grouped_bar[variable_of_interest].unique())\n",
    "\n",
    "# Set up errorbar plot parameters.\n",
    "n_groups = len(second_variable_of_interest_values)\n",
    "n_series = len(variable_batch_values)\n",
    "x = np.arange(n_groups)  # base x locations for groups\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "# Plot an errorbar for each variable_of_interest value within each second_variable_of_interest group.\n",
    "for i, mb in enumerate(variable_batch_values):\n",
    "    subset = grouped_bar[grouped_bar[variable_of_interest] == mb]\n",
    "    means = []\n",
    "    stds = []\n",
    "    for ds in second_variable_of_interest_values:\n",
    "        row = subset[subset[second_variable_of_interest] == ds]\n",
    "        if not row.empty:\n",
    "            means.append(row['mean'].values[0])\n",
    "            stds.append(row['std'].values[0])\n",
    "        else:\n",
    "            means.append(np.nan)\n",
    "            stds.append(0)\n",
    "\n",
    "    # Use 'o-' for markers connected by lines.\n",
    "    ax.errorbar(x, means, yerr=stds, fmt='o-', capsize=5, label=f'{mb}', alpha=0.75, color=colors[i])\n",
    "\n",
    "ax.axhline(max_steps, color='k', linestyle='--')\n",
    "ax.text(0.1, max_steps-3500, f\"Maximal Number of Steps\", fontsize=8, color='k')\n",
    "\n",
    "# Center the x-axis ticks and label them.\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(second_variable_of_interest_values)\n",
    "ax.set_xlabel(experiment_names[second_variable_of_interest])\n",
    "ax.set_ylabel('Number of Steps')\n",
    "#ax.set_title(f'Number of Steps by {experiment_names[second_variable_of_interest]} and {experiment_names[variable_of_interest]}')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(title=experiment_names[variable_of_interest], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.savefig(f'plots/{score_model.name}/{variable_of_interest}_n_steps.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "60e1621aa89bc4d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if variable_batch_values == 'mini_batch_size':\n",
    "    # ------------------------------\n",
    "    # Plot 1: Bar plot of n_steps for the full-batch  case.\n",
    "    # ------------------------------\n",
    "\n",
    "    # Filter the full-batch rows\n",
    "    df_full = df_results[df_results['data_size'] == df_results['mini_batch']]\n",
    "\n",
    "    # Group by data_size and compute mean and standard deviation of n_steps.\n",
    "    grouped_full = df_full.groupby('data_size')['n_steps'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    plt.figure(figsize=(4, 3), tight_layout=True)\n",
    "    plt.bar(grouped_full['data_size'], grouped_full['mean'],\n",
    "            yerr=grouped_full['std'], capsize=5, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Data Size')\n",
    "    plt.ylabel('Number of Steps')\n",
    "    plt.title('Number of Steps (Full Batch) per Data Size')\n",
    "    plt.xticks(grouped_full['data_size'])\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.savefig(f'plots/{score_model.name}/{variable_of_interest}_steps_full_batch.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# Plot 2: Errorbar plots for MMD, RMSE, and Contraction vs. variable_of_interest.\n",
    "# ------------------------------\n",
    "\n",
    "# Filter rows with a variable_of_interest value (skip full-batch rows).\n",
    "df_mb = df_results[df_results[variable_of_interest].notnull()].copy()\n",
    "# Convert mini_batch to float (if not already) to allow proper plotting on the x-axis.\n",
    "df_mb[variable_of_interest] = df_mb[variable_of_interest].astype(float)\n",
    "\n",
    "# Define the metrics to plot: key is dataframe column, value is label for y-axis.\n",
    "y_limits = {\n",
    "    #'kl': (0, 100),\n",
    "    'median_rmse': (-0.1, 1),\n",
    "    'rel_contraction': (-0.1, 1.2),\n",
    "    'c_error': (-0.05, 0.55)\n",
    "}\n",
    "\n",
    "# Identify the unique data sizes (to plot different lines per data size).\n",
    "unique_second_variable_of_interest = sorted(df_mb[second_variable_of_interest].unique())\n",
    "\n",
    "# Create one figure per metric.\n",
    "for metric, metric_label in metrics.items():\n",
    "    plt.figure(figsize=(5, 3), tight_layout=True)\n",
    "    for i, ds in enumerate(unique_second_variable_of_interest):\n",
    "        # Select the rows for this particular data size.\n",
    "        df_sub = df_mb[(df_mb[second_variable_of_interest] == ds) & (df_mb['n_steps'] != max_steps)]\n",
    "        # Group by variable_of_interest size to get mean and std of the metric.\n",
    "        grouped = df_sub.groupby(variable_of_interest)[metric].agg(['mean', 'std']).reset_index()\n",
    "        if not np.isfinite(grouped['mean']).all() or grouped.empty:\n",
    "            continue\n",
    "        plt.errorbar(grouped[variable_of_interest], grouped['mean'], yerr=grouped['std'],\n",
    "                     marker='o', capsize=5, label=f'{ds}', alpha=0.75, color=colors[i])\n",
    "    plt.xlabel(experiment_names[variable_of_interest])\n",
    "    plt.ylabel(metric_label)\n",
    "    #plt.title(f'{metric_label} vs {experiment_names[variable_of_interest]}')\n",
    "    plt.legend(title=experiment_names[second_variable_of_interest], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # Using a logarithmic scale for the x-axis since mini-batch sizes vary widely.\n",
    "    if variable_of_interest == 'mini_batch':\n",
    "        plt.xscale('log')\n",
    "    if metric == 'kl':\n",
    "        plt.yscale('log')\n",
    "    else:\n",
    "        plt.ylim(y_limits[metric])\n",
    "    plt.savefig(f'plots/{score_model.name}/{variable_of_interest}_{metric}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "606f3c91ce56d551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if variable_of_interest == 'mini_batch':\n",
    "    # Figure 1: Full Batch (mini_batch is None) for data_id 0\n",
    "    # ------------------------------\n",
    "    # Filter for valid_id 0 and full-batch runs\n",
    "    df_full = df_results[(df_results['data_id'] == 0) & (df_results['data_size'] == df_results['mini_batch'])]\n",
    "\n",
    "    plt.figure(figsize=(4, 3), tight_layout=True)\n",
    "    for ds in sorted(df_full['data_size'].unique()):\n",
    "        # Extract the row for this data_size (should be a single row per combination)\n",
    "        row = df_full[df_full['data_size'] == ds]\n",
    "        if not row.empty:\n",
    "            # Extract the list of step sizes (assumed to be a list or array)\n",
    "            steps_list = row.iloc[0]['list_steps']\n",
    "            # Plot step size vs iteration\n",
    "            plt.plot(range(len(steps_list)), steps_list, label=f\"{ds}\", alpha=.75)\n",
    "\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Step Size\")\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Step Size Over Time for Full Batch\")\n",
    "    plt.legend(title=\"Data Size\")\n",
    "    plt.savefig(f'plots/{score_model.name}/{variable_of_interest}_full_batch_step_size.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# Figure 2\n",
    "# ------------------------------\n",
    "# Filter for data_id 0 and only mini-batch runs.\n",
    "df_mb = df_results[(df_results['data_id'] == 0) & (df_results[variable_of_interest].notnull())]\n",
    "\n",
    "# Get the sorted unique mini_batch values\n",
    "variable_batch_values = sorted(df_mb[variable_of_interest].unique())\n",
    "n_subplots = len(variable_batch_values)\n",
    "\n",
    "# Create subplots (one per mini_batch value)\n",
    "fig, axes = plt.subplots(1, n_subplots, figsize=(4 * n_subplots, 3), sharey=True, tight_layout=True)\n",
    "\n",
    "# In case there's only one subplot, wrap axes in a list for uniformity.\n",
    "if n_subplots == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "group_unique = df_mb[second_variable_of_interest].unique()\n",
    "for ax, mb in zip(axes, variable_batch_values):\n",
    "    # Filter for the current mini_batch value\n",
    "    df_mb_subset = df_mb[df_mb[variable_of_interest] == mb]\n",
    "    for i, ds in enumerate(sorted(group_unique)):\n",
    "        row = df_mb_subset[df_mb_subset[second_variable_of_interest] == ds]\n",
    "        if not row.empty:\n",
    "            steps_list = row.iloc[0]['list_steps']\n",
    "            ax.plot(range(len(steps_list)), steps_list, label=f\"{ds}\", color=colors[i])\n",
    "\n",
    "    ax.set_title(f\"{experiment_names[variable_of_interest]} = {mb}\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Step Size\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend(title=experiment_names[second_variable_of_interest], loc='lower right')\n",
    "plt.savefig(f'plots/{score_model.name}/{variable_of_interest}_step_size.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "ac285d4f25d5218d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "62c11ed58b4f7497",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
